{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"./data/allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"./data/methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"./data/fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"./data/functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"./data/basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"./data/supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug purposes\n",
    "#for val in allvalues_perset:\n",
    "#    print(\"======= START =======\")\n",
    "#    print(val, len(allvalues_perset[val]))\n",
    "#    pp.pprint(allvalues_perset[val])\n",
    "#    print(\"=======  END  =======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(commonutils)\n",
    "\n",
    "from commonutils import ModelResults\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        wtmad = None\n",
    "        if setname in supersetnames:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestinsidemethod_wtmad:\n",
    "                models_results[setname].bestinsidemethod_wtmad = wtmad\n",
    "                models_results[setname].bestinsidemethod_name_wtmad = str(methodid)\n",
    "                models_results[setname].y_pred_bestinsidemethod_wtmad = y_pred\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestinsidemethod_rmse:\n",
    "            models_results[setname].bestinsidemethod_rmse = rmse\n",
    "            models_results[setname].bestinsidemethod_name_rmse = str(methodid)\n",
    "            models_results[setname].y_pred_bestinsidemethod_rmse = y_pred\n",
    "\n",
    "    for j, method in enumerate(methods):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        wtmad = None            \n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestourmethod_wtmad:\n",
    "                models_results[setname].bestourmethod_wtmad = wtmad\n",
    "                models_results[setname].bestourmethod_name_wtmad = method\n",
    "                models_results[setname].y_pred_bestourmethod_wtmad = y_pred\n",
    "        \n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestourmethod_rmse:\n",
    "            models_results[setname].bestourmethod_rmse = rmse\n",
    "            models_results[setname].bestourmethod_name_rmse = method\n",
    "            models_results[setname].y_pred_bestourmethod_rmse = y_pred\n",
    "\n",
    "bestmnethodscount = {}\n",
    "setofbestourmethodswtamd = {}\n",
    "\n",
    "print(\"Results for inside and our methods\")\n",
    "print(\"%40s\"% \"Dataset\", \" , \", \\\n",
    "    \"Best inside method RMSE\", \" , \", \\\n",
    "    \"RMSE\", \" , \", \\\n",
    "    \"Best inside method WTMAD2\", \" , \", \\\n",
    "    \"WTMAD2\", \" , \", \\\n",
    "    \"Best our method RMSE\", \" , \", \\\n",
    "    \"RMSE\", \" , \", \\\n",
    "    \"Best our method WTMAD2\", \" , \", \\\n",
    "    \"WTMAD2\")\n",
    "for setname in fullsetnames:\n",
    "    if models_results[setname].bestourmethod_name_rmse in bestmnethodscount:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] += 1\n",
    "    else:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] = 1\n",
    "\n",
    "    if models_results[setname].bestourmethod_name_wtmad != \"\":\n",
    "        if models_results[setname].bestourmethod_name_wtmad in setofbestourmethodswtamd:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] += 1\n",
    "        else:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] = 1\n",
    "          \n",
    "    print(\"%40s\"%setname, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestinsidemethod_name_rmse , \" , \",\\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_rmse, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestinsidemethod_name_wtmad , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_wtmad, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestourmethod_name_rmse , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_rmse, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestourmethod_name_wtmad , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_wtmad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE\")\n",
    "for method in bestmnethodscount:\n",
    "    print(\"Best our method \", method, \" count: \", bestmnethodscount[method])\n",
    "\n",
    "print()\n",
    "print(\"WTMAD2\")\n",
    "for method in setofbestourmethodswtamd:\n",
    "    print(\"Best our method \", method, \" count: \", setofbestourmethodswtamd[method])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build descriptors \n",
    "selected_basisset = \"TZVP\"\n",
    "selected_functional = \"PBE0\"\n",
    "functionals = [\"PBE\", \"PBE0\", \"TPSS\", \"TPSSh\"]\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for func in functionals:\n",
    "            for basis in basis_sets:\n",
    "                if basis == selected_basisset and func == selected_functional:\n",
    "                    k = func + \"-\" + basis + \"_energydiff\"\n",
    "                    for k2 in val[k]:\n",
    "                        if k2 not in desciptors:\n",
    "                            desciptors[k2] = [val[k][k2]]\n",
    "                        else:\n",
    "                            desciptors[k2].append(val[k][k2])\n",
    "                else:\n",
    "                    refk  = selected_functional + \"-\" + selected_basisset + \"_energydiff\"\n",
    "                    k = func + \"-\" + basis + \"_energydiff\"\n",
    "                    for k2 in val[k]:\n",
    "                        refk2 = k2.replace(basis, selected_basisset)\n",
    "                        refk2 = refk2.replace(func, selected_functional)\n",
    "                        newk2 = k2 + \"_difftoref\"\n",
    "                        if newk2 not in desciptors:\n",
    "                            desciptors[newk2] = [val[refk][refk2] - val[k][k2]]\n",
    "                        else:\n",
    "                            desciptors[newk2].append(val[refk][refk2] - val[k][k2])\n",
    "    models_results[setname].features = desciptors\n",
    "    #print(\"Descriptors for \", setname)\n",
    "    #for k in desciptors:\n",
    "    #    print(k, len(desciptors[k]), desciptors[k])\n",
    "\n",
    "# feastures selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    #print(\"Removing constant features for \", setname)\n",
    "    for k in toremove:\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "# test print for debug\n",
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "print(\"Removing Nuclear Repulsion difference\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"Nuclear_Repulsion_difftoref\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(commonutils)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "setname = \"Full\"\n",
    "print(\"Running PLS for dataset: \", setname)\n",
    "\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "setlist = models_results[setname].setnames  \n",
    "supersetlist = models_results[setname].supersetnames\n",
    "maxcomp = X.shape[1]\n",
    "ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp-8, split = False,\\\n",
    "          plot = True, loo=False)\n",
    "r2max_comps = np.argmax(r2s)+1\n",
    "rmsemin_comps = np.argmin(rmses)+1\n",
    "wtmadmin_comps = np.argmin(wtmads)+1\n",
    "#loormsemin_comps = np.argmin(loormses)+1\n",
    "print(\"Best number of components for       R2: %4d [%8.2f]\"%(\\\n",
    "      r2max_comps, r2s[r2max_comps-1]))\n",
    "print(\"Best number of components for     RMSE: %4d [%8.2f]\"%(\\\n",
    "      rmsemin_comps, rmses[rmsemin_comps-1]))\n",
    "print(\"Best number of components for    WTMAD: %4d [%8.2f]\"%(\\\n",
    "      wtmadmin_comps, wtmads[wtmadmin_comps-1]))\n",
    "#print(\"Best number of components for LOO RMSE: %4d [%8.2f]\"%(\\\n",
    "#      loormsemin_comps, loormses[loormsemin_comps-1]))\n",
    "#compstouse = min(r2max_comps, rmsemin_comps, wtmadmin_comps, loormsemin_comps)\n",
    "compstouse = min(r2max_comps, rmsemin_comps, wtmadmin_comps)\n",
    "print(\"Using \", compstouse, \" components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform features importance analysis\n",
    "setname = \"Full\"   \n",
    "print(\"Running PLS for dataset: \", setname)\n",
    "print(\"  Using \", compstouse, \" components\")\n",
    "X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "setlist = []\n",
    "for i, s in enumerate(models_results[setname].setnames):\n",
    "    ss = models_results[setname].supersetnames[i]\n",
    "    setlist.append(ss + \"_\" + s)\n",
    "\n",
    "plsmodel = PLSRegression(n_components=compstouse)\n",
    "plsmodel.fit(X, Y)\n",
    "y_pred = plsmodel.predict(X) \n",
    "   \n",
    "cv = LeaveOneOut()\n",
    "model = PLSRegression(n_components=compstouse)\n",
    "scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "r2 = r2_score(Y, y_pred)\n",
    "if len(y_pred.shape) == 2:\n",
    "    y_pred = y_pred[:,0]\n",
    "wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "wtmad = wtmadf[\"Full\"]\n",
    "print(\"      RMSE: %10.2f\"%rmse)\n",
    "print(\"        R2: %10.2f\"%r2)\n",
    "print(\"     WTMAD: %10.2f\"%wtmad)\n",
    "print(\"  LOO RMSE: %10.2f\"%loormse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_importante_features = []\n",
    "result = permutation_importance(plsmodel, X, Y, n_repeats=10, \\\n",
    "                                random_state=42, n_jobs=2)\n",
    "pfi_sorted_idx = result.importances_mean.argsort()\n",
    "#compute absolute values of the PLS coefficients\n",
    "coef = np.abs(plsmodel.coef_).flatten()\n",
    "#sort the coefficients\n",
    "sorted_idx = np.argsort(coef)\n",
    "\n",
    "# scatter plot of the most important features\n",
    "plt.clf()\n",
    "plt.rcParams['figure.figsize'] = 15,15\n",
    "fis = [np.mean(result.importances[i].T) for i in pfi_sorted_idx]\n",
    "cfs = [coef[i] for i in sorted_idx]\n",
    "plt.plot(cfs, fis, '-o', color='black')\n",
    "plt.xlabel(\"PLS coefficients\")\n",
    "plt.ylabel(\"Permutation importances\")\n",
    "plt.title(\"Most important features \" + setname)\n",
    "plt.show()\n",
    "\n",
    "# print the most important features\n",
    "print(\"Most important features\")\n",
    "for i in reversed(pfi_sorted_idx):\n",
    "    most_importante_features.append(features_names[i])\n",
    "    print(\"%60s\"%features_names[i], \\\n",
    "          \"%10.2f\"%coef[i], \\\n",
    "          \"%10.2f\"%np.mean(result.importances[i].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove corralted features \n",
    "CORRCUT = 0.95\n",
    "\n",
    "setname = \"Full\"\n",
    "touse = set()\n",
    "# add by default the selected FINAL_SINGLE_POINT_ENERGY\n",
    "touse.add(selected_functional + \"-\" + \\\n",
    "            selected_basisset + \"_\" + \\\n",
    "            \"FINAL_SINGLE_POINT_ENERGY\")\n",
    "toremove = set()\n",
    "df = pd.DataFrame(models_results[setname].features)\n",
    "corr = df.corr().abs()\n",
    "for feat1 in most_importante_features:\n",
    "    if feat1 not in toremove:\n",
    "        touse.add(feat1)\n",
    "        for idx, v in enumerate(corr[feat1]):\n",
    "            if v > CORRCUT:\n",
    "                feat2 = corr.columns[idx]\n",
    "                if feat2 != feat1:\n",
    "                    toremove.add(feat2)\n",
    "\n",
    "z = touse.intersection(toremove) \n",
    "if len(z) != 0:\n",
    "    print(\"Error in removing correlated features\")\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"Features to use\")\n",
    "for i, feat in enumerate(touse):\n",
    "    print(i+1 ,  \" - \" , feat)\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for k in touse:\n",
    "        models_results[setname].uncorrelated_features[k] = \\\n",
    "            deepcopy(models_results[setname].features[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    i = 1\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(i, \" - \", k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])\n",
    "#        i += 1\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "setname = \"Full\"\n",
    "df = pd.DataFrame(models_results[setname].uncorrelated_features)\n",
    "print(\"Correlation matrix\")\n",
    "plt.rcParams['figure.figsize'] = 60,60\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(df.corr().abs(), annot=True)\n",
    "#print(df.corr().abs())\n",
    "#sns.heatmap(df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "df = pd.DataFrame(models_results[\"Full\"].uncorrelated_features)\n",
    "vif = pd.DataFrame()\n",
    "#scale data before computing VIF\n",
    "df = df.apply(lambda x: (x - np.mean(x)) / np.std(x))\n",
    "vif[\"features\"] = df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "# histogram of VIF\n",
    "plt.clf()\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "sns.set(font_scale=1)\n",
    "sns.histplot(vif[\"VIF\"])\n",
    "plt.show()\n",
    "# mean and stdev of VIF\n",
    "print(\"VIF mean and stdev\")\n",
    "print(vif[\"VIF\"].mean(), vif[\"VIF\"].std())\n",
    "\n",
    "print(\"VIF\")\n",
    "for v in vif.values:\n",
    "    if v[1] > 160:\n",
    "        print(v[0], v[1])\n",
    "        for setname in fullsetnames:\n",
    "            if v[0] in models_results[setname].uncorrelated_features:\n",
    "                del models_results[setname].uncorrelated_features[v[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = \"Full\"\n",
    "print(\"Uncorrelated features \", len(models_results[setname].uncorrelated_features))\n",
    "df = pd.DataFrame(models_results[setname].uncorrelated_features)\n",
    "print(\"Correlation matrix\")\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(df.corr().abs(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(commonutils)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "comptuseperset = {}\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    comptuseperset[setname] = 0\n",
    "\n",
    "perc_split = 0.2\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "   print(\"Running PLS for dataset: \", setname)\n",
    "\n",
    "   X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "              models_results[setname].labels)\n",
    "   setlist = models_results[setname].setnames\n",
    "   supersetlist = models_results[setname].supersetnames\n",
    "   maxcomp = X.shape[1]\n",
    "   ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp, split = False,\\\n",
    "          plot = True)\n",
    "   r2max_comps = np.argmax(r2s)+1\n",
    "   rmsemin_comps = np.argmin(rmses)+1\n",
    "   wtmadmin_comps = np.argmin(wtmads)+1\n",
    "   loormsemin_comps = np.argmin(loormses)+1\n",
    "   print(\"Best number of components for       R2: %4d [%8.2f]\"%(\\\n",
    "      r2max_comps, r2s[r2max_comps-1]))\n",
    "   print(\"Best number of components for     RMSE: %4d [%8.2f]\"%(\\\n",
    "      rmsemin_comps, rmses[rmsemin_comps-1]))\n",
    "   print(\"Best number of components for    WTMAD: %4d [%8.2f]\"%(\\\n",
    "      wtmadmin_comps, wtmads[wtmadmin_comps-1]))\n",
    "   print(\"Best number of components for LOO RMSE: %4d [%8.2f]\"%(\\\n",
    "      loormsemin_comps, loormses[loormsemin_comps-1]))\n",
    "\n",
    "   compstouse = wtmadmin_comps\n",
    "   comptuseperset[setname] = compstouse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select components to use\n",
    "comptuseperset[\"BARRIER_HEIGHTS\"] = 14\n",
    "comptuseperset[\"INTRAMOLECULAR_INTERACTIONS\"] = 15\n",
    "comptuseperset[\"SMALL_MOLECULES\"] = 15\n",
    "comptuseperset[\"INTERMOLECULAR_INTERACTIONS\"] = 16\n",
    "comptuseperset[\"LARGE_SYSTEMS\"] = 16\n",
    "comptuseperset[\"Full\"] = 15\n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "   print(\"Running PLS for dataset: \", setname)\n",
    "   print(\"  Using \", comptuseperset[setname], \" components\")\n",
    "   compstouse = comptuseperset[setname]\n",
    "   X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "              models_results[setname].labels)\n",
    "   setlist = models_results[setname].setnames\n",
    "   models_results[setname].plsmodel = PLSRegression(n_components=compstouse)\n",
    "   models_results[setname].plsmodel.fit(X, Y)\n",
    "   models_results[setname].y_pred = \\\n",
    "      models_results[setname].plsmodel.predict(X) \n",
    "   \n",
    "   cv = LeaveOneOut()\n",
    "   model = PLSRegression(n_components=compstouse)\n",
    "   scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "   loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "   rmse = mean_squared_error(Y, models_results[setname].y_pred, squared=False)\n",
    "   r2 = r2_score(Y, models_results[setname].y_pred)\n",
    "   y_pred = models_results[setname].y_pred\n",
    "   if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred[:,0]\n",
    "   wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "   wtmad = wtmadf[setname]\n",
    "   print(\"      RMSE: %10.2f\"%rmse)\n",
    "   print(\"        R2: %10.2f\"%r2)\n",
    "   print(\"     WTMAD: %10.2f\"%wtmad)\n",
    "   print(\"  LOO RMSE: %10.2f\"%loormse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" Dim , %40s\"% \"Dataset\", \" , \", \\\n",
    "      \"Best inside method RMSE\", \" , \", \\\n",
    "      \"Best our method RMSE\", \" , \", \\\n",
    "      \"RMSE (superset) ,\" + \\\n",
    "      \"RMSE (Full)\")\n",
    "pls_model_full = models_results[\"Full\"].plsmodel\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results[\"Full\"].uncorrelated_features, \\\n",
    "                                    models_results[\"Full\"].labels)\n",
    "y_pred = pls_model_full.predict(X)\n",
    "rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "r2 = r2_score(Y, y_pred)\n",
    "print(\"%4d , %40s\"%(len(models_results[\"Full\"].labels), \"Full\"), \" , \", \\\n",
    "    \"%7.3f\"%models_results[\"Full\"].bestinsidemethod_rmse, \" , \", \\\n",
    "    \"%7.3f\"%models_results[\"Full\"].bestourmethod_rmse, \" , \", \\\n",
    "    \"%7.3f\"%rmse, \" , \", \\\n",
    "    \"%7.3f\"%rmse)\n",
    "\n",
    "for ssetname in supersetnames:\n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[ssetname].uncorrelated_features, \\\n",
    "                                    models_results[ssetname].labels)\n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "\n",
    "    y_pred_full = pls_model_full.predict(X) \n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "\n",
    "    print(\"%4d , %40s\"%(len(models_results[ssetname].labels), ssetname), \" , \", \\\n",
    "        \"%7.3f\"%models_results[ssetname].bestinsidemethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%models_results[ssetname].bestourmethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%rmse, \" , \", \\\n",
    "        \"%7.3f\"%rmse_full)\n",
    "    \n",
    "    for isetname in supersetnames[ssetname]:\n",
    "        setname = ssetname + \"_\" + isetname \n",
    "        X, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "\n",
    "        y_pred_ssetname = pls_model_ssetname.predict(X)\n",
    "        rmse_ssetname = mean_squared_error(Y, y_pred_ssetname, squared=False)\n",
    "\n",
    "        y_pred_full = pls_model_full.predict(X)\n",
    "        rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "\n",
    "        print(\"%4d , %40s\"%(len(models_results[setname].labels), setname), \" , \", \\\n",
    "            \"%7.3f\"%models_results[setname].bestinsidemethod_rmse, \" , \", \\\n",
    "            \"%7.3f\"%models_results[setname].bestourmethod_rmse, \" , \", \\\n",
    "            \"%7.3f\"%rmse_ssetname, \" , \", \\\n",
    "            \"%7.3f\"%rmse_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = \"Full\"\n",
    "pls_model_full = models_results[setname].plsmodel\n",
    "printonlysuperset = True\n",
    "setnametouse = deepcopy(fullsetnames)\n",
    "setnametouse.remove(\"Full\")\n",
    "\n",
    "ypredFull = []\n",
    "setnamesFull = []\n",
    "\n",
    "for setname in setnametouse:\n",
    "    if setname in supersetnames:\n",
    "        ssetname = setname  \n",
    "    else:    \n",
    "        lastunder = setname.rfind(\"_\")\n",
    "        ssetname = setname[:lastunder]\n",
    "    \n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    setlist = models_results[setname].setnames\n",
    "    y_pred_full = pls_model_full.predict(X)\n",
    "    if len(y_pred_full.shape) == 2:\n",
    "        y_pred_full = y_pred_full[:,0]\n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "\n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    \n",
    "    if setname in supersetnames:\n",
    "        ypredFull.extend(list(y_pred))\n",
    "        setnamesFull.extend(setlist)\n",
    "        print(\"Results for \", setname, \" dim: \", len(Y))\n",
    "        wtmad2df = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "        wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "        wtmad2 = wtmad2df[setname]\n",
    "        wtmad2_full = wtmad2_fulldf[setname]\n",
    "        print(\"WTAMD2     (PLS ssetname) %7.3f\"%wtmad2)\n",
    "        print(\"WTAMD2         (PLS Full) %7.3f\"%wtmad2_full)\n",
    "        print(\"WTAMD2 (bestinsidemethod) %7.3f\"%models_results[setname].bestinsidemethod_wtmad) \n",
    "        print(\"WTAMD2    (bestourmethod) %7.3f\"%models_results[setname].bestourmethod_wtmad)\n",
    "        \n",
    "    if printonlysuperset and setname not in list(supersetnames.keys()) + [\"Full\"]:\n",
    "        continue\n",
    "\n",
    "    print(\"RMSE       (PLS ssetname) %7.3f\"%rmse)\n",
    "    print(\"RMSE           (PLS Full) %7.3f\"%rmse_full,)\n",
    "    print(\"RMSE   (bestinsidemethod) %7.3f\"%models_results[setname].bestinsidemethod_rmse)\n",
    "    print(\"RMSE      (bestourmethod) %7.3f\"%models_results[setname].bestourmethod_rmse)\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 10,10\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(Y, models_results[setname].y_pred_bestourmethod_rmse, \\\n",
    "               c='g', s=50, label='Best our method')\n",
    "    ax.scatter(Y, y_pred_full, c='r', s=50, label='PLS full model')\n",
    "    ax.scatter(Y, y_pred, c='b', s=50, label='PLS ssetname model')\n",
    "    #ax.scatter(Y, models_results[setname].y_pred_bestinsidemethod, \\\n",
    "    #            c='r', s=50, label='Best inside method')\n",
    "\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(setname)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Results for Full sim \", len(ypredFull))\n",
    "X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[\"Full\"].uncorrelated_features, \\\n",
    "                                    models_results[\"Full\"].labels)\n",
    "setlist = models_results[\"Full\"].setnames\n",
    "wtmad2df = commonutils.wtmad2(setnamesFull, Y, ypredFull)\n",
    "wtmad2 = wtmad2df[\"Full\"]\n",
    "rmse = mean_squared_error(Y, ypredFull, squared=False)\n",
    "\n",
    "y_pred_full = pls_model_full.predict(X)\n",
    "if len(y_pred_full.shape) == 2:\n",
    "    y_pred_full = y_pred_full[:,0]\n",
    "rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "wtmad2_full = wtmad2_fulldf[\"Full\"]\n",
    "\n",
    "print(\"WTAMD2     (PLS ssetname) %7.3f\"%wtmad2)\n",
    "print(\"WTAMD2         (PLS Full) %7.3f\"%wtmad2_full)\n",
    "print(\"WTAMD2 (bestinsidemethod) %7.3f\"%models_results[\"Full\"].bestinsidemethod_wtmad)\n",
    "print(\"WTAMD2    (bestourmethod) %7.3f\"%models_results[\"Full\"].bestourmethod_wtmad)\n",
    "rmse = mean_squared_error(models_results[\"Full\"].labels, ypredFull, squared=False)\n",
    "print(\"RMSE       (PLS ssetname) %7.3f\"%rmse)\n",
    "print(\"RMSE           (PLS Full) %7.3f\"%rmse_full)\n",
    "print(\"RMSE   (bestinsidemethod) %7.3f\"%models_results[\"Full\"].bestinsidemethod_rmse)\n",
    "print(\"RMSE      (bestourmethod) %7.3f\"%models_results[\"Full\"].bestourmethod_rmse)\n",
    "\n",
    "plt.clf()\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y, y_pred_full, c='r', s=50, label='PLS full model')\n",
    "ax.scatter(Y, ypredFull, c='b', s=50, label='PLS ssetname model')\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"Full\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and dump PLS equations\n",
    "setname = \"Full\"\n",
    "pls_model_full = models_results[setname].plsmodel\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    print(\"Equations for dataset: \", setname)\n",
    "    ssetname = \"Full\"\n",
    "    if setname in supersetnames or setname == \"Full\":\n",
    "        ssetname = setname  \n",
    "    else:    \n",
    "        lastunder = setname.rfind(\"_\")\n",
    "        ssetname = setname[:lastunder]\n",
    "    \n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    \n",
    "    y_pred_full = pls_model_full.predict(X)\n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "    r2_full = r2_score(Y, y_pred_full)\n",
    "    X_e = X.copy()\n",
    "    X_e -= pls_model_full._x_mean\n",
    "    X_e /= pls_model_full._x_std\n",
    "    y_pred_full_e = np.dot(X_e, pls_model_full.coef_.T)\n",
    "    y_pred_full_e += pls_model_full._y_mean\n",
    "    rmse_full_e = mean_squared_error(Y, y_pred_full_e, squared=False)\n",
    "    print(\"   Full dataset equations Y mean %7.3f\"%pls_model_full._y_mean)\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f [%15.3f %15.3f]\"%(f, \\\n",
    "            pls_model_full.coef_.T[i],\n",
    "            pls_model_full._x_mean[i], \n",
    "            pls_model_full._x_std[i]))\n",
    "\n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    r2 = r2_score(Y, y_pred)\n",
    "    X_e = X.copy()\n",
    "    X_e -= pls_model_ssetname._x_mean\n",
    "    X_e /= pls_model_ssetname._x_std\n",
    "    y_pred_e = np.dot(X_e, pls_model_ssetname.coef_.T)\n",
    "    y_pred_e += pls_model_ssetname._y_mean\n",
    "    rmse_e = mean_squared_error(Y, y_pred_e, squared=False)\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f [%15.3f %15.3f]\"%(f, \\\n",
    "            pls_model_ssetname.coef_.T[i],\n",
    "            pls_model_ssetname._x_mean[i], \n",
    "            pls_model_ssetname._x_std[i]))\n",
    "\n",
    "    print()\n",
    "    print(\"RMSE         (ssetname) %7.3f from eq. %7.3f diff []\"%(rmse, rmse_e))\n",
    "    print(\"RMSE             (Full) %7.3f from eq. %7.3f diff []\"%(rmse_full, rmse_full_e))  \n",
    "    print(\"RMSE (bestinsidemethod) %7.3f\"%models_results[setname].bestinsidemethod_rmse)\n",
    "    print(\"RMSE    (bestourmethod) %7.3f\"%models_results[setname].bestourmethod_rmse)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform features importance analysis\n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    model = models_results[setname].plsmodel\n",
    "    result = permutation_importance(model, X, Y, n_repeats=10, \\\n",
    "                                random_state=42, n_jobs=2)\n",
    "    pfi_sorted_idx = result.importances_mean.argsort()\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 15,15\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(result.importances[pfi_sorted_idx].T, vert=False, \\\n",
    "               labels=np.array(features_names)[pfi_sorted_idx])\n",
    "    ax.set_title(\"Permutation Importances \" + setname)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #compute absolute values of the PLS coefficients\n",
    "    coef = np.abs(model.coef_).flatten()\n",
    "    #sort the coefficients\n",
    "    sorted_idx = np.argsort(coef)\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 15,15\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(np.array(features_names)[sorted_idx], \\\n",
    "            coef[sorted_idx])\n",
    "    ax.set_title(\"PLS coefficients \" + setname)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # scatter plot of the most important features\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 15,15\n",
    "    fis = [np.mean(result.importances[i].T) for i in pfi_sorted_idx]\n",
    "    cfs = [coef[i] for i in sorted_idx]\n",
    "    plt.plot(cfs, fis, '-o', color='black')\n",
    "    plt.xlabel(\"PLS coefficients\")\n",
    "    plt.ylabel(\"Permutation importances\")\n",
    "    plt.title(\"Most important features \" + setname)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
