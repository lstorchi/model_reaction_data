{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"./data/allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"./data/methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"./data/fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"./data/functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"./data/basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"./data/supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug purposes\n",
    "#for val in allvalues_perset:\n",
    "#    print(\"======= START =======\")\n",
    "#    print(val, len(allvalues_perset[val]))\n",
    "#    pp.pprint(allvalues_perset[val])\n",
    "#    print(\"=======  END  =======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(commonutils)\n",
    "\n",
    "from commonutils import ModelResults\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "insidemethods = [\"W\",\"D3(0)\",\"D3(BJ)\"]\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        wtmad = None\n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestinsidemethod_wtmad:\n",
    "                models_results[setname].bestinsidemethod_wtmad = wtmad\n",
    "                models_results[setname].bestinsidemethod_name_wtmad = insidemethods[methodid]\n",
    "                models_results[setname].y_pred_bestinsidemethod_wtmad = y_pred\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestinsidemethod_rmse:\n",
    "            models_results[setname].bestinsidemethod_rmse = rmse\n",
    "            models_results[setname].bestinsidemethod_name_rmse = insidemethods[methodid]\n",
    "            models_results[setname].y_pred_bestinsidemethod_rmse = y_pred\n",
    "\n",
    "    for j, method in enumerate(methods):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        wtmad = None            \n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestourmethod_wtmad:\n",
    "                models_results[setname].bestourmethod_wtmad = wtmad\n",
    "                models_results[setname].bestourmethod_name_wtmad = method\n",
    "                models_results[setname].y_pred_bestourmethod_wtmad = y_pred\n",
    "        \n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestourmethod_rmse:\n",
    "            models_results[setname].bestourmethod_rmse = rmse\n",
    "            models_results[setname].bestourmethod_name_rmse = method\n",
    "            models_results[setname].y_pred_bestourmethod_rmse = y_pred\n",
    "\n",
    "bestmnethodscount = {}\n",
    "setofbestourmethodswtamd = {}\n",
    "\n",
    "print(\"Results for inside and our methods\")\n",
    "print(\"%40s\"% \"Dataset\", \" , \", \\\n",
    "    \"Best inside method RMSE\", \" , \", \\\n",
    "    \"RMSE\", \" , \", \\\n",
    "    \"Best inside method WTMAD2\", \" , \", \\\n",
    "    \"WTMAD2\", \" , \", \\\n",
    "    \"Best our method RMSE\", \" , \", \\\n",
    "    \"RMSE\", \" , \", \\\n",
    "    \"Best our method WTMAD2\", \" , \", \\\n",
    "    \"WTMAD2\")\n",
    "for setname in fullsetnames:\n",
    "    if models_results[setname].bestourmethod_name_rmse in bestmnethodscount:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] += 1\n",
    "    else:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] = 1\n",
    "\n",
    "    if models_results[setname].bestourmethod_name_wtmad != \"\":\n",
    "        if models_results[setname].bestourmethod_name_wtmad in setofbestourmethodswtamd:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] += 1\n",
    "        else:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] = 1\n",
    "          \n",
    "    print(\"%40s\"%setname, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestinsidemethod_name_rmse , \" , \",\\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_rmse, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestinsidemethod_name_wtmad , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_wtmad, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestourmethod_name_rmse , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_rmse, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestourmethod_name_wtmad , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_wtmad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RMSE\")\n",
    "for method in bestmnethodscount:\n",
    "    print(\"Best our method \", method, \" count: \", bestmnethodscount[method])\n",
    "\n",
    "print()\n",
    "print(\"WTMAD2\")\n",
    "for method in setofbestourmethodswtamd:\n",
    "    print(\"Best our method \", method, \" count: \", setofbestourmethodswtamd[method])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and generate equations\n",
    "basicfeattouse = [\"Potential_Energy\", \\\n",
    "                \"Kinetic_Energy\", \\\n",
    "                \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "                \"Dispersion_correction\", \\\n",
    "                \"E(C)\", \\\n",
    "                \"E(X)\", \\\n",
    "                \"Two_Electron_Energy\", \\\n",
    "                \"Nuclear_Repulsion\", \\\n",
    "                \"One_Electron_Energy\"]\n",
    "\n",
    "featuresvalues_perset = {}\n",
    "for setname in fullsetnames:\n",
    "    featuresvalues_perset [setname] = []\n",
    "    for val in allvalues_perset[setname]:\n",
    "        featuresvalues_perset[setname].append({})\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                torm = k.replace(\"energydiff\", \"\")\n",
    "                for f in val[k]:\n",
    "                    tocheck = f.replace(torm, \"\")\n",
    "                    if tocheck in basicfeattouse:\n",
    "                        keytouse = f.replace(\"-\", \"_\")\n",
    "                        keytouse = keytouse.replace(\"(\", \"\")\n",
    "                        keytouse = keytouse.replace(\")\", \"\")\n",
    "                        featuresvalues_perset[setname][-1][keytouse] = val[k][f]\n",
    "\n",
    "# for debug purposes\n",
    "#for val in featuresvalues_perset:\n",
    "#    print(\"======= START =======\")\n",
    "#    print(val, len(featuresvalues_perset[val]))\n",
    "#    pp.pprint(featuresvalues_perset[val])\n",
    "#    print(\"=======  END  =======\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equations = {\"EQ1\" :\"power(FINAL_SINGLE_POINT_ENERGY, 2) + multiply(Dispersion_correction, 2)\", \\\n",
    "             \"EQ1\" : \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "             \"EQ2\" : \"One_Electron_Energy + Two_Electron_Energy + Dispersion_correction + Nuclear_Repulsion\", \\\n",
    "             \"EQ3\" : \"multiply(Potential_Energy, Dispersion_correction)\", \\\n",
    "             \"EQ4\" : \"Nuclear_Repulsion\"}\n",
    "\n",
    "equations = {\"EC\" :\"EC\" , \\\n",
    "            \"EX\" : \"EX\", \\\n",
    "            \"FSPE\" : \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "            \"DC\" : \"Dispersion_correction\", \\\n",
    "            \"PE\" : \"Potential_Energy\", \\\n",
    "            \"KE\" : \"Kinetic_Energy\", \\\n",
    "            \"OEE\" : \"One_Electron_Energy\", \\\n",
    "            \"TEE\" : \"Two_Electron_Energy\", \\\n",
    "            \"NR\" : \"Nuclear_Repulsion\"}\n",
    "\n",
    "# FINAL_SINGLE_POINT_ENERGY = \n",
    "# 1 - Kinetic_Energy+(One_Electron_Energy-Kinetic_Energy) + EX + EC \n",
    "# 2 - (Two_Electron_Energy-EX-EC) + Dispersion_correction+ Nuclear_Repulsion\n",
    "# 3 -One_Electron_Energy + Two_Electron_Energy + Dispersion_correction + Nuclear_Repulsion\"\n",
    "# 4 - Kinetic_Energy + Potential_Energy + Dispersion_correction\n",
    "\n",
    "eq_featuresvalues_perset = \\\n",
    "    commonutils.equation_parser_compiler(equations, functionals, basis_sets, basicfeattouse, \\\n",
    "                              featuresvalues_perset)\n",
    "\n",
    "# for debug purposes\n",
    "#for setname in featuresvalues_perset:\n",
    "#    print(\"Equations for \", setname , \" set \", len(featuresvalues_perset[setname]))\n",
    "#    pp.pprint(eq_featuresvalues_perset[setname])\n",
    "\n",
    "featuresvalues_perset = deepcopy(eq_featuresvalues_perset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build descriptors \n",
    "# functionals = [\"PBE\", \"PBE0\", \"TPSS\", \"TPSSh\"]\n",
    "# basis_sets = ['MINIX', 'SVP', 'TZVP']\n",
    "# basicfeattouse = [\"Potential_Energy\", \\\n",
    "#                 \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "#                 \"Kinetic_Energy\", \\\n",
    "#                 \"Dispersion_correction\", \\\n",
    "#                 \"E(C)\", \\\n",
    "#                 \"E(X)\", \\\n",
    "#                 \"Two_Electron_Energy\", \\\n",
    "#                 \"Nuclear_Repulsion\", \\\n",
    "#                 \"One_Electron_Energy\"]\n",
    "selected_basisset = \"TZVP\"\n",
    "selected_functional = \"PBE0\"\n",
    "functionals = [\"PBE0\"]\n",
    "basis_sets = ['SVP']\n",
    "\n",
    "sep = \"_\"\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    k = selected_functional + sep + \\\n",
    "            selected_basisset \n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            if val.find(k) != -1:\n",
    "                if val not in desciptors:\n",
    "                    desciptors[val] = [features[val]]\n",
    "                else:\n",
    "                    desciptors[val].append(features[val])\n",
    "\n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            for func in functionals:\n",
    "                for basis in basis_sets:\n",
    "                    if not(basis == selected_basisset and \\\n",
    "                           func == selected_functional):\n",
    "                        if val.find(func + sep + basis) != -1:\n",
    "                            actualk = val \n",
    "                            refk  = selected_functional + sep  + selected_basisset + \\\n",
    "                                val.replace(func + sep + basis, \"\")\n",
    "                            newk = actualk + \"_difftoref\"\n",
    "                            if newk not in desciptors:\n",
    "                                desciptors[newk] = [features[actualk]-features[refk]]\n",
    "                            else:\n",
    "                                desciptors[newk].append(features[actualk]-features[refk])\n",
    "    \n",
    "    models_results[setname].features = desciptors\n",
    "    #print(\"Descriptors for \", setname)\n",
    "    #for k in desciptors:\n",
    "    #    print(k, len(desciptors[k]), desciptors[k])\n",
    "\n",
    "# feastures selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    #print(\"Removing constant features for \", setname)\n",
    "    for k in toremove:\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "# test print for debug\n",
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "print(\"Removing Nuclear Repulsion difference\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"NR\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(commonutils)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "setname = \"Full\"\n",
    "print(\"Running PLS for dataset: \", setname)\n",
    "\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "setlist = models_results[setname].setnames  \n",
    "supersetlist = models_results[setname].supersetnames\n",
    "maxcomp = X.shape[1]\n",
    "ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp-8, split = False,\\\n",
    "          plot = True, loo=False)\n",
    "r2max_comps = np.argmax(r2s)+1\n",
    "rmsemin_comps = np.argmin(rmses)+1\n",
    "wtmadmin_comps = np.argmin(wtmads)+1\n",
    "#loormsemin_comps = np.argmin(loormses)+1\n",
    "print(\"Best number of components for       R2: %4d [%8.2f]\"%(\\\n",
    "      r2max_comps, r2s[r2max_comps-1]))\n",
    "print(\"Best number of components for     RMSE: %4d [%8.2f]\"%(\\\n",
    "      rmsemin_comps, rmses[rmsemin_comps-1]))\n",
    "print(\"Best number of components for    WTMAD: %4d [%8.2f]\"%(\\\n",
    "      wtmadmin_comps, wtmads[wtmadmin_comps-1]))\n",
    "#print(\"Best number of components for LOO RMSE: %4d [%8.2f]\"%(\\\n",
    "#      loormsemin_comps, loormses[loormsemin_comps-1]))\n",
    "#compstouse = min(r2max_comps, rmsemin_comps, wtmadmin_comps, loormsemin_comps)\n",
    "compstouse = min(r2max_comps, rmsemin_comps, wtmadmin_comps)\n",
    "print(\"Using \", compstouse, \" components\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform features importance analysis\n",
    "setname = \"Full\"   \n",
    "print(\"Running PLS for dataset: \", setname)\n",
    "print(\"  Using \", compstouse, \" components\")\n",
    "X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "setlist = []\n",
    "for i, s in enumerate(models_results[setname].setnames):\n",
    "    ss = models_results[setname].supersetnames[i]\n",
    "    setlist.append(ss + \"_\" + s)\n",
    "\n",
    "plsmodel = PLSRegression(n_components=compstouse)\n",
    "plsmodel.fit(X, Y)\n",
    "y_pred = plsmodel.predict(X) \n",
    "   \n",
    "cv = LeaveOneOut()\n",
    "model = PLSRegression(n_components=compstouse)\n",
    "scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "r2 = r2_score(Y, y_pred)\n",
    "if len(y_pred.shape) == 2:\n",
    "    y_pred = y_pred[:,0]\n",
    "wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "wtmad = wtmadf[\"Full\"]\n",
    "print(\"      RMSE: %10.2f\"%rmse)\n",
    "print(\"        R2: %10.2f\"%r2)\n",
    "print(\"     WTMAD: %10.2f\"%wtmad)\n",
    "print(\"  LOO RMSE: %10.2f\"%loormse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_importante_features = []\n",
    "result = permutation_importance(plsmodel, X, Y, n_repeats=10, \\\n",
    "                                random_state=42, n_jobs=2)\n",
    "pfi_sorted_idx = result.importances_mean.argsort()\n",
    "#compute absolute values of the PLS coefficients\n",
    "coef = np.abs(plsmodel.coef_).flatten()\n",
    "#sort the coefficients\n",
    "sorted_idx = np.argsort(coef)\n",
    "\n",
    "# scatter plot of the most important features\n",
    "plt.clf()\n",
    "plt.rcParams['figure.figsize'] = 15,15\n",
    "fis = [np.mean(result.importances[i].T) for i in pfi_sorted_idx]\n",
    "cfs = [coef[i] for i in sorted_idx]\n",
    "plt.plot(cfs, fis, '-o', color='black')\n",
    "plt.xlabel(\"PLS coefficients\")\n",
    "plt.ylabel(\"Permutation importances\")\n",
    "plt.title(\"Most important features \" + setname)\n",
    "plt.show()\n",
    "\n",
    "# print the most important features\n",
    "print(\"Most important features\")\n",
    "for i in reversed(pfi_sorted_idx):\n",
    "    most_importante_features.append(features_names[i])\n",
    "    print(\"%60s\"%features_names[i], \\\n",
    "          \"%10.2f\"%coef[i], \\\n",
    "          \"%10.2f\"%np.mean(result.importances[i].T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove corralted features \n",
    "CORRCUT = 0.95\n",
    "\n",
    "setname = \"Full\"\n",
    "touse = set()\n",
    "# add by default the selected FINAL_SINGLE_POINT_ENERGY\n",
    "#touse.add(selected_functional + \"-\" + \\\n",
    "#            selected_basisset + \"_\" + \\\n",
    "#            \"FINAL_SINGLE_POINT_ENERGY\")\n",
    "toremove = set()\n",
    "df = pd.DataFrame(models_results[setname].features)\n",
    "corr = df.corr().abs()\n",
    "for feat1 in most_importante_features:\n",
    "    print(\"Checking feature \", feat1)\n",
    "    if feat1 not in toremove:\n",
    "        touse.add(feat1)\n",
    "        print(\"  Adding feature \", feat1)\n",
    "        for idx, v in enumerate(corr[feat1]):\n",
    "            if v > CORRCUT:\n",
    "                feat2 = corr.columns[idx]\n",
    "                if feat2 != feat1:\n",
    "                    print(\"    Correlated with \", feat2, \" \", v)\n",
    "                    toremove.add(feat2)\n",
    "                    print(\"      Removing feature \", feat2)\n",
    "\n",
    "z = touse.intersection(toremove) \n",
    "if len(z) != 0:\n",
    "    print(\"Error in removing correlated features\")\n",
    "    print(\"z = \", z)\n",
    "    sys.exit(1)\n",
    "    \n",
    "print(\"Features to use\")\n",
    "for i, feat in enumerate(touse):\n",
    "    print(i+1 ,  \" - \" , feat)\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for k in touse:\n",
    "        models_results[setname].uncorrelated_features[k] = \\\n",
    "            deepcopy(models_results[setname].features[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    i = 1\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(i, \" - \", k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])\n",
    "#        i += 1\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "setname = \"Full\"\n",
    "df = pd.DataFrame(models_results[setname].uncorrelated_features)\n",
    "print(\"Correlation matrix\")\n",
    "plt.rcParams['figure.figsize'] = 60,60\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(df.corr().abs(), annot=True)\n",
    "#print(df.corr().abs())\n",
    "#sns.heatmap(df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "\n",
    "df = pd.DataFrame(models_results[\"Full\"].uncorrelated_features)\n",
    "vif = pd.DataFrame()\n",
    "#scale data before computing VIF\n",
    "df = df.apply(lambda x: (x - np.mean(x)) / np.std(x))\n",
    "vif[\"features\"] = df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "# histogram of VIF\n",
    "#plt.clf()\n",
    "#plt.rcParams['figure.figsize'] = 10,10\n",
    "#sns.set(font_scale=1)\n",
    "#sns.histplot(vif[\"VIF\"])\n",
    "#plt.show()\n",
    "# mean and stdev of VIF\n",
    "print(\"VIF mean and stdev\")\n",
    "print(vif[\"VIF\"].mean(), vif[\"VIF\"].std())\n",
    "\n",
    "print(\"VIF\")\n",
    "for v in vif.values:\n",
    "    if v[1] > 160:\n",
    "        print(v[0], v[1])\n",
    "        for setname in fullsetnames:\n",
    "            if v[0] in models_results[setname].uncorrelated_features:\n",
    "                del models_results[setname].uncorrelated_features[v[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setname in fullsetnames:\n",
    "    print(\"Check Descriptors for \", setname)\n",
    "    i = 1\n",
    "    descset = set()\n",
    "    for k in models_results[setname].uncorrelated_features:\n",
    "        descset.add(k)\n",
    "    if len(descset) != len(models_results[setname].uncorrelated_features):\n",
    "        print(i, \" - \", k, len(models_results[setname].uncorrelated_features[k]), \\\n",
    "           models_results[setname].uncorrelated_features[k])\n",
    "        i += 1\n",
    "        sys.exit(1)\n",
    "\n",
    "setname = \"Full\"\n",
    "print(\"Uncorrelated features \", len(models_results[setname].uncorrelated_features))\n",
    "df = pd.DataFrame(models_results[setname].uncorrelated_features)\n",
    "print(\"Correlation matrix\")\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(df.corr().abs(), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(commonutils)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "comptuseperset = {}\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    comptuseperset[setname] = 0\n",
    "\n",
    "perc_split = 0.2\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "   print(\"Running PLS for dataset: \", setname)\n",
    "\n",
    "   X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "              models_results[setname].labels)\n",
    "   setlist = models_results[setname].setnames\n",
    "   supersetlist = models_results[setname].supersetnames\n",
    "   maxcomp = X.shape[1]\n",
    "   ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp, split = False,\\\n",
    "          plot = True)\n",
    "   r2max_comps = np.argmax(r2s)+1\n",
    "   rmsemin_comps = np.argmin(rmses)+1\n",
    "   wtmadmin_comps = np.argmin(wtmads)+1\n",
    "   loormsemin_comps = np.argmin(loormses)+1\n",
    "   print(\"Best number of components for       R2: %4d [%8.2f]\"%(\\\n",
    "      r2max_comps, r2s[r2max_comps-1]))\n",
    "   print(\"Best number of components for     RMSE: %4d [%8.2f]\"%(\\\n",
    "      rmsemin_comps, rmses[rmsemin_comps-1]))\n",
    "   print(\"Best number of components for    WTMAD: %4d [%8.2f]\"%(\\\n",
    "      wtmadmin_comps, wtmads[wtmadmin_comps-1]))\n",
    "   print(\"Best number of components for LOO RMSE: %4d [%8.2f]\"%(\\\n",
    "      loormsemin_comps, loormses[loormsemin_comps-1]))\n",
    "\n",
    "   compstouse = wtmadmin_comps\n",
    "   comptuseperset[setname] = compstouse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select components to use\n",
    "#comptuseperset[\"BARRIER_HEIGHTS\"] = 14\n",
    "#comptuseperset[\"INTRAMOLECULAR_INTERACTIONS\"] = 15\n",
    "#comptuseperset[\"SMALL_MOLECULES\"] = 15\n",
    "#comptuseperset[\"INTERMOLECULAR_INTERACTIONS\"] = 16\n",
    "#comptuseperset[\"LARGE_SYSTEMS\"] = 16\n",
    "#comptuseperset[\"Full\"] = 15\n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "   print(\"Running PLS for dataset: \", setname)\n",
    "   print(\"  Using \", comptuseperset[setname], \" components\")\n",
    "   compstouse = comptuseperset[setname]\n",
    "   X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "              models_results[setname].labels)\n",
    "   setlist = models_results[setname].setnames\n",
    "   models_results[setname].plsmodel = PLSRegression(n_components=compstouse)\n",
    "   models_results[setname].plsmodel.fit(X, Y)\n",
    "   models_results[setname].y_pred = \\\n",
    "      models_results[setname].plsmodel.predict(X) \n",
    "   \n",
    "   cv = LeaveOneOut()\n",
    "   model = PLSRegression(n_components=compstouse)\n",
    "   scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "   loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "   rmse = mean_squared_error(Y, models_results[setname].y_pred, squared=False)\n",
    "   r2 = r2_score(Y, models_results[setname].y_pred)\n",
    "   y_pred = models_results[setname].y_pred\n",
    "   if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred[:,0]\n",
    "   wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "   wtmad = wtmadf[setname]\n",
    "   print(\"      RMSE: %10.2f\"%rmse)\n",
    "   print(\"        R2: %10.2f\"%r2)\n",
    "   print(\"     WTMAD: %10.2f\"%wtmad)\n",
    "   print(\"  LOO RMSE: %10.2f\"%loormse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gere compute LR and LR custom \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "sys.path.append(\"./CLossLr\")\n",
    "import customlosslr as clr\n",
    "\n",
    "\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    print(\"Running LR for dataset: \", setname)\n",
    "\n",
    "    setlist = models_results[setname].setnames\n",
    "    supersetlist = models_results[setname].supersetnames\n",
    "    \n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "              models_results[setname].labels)\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X, Y)\n",
    "\n",
    "    models_results[setname].lr_model = lm\n",
    "\n",
    "    clm = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    clm.fit(X, Y)\n",
    "\n",
    "    models_results[setname].lr_custom_model = clm\n",
    "\n",
    "    y_pred_custom_lr = clm.predict(X)\n",
    "    y_pred_lr = lm.predict(X)\n",
    "\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_custom_lr)\n",
    "    wtmad_custom_lr = wtamd2[setname]\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_lr)\n",
    "    wtmad_lr = wtamd2[setname]\n",
    "\n",
    "    print(\"        Optimized final WTMAD2: %10.5f\"%(wtmad_custom_lr))\n",
    "    print(\"Linear Regression FINAL WTMAD2: %10.5f\"%(wtmad_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(\" Dim , %40s\"% \"Dataset\", \" , \", \\\n",
    "      \"Best inside method RMSE\", \" , \", \\\n",
    "      \"Best our method RMSE\", \" , \", \\\n",
    "      \"RMSE (superset) ,\" + \\\n",
    "      \"RMSE (Full)\")\n",
    "pls_model_full = models_results[\"Full\"].plsmodel\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results[\"Full\"].uncorrelated_features, \\\n",
    "                                    models_results[\"Full\"].labels)\n",
    "y_pred = pls_model_full.predict(X)\n",
    "rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "r2 = r2_score(Y, y_pred)\n",
    "print(\"%4d , %40s\"%(len(models_results[\"Full\"].labels), \"Full\"), \" , \", \\\n",
    "    \"%7.3f\"%models_results[\"Full\"].bestinsidemethod_rmse, \" , \", \\\n",
    "    \"%7.3f\"%models_results[\"Full\"].bestourmethod_rmse, \" , \", \\\n",
    "    \"%7.3f\"%rmse, \" , \", \\\n",
    "    \"%7.3f\"%rmse)\n",
    "\n",
    "for ssetname in supersetnames:\n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[ssetname].uncorrelated_features, \\\n",
    "                                    models_results[ssetname].labels)\n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "\n",
    "    y_pred_full = pls_model_full.predict(X) \n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "\n",
    "    print(\"%4d , %40s\"%(len(models_results[ssetname].labels), ssetname), \" , \", \\\n",
    "        \"%7.3f\"%models_results[ssetname].bestinsidemethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%models_results[ssetname].bestourmethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%rmse, \" , \", \\\n",
    "        \"%7.3f\"%rmse_full)\n",
    "    \n",
    "    for isetname in supersetnames[ssetname]:\n",
    "        setname = ssetname + \"_\" + isetname \n",
    "        X, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "\n",
    "        y_pred_ssetname = pls_model_ssetname.predict(X)\n",
    "        rmse_ssetname = mean_squared_error(Y, y_pred_ssetname, squared=False)\n",
    "\n",
    "        y_pred_full = pls_model_full.predict(X)\n",
    "        rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "\n",
    "        print(\"%4d , %40s\"%(len(models_results[setname].labels), setname), \" , \", \\\n",
    "            \"%7.3f\"%models_results[setname].bestinsidemethod_rmse, \" , \", \\\n",
    "            \"%7.3f\"%models_results[setname].bestourmethod_rmse, \" , \", \\\n",
    "            \"%7.3f\"%rmse_ssetname, \" , \", \\\n",
    "            \"%7.3f\"%rmse_full)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = \"Full\"\n",
    "pls_model_full = models_results[setname].plsmodel\n",
    "lr_model_full = models_results[setname].lr_model\n",
    "lr_custom_model_full = models_results[setname].lr_custom_model\n",
    "printonlysuperset = True\n",
    "setnametouse = deepcopy(fullsetnames)\n",
    "setnametouse.remove(\"Full\")\n",
    "\n",
    "ypredFull = []\n",
    "setnamesFull = []\n",
    "ypredFull_lr = []\n",
    "setnamesFull_lr = []\n",
    "ypredFull_lr_custom = []\n",
    "setnamesFull_lr_custom = []\n",
    "\n",
    "for setname in setnametouse:\n",
    "    if setname in supersetnames:\n",
    "        ssetname = setname  \n",
    "    else:    \n",
    "        lastunder = setname.rfind(\"_\")\n",
    "        ssetname = setname[:lastunder]\n",
    "    \n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    lr_model_ssetname = models_results[ssetname].lr_model\n",
    "    lr_custom_model_ssetname = models_results[ssetname].lr_custom_model\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    setlist = models_results[setname].setnames\n",
    "    \n",
    "    # PLS\n",
    "    y_pred_full = pls_model_full.predict(X)\n",
    "    if len(y_pred_full.shape) == 2:\n",
    "        y_pred_full = y_pred_full[:,0]\n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "\n",
    "    # LR    \n",
    "    y_pred_lr_full = lr_model_full.predict(X)\n",
    "    if len(y_pred_lr_full.shape) == 2:\n",
    "        y_pred_lr_full = y_pred_lr_full[:,0]\n",
    "    rmse_lr_full = mean_squared_error(Y, y_pred_lr_full, squared=False)\n",
    "    y_pred_lr = lr_model_ssetname.predict(X)\n",
    "    if len(y_pred_lr.shape) == 2:\n",
    "        y_pred_lr = y_pred_lr[:,0]\n",
    "    rmse_lr = mean_squared_error(Y, y_pred_lr, squared=False)\n",
    "\n",
    "    # CLR\n",
    "    y_pred_lr_custom_full = lr_custom_model_full.predict(X)\n",
    "    if len(y_pred_lr_custom_full.shape) == 2:\n",
    "        y_pred_lr_custom_full = y_pred_lr_custom_full[:,0]\n",
    "    rmse_lr_custom_full = mean_squared_error(Y, y_pred_lr_custom_full, squared=False)\n",
    "    y_pred_lr_custom = lr_custom_model_ssetname.predict(X)\n",
    "    if len(y_pred_lr_custom.shape) == 2:\n",
    "        y_pred_lr_custom = y_pred_lr_custom[:,0]\n",
    "    rmse_lr_custom = mean_squared_error(Y, y_pred_lr_custom, squared=False)\n",
    "\n",
    "    if setname in supersetnames:\n",
    "        ypredFull.extend(list(y_pred))\n",
    "        setnamesFull.extend(setlist)\n",
    "        ypredFull_lr.extend(list(y_pred_lr))\n",
    "        setnamesFull_lr.extend(setlist)\n",
    "        ypredFull_lr_custom.extend(list(y_pred_lr_custom))\n",
    "        setnamesFull_lr_custom.extend(setlist)\n",
    "\n",
    "        print(\"Results for \", setname, \" dim: \", len(Y))\n",
    "        wtmad2df = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "        wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "        wtmad2 = wtmad2df[setname]\n",
    "        wtmad2_full = wtmad2_fulldf[setname]\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(\"PLS Super Set\", wtmad2))\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(\"PLS Full\", wtmad2_full))\n",
    "        wtmad2df = commonutils.wtmad2(setlist, Y, y_pred_lr)\n",
    "        wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_lr_full)\n",
    "        wtmad2 = wtmad2df[setname]\n",
    "        wtmad2_full = wtmad2_fulldf[setname]\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Super Set\", wtmad2))\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Full\", wtmad2_full))\n",
    "        wtmad2df = commonutils.wtmad2(setlist, Y, y_pred_lr_custom)\n",
    "        wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_lr_custom_full)\n",
    "        wtmad2 = wtmad2df[setname]\n",
    "        wtmad2_full = wtmad2_fulldf[setname]\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Custom Super Set\", wtmad2))\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Custom Full\", wtmad2_full))        \n",
    "\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(models_results[setname].bestinsidemethod_name_wtmad, models_results[setname].bestinsidemethod_wtmad))\n",
    "        print(\"WTMAD2\",\"%20s,%7.3f\"%(models_results[setname].bestourmethod_name_wtmad, models_results[setname].bestourmethod_wtmad))\n",
    "        \n",
    "    if printonlysuperset and setname not in list(supersetnames.keys()) + [\"Full\"]:\n",
    "        continue\n",
    "\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(\"PLS Super Set\",rmse))\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(\"PLS Full\", rmse_full))\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(\"LR Super Set\",rmse_lr))\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(\"LR Full\", rmse_lr_full))\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(\"LR Custom Super Set\",rmse_lr_custom))\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(\"LR Custom Full\", rmse_lr_custom))\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(models_results[setname].bestinsidemethod_name_rmse, models_results[setname].bestinsidemethod_rmse))\n",
    "    print(\"RMSE  \",\"%20s,%7.3f\"%(models_results[setname].bestourmethod_name_rmse, models_results[setname].bestourmethod_rmse))\n",
    "    \n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 10,10\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(Y, models_results[setname].y_pred_bestourmethod_rmse, \\\n",
    "               c='g', s=50, label=f\"{models_results[setname].bestourmethod_name_rmse}\")\n",
    "    #ax.scatter(Y, y_pred_full, c='r', s=50, label='PLS Full Model')\n",
    "    ax.scatter(Y, y_pred, c='b', s=50, label='PLS Super Set Model')\n",
    "    #ax.scatter(Y, models_results[setname].y_pred_bestinsidemethod, \\\n",
    "    #            c='r', s=50, label='Best inside method')\n",
    "    ax.scatter(Y, y_pred_lr, c='y', s=50, label='LR Super Set Model')\n",
    "    #ax.scatter(Y, y_pred_lr_full, c='r', s=50, label='LR Full Model')\n",
    "    ax.scatter(Y, y_pred_lr_custom, c='m', s=50, label='LR Custom Super Set Model')\n",
    "    #ax.scatter(Y, y_pred_lr_custom_full, c='r', s=50, label='LR Custom Full Model')\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(setname)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Results for Full sim \", len(ypredFull))\n",
    "X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[\"Full\"].uncorrelated_features, \\\n",
    "                                    models_results[\"Full\"].labels)\n",
    "setlist = models_results[\"Full\"].setnames\n",
    "\n",
    "# PLS\n",
    "y_pred_full = pls_model_full.predict(X)\n",
    "if len(y_pred_full.shape) == 2:\n",
    "    y_pred_full = y_pred_full[:,0]\n",
    "rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "wtmad2_full = wtmad2_fulldf[\"Full\"]\n",
    "wtmad2df = commonutils.wtmad2(setnamesFull, Y, ypredFull)\n",
    "wtmad2 = wtmad2df[\"Full\"]\n",
    "rmse = mean_squared_error(Y, ypredFull, squared=False)\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(\"PLS Super Set\",wtmad2))\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(\"PLS Full\",wtmad2_full))\n",
    "\n",
    "# LR\n",
    "y_pred_full = lr_model_full.predict(X)\n",
    "if len(y_pred_full.shape) == 2:\n",
    "    y_pred_full = y_pred_full[:,0]\n",
    "rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "wtmad2_full = wtmad2_fulldf[\"Full\"]\n",
    "wtmad2df = commonutils.wtmad2(setnamesFull_lr, Y, ypredFull_lr)\n",
    "wtmad2 = wtmad2df[\"Full\"]\n",
    "rmse = mean_squared_error(Y, ypredFull_lr, squared=False)\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Super Set\",wtmad2))\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Full\",wtmad2_full))\n",
    "\n",
    "# LR Custom\n",
    "y_pred_full = lr_custom_model_full.predict(X)\n",
    "if len(y_pred_full.shape) == 2:\n",
    "    y_pred_full = y_pred_full[:,0]  \n",
    "rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "wtmad2_full = wtmad2_fulldf[\"Full\"]\n",
    "wtmad2df = commonutils.wtmad2(setnamesFull_lr_custom, Y, ypredFull_lr_custom)\n",
    "wtmad2 = wtmad2df[\"Full\"]\n",
    "rmse = mean_squared_error(Y, ypredFull_lr_custom, squared=False)\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Custom Super Set\",wtmad2))\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(\"LR Custom Full\",wtmad2_full))\n",
    "\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(models_results['Full'].bestinsidemethod_name_wtmad, models_results['Full'].bestinsidemethod_wtmad))\n",
    "print(\"WTMAD2\",\"%20s,%7.3f\"%(models_results['Full'].bestourmethod_name_wtmad, models_results['Full'].bestourmethod_wtmad))\n",
    "rmse = mean_squared_error(models_results[\"Full\"].labels, ypredFull, squared=False)\n",
    "print(\"RMSE  \",\"%20s,%7.3f\"%(\"PLS Super Set\", rmse))\n",
    "print(\"RMSE  \",\"%20s,%7.3f\"%(\"PLS Full\", rmse_full))\n",
    "print(\"RMSE  \",\"%20s,%7.3f\"%(models_results['Full'].bestinsidemethod_name_rmse, models_results['Full'].bestinsidemethod_rmse))\n",
    "print(\"RMSE  \",\"%20s,%7.3f\"%(models_results['Full'].bestourmethod_name_rmse, models_results['Full'].bestourmethod_rmse))\n",
    "\n",
    "plt.clf()\n",
    "plt.rcParams['figure.figsize'] = 10,10\n",
    "fig, ax = plt.subplots()\n",
    "#ax.scatter(Y, y_pred_full, c='r', s=50, label='PLS Full Model')\n",
    "ax.scatter(Y, ypredFull, c='b', s=50, label='PLS Super Set Model')\n",
    "#ax.scatter(Y, y_pred_lr_full, c='r', s=50, label='LR Full Model')\n",
    "ax.scatter(Y, ypredFull_lr, c='y', s=50, label='LR Super Set Model')\n",
    "#ax.scatter(Y, y_pred_lr_custom_full, c='r', s=50, label='LR Custom Full Model')\n",
    "ax.scatter(Y, ypredFull_lr_custom, c='m', s=50, label='LR Custom Super Set Model')\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.title(\"Full\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test and dump PLS equations\n",
    "setname = \"Full\"\n",
    "pls_model_full = models_results[setname].plsmodel\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    print(\"Equations for dataset: \", setname)\n",
    "    ssetname = \"Full\"\n",
    "    if setname in supersetnames or setname == \"Full\":\n",
    "        ssetname = setname  \n",
    "    else:    \n",
    "        lastunder = setname.rfind(\"_\")\n",
    "        ssetname = setname[:lastunder]\n",
    "    \n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    \n",
    "    y_pred_full = pls_model_full.predict(X)\n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "    r2_full = r2_score(Y, y_pred_full)\n",
    "    X_e = X.copy()\n",
    "    X_e -= pls_model_full._x_mean\n",
    "    X_e /= pls_model_full._x_std\n",
    "    y_pred_full_e = np.dot(X_e, pls_model_full.coef_.T)\n",
    "    y_pred_full_e += pls_model_full._y_mean\n",
    "    rmse_full_e = mean_squared_error(Y, y_pred_full_e, squared=False)\n",
    "    print(\"   Full dataset equations Y mean %7.3f\"%pls_model_full._y_mean)\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f [%15.3f %15.3f]\"%(f, \\\n",
    "            pls_model_full.coef_.T[i],\n",
    "            pls_model_full._x_mean[i], \n",
    "            pls_model_full._x_std[i]))\n",
    "    print()\n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    r2 = r2_score(Y, y_pred)\n",
    "    X_e = X.copy()\n",
    "    X_e -= pls_model_ssetname._x_mean\n",
    "    X_e /= pls_model_ssetname._x_std\n",
    "    y_pred_e = np.dot(X_e, pls_model_ssetname.coef_.T)\n",
    "    y_pred_e += pls_model_ssetname._y_mean\n",
    "    rmse_e = mean_squared_error(Y, y_pred_e, squared=False)\n",
    "    print(\"   Super set dataset equations Y mean %7.3f\"%pls_model_ssetname._y_mean)\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f [%15.3f %15.3f]\"%(f, \\\n",
    "            pls_model_ssetname.coef_.T[i],\n",
    "            pls_model_ssetname._x_mean[i], \n",
    "            pls_model_ssetname._x_std[i]))\n",
    "\n",
    "    print()\n",
    "    print(\"RMSE         (ssetname) %7.3f from eq. %7.3f diff []\"%(rmse, rmse_e))\n",
    "    print(\"RMSE             (Full) %7.3f from eq. %7.3f diff []\"%(rmse_full, rmse_full_e))  \n",
    "    print(\"RMSE (bestinsidemethod) %7.3f\"%models_results[setname].bestinsidemethod_rmse)\n",
    "    print(\"RMSE    (bestourmethod) %7.3f\"%models_results[setname].bestourmethod_rmse)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = \"Full\"\n",
    "lr_model_full = models_results[setname].lr_model\n",
    "lr_custom_model_full = models_results[setname].lr_custom_model\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    print(\"Equations for dataset: \", setname)\n",
    "    ssetname = \"Full\"\n",
    "    if setname in supersetnames or setname == \"Full\":\n",
    "        ssetname = setname  \n",
    "    else:    \n",
    "        lastunder = setname.rfind(\"_\")\n",
    "        ssetname = setname[:lastunder]\n",
    "    \n",
    "    lr_model_ssetname = models_results[ssetname].lr_model\n",
    "    lr_custom_model_ssetname = models_results[ssetname].lr_custom_model\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    \n",
    "    \n",
    "    y_pred_full = lr_model_full.predict(X)\n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "    y_pred_full_eq = lr_model_full.intercept_ + np.dot(X, lr_model_full.coef_.T)\n",
    "    rmse_full_eq = mean_squared_error(Y, y_pred_full_eq, squared=False)\n",
    "    print(\"   Full dataset equations\")\n",
    "    print(\" %50s %10.3f\"%(\"Intercept\", lr_model_full.intercept_))\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f\"%(f, lr_model_full.coef_.T[i]))\n",
    "    print(\"\")\n",
    "    print(\"RMSEs Full %7.3f %7.3f\"%(rmse_full, rmse_full_eq))\n",
    "\n",
    "    y_pred_full_custom = lr_custom_model_full.predict(X)\n",
    "    rmse_full_custom = mean_squared_error(Y, y_pred_full_custom, squared=False)\n",
    "    y_pred_full_custom_eq = lr_custom_model_full.get_intercept() + \\\n",
    "        np.dot(X, lr_custom_model_full.get_coefficients().T)\n",
    "    rmse_full_custom_eq = mean_squared_error(Y, y_pred_full_custom_eq, squared=False)\n",
    "    print(\"   Full Custom dataset equations\")\n",
    "    print(\" %50s %10.3f\"%(\"Intercept\", lr_custom_model_full.get_intercept()))\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f\"%(f, lr_custom_model_full.get_coefficients().T[i]))\n",
    "    print(\"\")\n",
    "    print(\"RMSEs Full Custom %7.3f %7.3f\"%(rmse_full_custom, rmse_full_custom_eq))\n",
    "\n",
    "    y_pred = lr_model_ssetname.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    y_pred_eq = lr_model_ssetname.intercept_ + np.dot(X, lr_model_ssetname.coef_.T)\n",
    "    rmse_eq = mean_squared_error(Y, y_pred_eq, squared=False)\n",
    "    print(\"   Super set dataset equations\")\n",
    "    print(\" %50s %10.3f\"%(\"Intercept\", lr_model_ssetname.intercept_))\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f\"%(f, lr_model_ssetname.coef_.T[i]))\n",
    "    print(\"\")\n",
    "    print(\"RMSEs Super Set %7.3f %7.3f\"%(rmse, rmse_eq))\n",
    "\n",
    "    y_pred_custom = lr_custom_model_ssetname.predict(X)\n",
    "    rmse_custom = mean_squared_error(Y, y_pred_custom, squared=False)\n",
    "    y_pred_custom_eq = lr_custom_model_ssetname.get_intercept() + \\\n",
    "        np.dot(X, lr_custom_model_ssetname.get_coefficients().T)\n",
    "    rmse_custom_eq = mean_squared_error(Y, y_pred_custom_eq, squared=False)\n",
    "    print(\"   Super set Custom dataset equations\")\n",
    "    print(\" %50s %10.3f\"%(\"Intercept\", lr_custom_model_ssetname.get_intercept()))\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\" %50s %10.3f\"%(f, lr_custom_model_ssetname.get_coefficients().T[i]))\n",
    "    print(\"\")\n",
    "    print(\"RMSEs Super Set Custom %7.3f %7.3f\"%(rmse_custom, rmse_custom_eq))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform features importance analysis\n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    model = models_results[setname].plsmodel\n",
    "    result = permutation_importance(model, X, Y, n_repeats=10, \\\n",
    "                                random_state=42, n_jobs=2)\n",
    "    pfi_sorted_idx = result.importances_mean.argsort()\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 15,15\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(result.importances[pfi_sorted_idx].T, vert=False, \\\n",
    "               labels=np.array(features_names)[pfi_sorted_idx])\n",
    "    ax.set_title(\"Permutation Importances \" + setname)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    #compute absolute values of the PLS coefficients\n",
    "    coef = np.abs(model.coef_).flatten()\n",
    "    #sort the coefficients\n",
    "    sorted_idx = np.argsort(coef)\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 15,15\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(np.array(features_names)[sorted_idx], \\\n",
    "            coef[sorted_idx])\n",
    "    ax.set_title(\"PLS coefficients \" + setname)\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # scatter plot of the most important features\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 15,15\n",
    "    fis = [np.mean(result.importances[i].T) for i in pfi_sorted_idx]\n",
    "    cfs = [coef[i] for i in sorted_idx]\n",
    "    plt.plot(cfs, fis, '-o', color='black')\n",
    "    plt.xlabel(\"PLS coefficients\")\n",
    "    plt.ylabel(\"Permutation importances\")\n",
    "    plt.title(\"Most important features \" + setname)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
