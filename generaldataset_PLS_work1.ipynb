{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"./data/allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"./data/methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"./data/fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"./data/functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"./data/basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"./data/supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(commonutils)\n",
    "\n",
    "from commonutils import ModelResults\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "insidemethods = [\"W\",\"D3(0)\",\"D3(BJ)\"]\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        wtmad = None\n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestinsidemethod_wtmad:\n",
    "                models_results[setname].bestinsidemethod_wtmad = wtmad\n",
    "                models_results[setname].bestinsidemethod_wtmad_name = insidemethods[methodid]\n",
    "                models_results[setname].y_pred_bestinsidemethod_wtmad = y_pred\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestinsidemethod_rmse:\n",
    "            models_results[setname].bestinsidemethod_rmse = rmse\n",
    "            models_results[setname].bestinsidemethod_rmse_name = insidemethods[methodid]\n",
    "            models_results[setname].y_pred_bestinsidemethod_rmse = y_pred\n",
    "\n",
    "    for j, method in enumerate(methods):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        wtmad = None            \n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestourmethod_wtmad:\n",
    "                models_results[setname].bestourmethod_wtmad = wtmad\n",
    "                models_results[setname].bestourmethod_wtmad_name = method\n",
    "                models_results[setname].y_pred_bestourmethod_wtmad = y_pred\n",
    "        \n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestourmethod_rmse:\n",
    "            models_results[setname].bestourmethod_rmse = rmse\n",
    "            models_results[setname].bestourmethod_rmse_name = method\n",
    "            models_results[setname].y_pred_bestourmethod_rmse = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and generate equations\n",
    "basicfeattouse = [\"Potential_Energy\", \\\n",
    "                \"Kinetic_Energy\", \\\n",
    "                \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "                \"Dispersion_correction\", \\\n",
    "                \"E(C)\", \\\n",
    "                \"E(X)\", \\\n",
    "                \"Two_Electron_Energy\", \\\n",
    "                \"Nuclear_Repulsion\", \\\n",
    "                \"One_Electron_Energy\"]\n",
    "\n",
    "featuresvalues_perset = {}\n",
    "for setname in fullsetnames:\n",
    "    featuresvalues_perset [setname] = []\n",
    "    for val in allvalues_perset[setname]:\n",
    "        featuresvalues_perset[setname].append({})\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                torm = k.replace(\"energydiff\", \"\")\n",
    "                for f in val[k]:\n",
    "                    tocheck = f.replace(torm, \"\")\n",
    "                    if tocheck in basicfeattouse:\n",
    "                        keytouse = f.replace(\"-\", \"_\")\n",
    "                        keytouse = keytouse.replace(\"(\", \"\")\n",
    "                        keytouse = keytouse.replace(\")\", \"\")\n",
    "                        featuresvalues_perset[setname][-1][keytouse] = val[k][f]\n",
    "\n",
    "\n",
    "equations = {\"EC\" :\"EC\" , \\\n",
    "            \"EX\" : \"EX\", \\\n",
    "            \"FSPE\" : \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "            \"DC\" : \"Dispersion_correction\", \\\n",
    "            \"PE\" : \"Potential_Energy\", \\\n",
    "            \"KE\" : \"Kinetic_Energy\", \\\n",
    "            \"OEE\" : \"One_Electron_Energy\", \\\n",
    "            \"TEE\" : \"Two_Electron_Energy\", \\\n",
    "            \"NR\" : \"Nuclear_Repulsion\"}\n",
    "\n",
    "eq_featuresvalues_perset = \\\n",
    "    commonutils.equation_parser_compiler(equations, functionals, basis_sets, basicfeattouse, \\\n",
    "                              featuresvalues_perset)\n",
    "\n",
    "featuresvalues_perset = deepcopy(eq_featuresvalues_perset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_basisset = \"SVP\"\n",
    "selected_functional = \"PBE0\"\n",
    "functionals = [\"PBE0\"]\n",
    "basis_sets = [\"MINIX\"]\n",
    "# compute rmse for QZVP and selected functional \n",
    "selectednames = set()\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname].y_pred_slectedfunc_qzbasis = []\n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for entry in features:\n",
    "            if len(entry.split(\"_\")) == 3:\n",
    "                func = entry.split(\"_\")[0]\n",
    "                basis = entry.split(\"_\")[1]\n",
    "                value = entry.split(\"_\")[2]\n",
    "                if func == selected_functional and basis == \"QZVP\" and \\\n",
    "                    value == \"FSPE\":\n",
    "                    selectednames.add(setname)\n",
    "                    models_results[\\\n",
    "                        setname].y_pred_slectedfunc_qzbasis.append(\\\n",
    "                            features[entry])  \n",
    "            else:\n",
    "                print(\"WARNING: \", entry)   \n",
    "\n",
    "    if len(selectednames) != 1:\n",
    "        print(\"ERROR: \", selectednames)\n",
    "        sys.exit(1)\n",
    "\n",
    "    models_results[setname].slectedfunc_qzbasis_name = selectednames.pop()\n",
    "    rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "            models_results[setname].y_pred_slectedfunc_qzbasis,\\\n",
    "            squared=False)\n",
    "    models_results[setname].slectedfunc_qzbasis_rmse = rmse\n",
    "\n",
    "    if setname in list(supersetnames.keys()) +[\"Full\"]:\n",
    "\n",
    "        wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, \\\n",
    "                                models_results[setname].y_pred_slectedfunc_qzbasis)\n",
    "        wtmad = wtmadf[setname]\n",
    "        models_results[setname].slectedfunc_qzbasis_wtmad = wtmad\n",
    "    \n",
    "\n",
    "sep = \"_\"\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    k = selected_functional + sep + \\\n",
    "            selected_basisset \n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            if val.find(k) != -1:\n",
    "                if val not in desciptors:\n",
    "                    desciptors[val] = [features[val]]\n",
    "                else:\n",
    "                    desciptors[val].append(features[val])\n",
    "\n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            for func in functionals:\n",
    "                for basis in basis_sets:\n",
    "                    if not(basis == selected_basisset and \\\n",
    "                           func == selected_functional):\n",
    "                        if val.find(func + sep + basis) != -1:\n",
    "                            actualk = val \n",
    "                            refk  = selected_functional + sep  + selected_basisset + \\\n",
    "                                val.replace(func + sep + basis, \"\")\n",
    "                            newk = actualk + \"_difftoref\"\n",
    "                            if newk not in desciptors:\n",
    "                                desciptors[newk] = [features[actualk]-features[refk]]\n",
    "                            else:\n",
    "                                desciptors[newk].append(features[actualk]-features[refk])\n",
    "    \n",
    "    models_results[setname].features = desciptors\n",
    "\n",
    "# feastures selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    #print(\"Removing constant features for \", setname)\n",
    "    for k in toremove:\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "print(\"Removing Nuclear Repulsion differences\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"NR\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(commonutils)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "sys.path.append(\"./CLossLr\")\n",
    "import customlosslr as clr\n",
    "\n",
    "from commonutils import ModelsStore\n",
    "\n",
    "models_store = {}\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    models_store[setname] = ModelsStore()\n",
    "\n",
    "    print(\"Running PLS for dataset: \", setname)\n",
    " \n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                      test_size=0.20, random_state=42)\n",
    "    setlist = models_results[setname].setnames  \n",
    "    supersetlist = models_results[setname].supersetnames\n",
    "    maxcomp = X.shape[1]\n",
    " \n",
    "    ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp, split = False,\\\n",
    "          plot = False, loo=False)\n",
    "    r2max_comps = np.argmax(r2s)+1\n",
    "    rmsemin_comps = np.argmin(rmses)+1\n",
    "    wtmadmin_comps = np.argmin(wtmads)+1\n",
    "    compstouse = min(r2max_comps, rmsemin_comps, wtmadmin_comps)\n",
    "    print(\"  Using \", compstouse, \" components\")\n",
    "    models_store[setname].plsmodel = PLSRegression(n_components=compstouse)\n",
    "    \n",
    "    cv = LeaveOneOut()\n",
    "    model = PLSRegression(n_components=compstouse)\n",
    "    scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "    plsloormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    plsrmse = mean_squared_error(Y, models_results[setname].y_pred, squared=False)\n",
    "    plsr2 = r2_score(Y, models_results[setname].y_pred)\n",
    "    y_pred = models_results[setname].y_pred\n",
    "    if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred[:,0]\n",
    "    wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "    plswtmad = wtmadf[setname]\n",
    "\n",
    "    #print(\"              PLS R2: %10.2f\"%plsr2)\n",
    "    print(\"           PLS WTMAD: %10.2f\"%plswtmad)\n",
    "    print(\"            PLS RMSE: %10.2f\"%plsrmse)\n",
    "    print(\"        PLS LOO RMSE: %10.2f\"%plsloormse)\n",
    " \n",
    "    best_rmse = 0.0\n",
    "    best_ncomp = 0\n",
    "    for ncomp in range(1, compstouse+1):\n",
    "        model = PLSRegression(n_components=ncomp)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "        if ncomp == 1:\n",
    "            best_rmse = rmse\n",
    "            best_ncomp = ncomp\n",
    "        else:\n",
    "            if rmse < best_rmse:\n",
    "                best_rmse = rmse\n",
    "                best_ncomp = ncomp\n",
    "    model = PLSRegression(n_components=best_ncomp)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    plsrmsetest = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    y_pred = model.predict(X_train)\n",
    "    plsrmsetrain = mean_squared_error(y_train, y_pred, squared=False)\n",
    "\n",
    "    print(\"      PLS Train RMSE: %10.2f\"%plsrmsetrain)\n",
    "    print(\"      PLS  Test RMSE: %10.2f\"%plsrmsetest)\n",
    "    print()\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X, Y)\n",
    "    models_store[setname].lr_model = lm\n",
    "    y_pred_lr = lm.predict(X)\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_lr)\n",
    "    wtmad_lr = wtamd2[setname]\n",
    "    lrrmse = mean_squared_error(Y, y_pred_lr, squared=False)\n",
    "    # use LOO to get the RMSE\n",
    "    cv = LeaveOneOut()\n",
    "    model = LinearRegression()\n",
    "    scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "    loolrrmse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_lr = lm.predict(X_test)\n",
    "    lrrmsetest = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
    "    y_pred_lr = lm.predict(X_train)\n",
    "    lrrmsetrain = mean_squared_error(y_train, y_pred_lr, squared=False)\n",
    "\n",
    "    print(\"            LR WTMAD: %10.2f\"%wtmad_lr)\n",
    "    print(\"             LR RMSE: %10.2f\"%lrrmse)\n",
    "    print(\"         LR LOO RMSE: %10.2f\"%loolrrmse)\n",
    "    print(\"       LR Train RMSE: %10.2f\"%lrrmsetrain)\n",
    "    print(\"        LR Test RMSE: %10.2f\"%lrrmsetest)\n",
    "    print()\n",
    "\n",
    "    clm = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    clm.fit(X, Y)\n",
    "    models_store[setname].lr_custom_model = clm\n",
    "    y_pred_custom_lr = clm.predict(X)\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_custom_lr)\n",
    "    wtmad_custom_lr = wtamd2[setname]\n",
    "    custom_lrrmse = mean_squared_error(Y, y_pred_custom_lr, squared=False)\n",
    "    # use LOO to get the RMSE canno use need to implemente full estimator API \n",
    "    # https://scikit-learn.org/1.5/developers/develop.html\n",
    "    #cv = LeaveOneOut()\n",
    "    #model = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    #scores = cross_val_score(model, X, Y, \\\n",
    "    #        scoring='neg_mean_squared_error', \\\n",
    "    #        cv=cv, n_jobs=-1)\n",
    "    #loocustom_lrrmse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    clm = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    clm.fit(X_train, y_train)\n",
    "    y_pred_custom_lr = clm.predict(X_test)\n",
    "    custom_lrrmsetest = mean_squared_error(y_test, y_pred_custom_lr, squared=False)\n",
    "    y_pred_custom_lr = clm.predict(X_train)\n",
    "    custom_lrrmsetrain = mean_squared_error(y_train, y_pred_custom_lr, squared=False)\n",
    "\n",
    "    print(\"     Custom LR WTMAD: %10.2f\"%wtmad_custom_lr)\n",
    "    print(\"      Custom LR RMSE: %10.2f\"%custom_lrrmse)\n",
    "    #print(\"  Custom LR LOO RMSE: %10.2f\"%loocustom_lrrmse)\n",
    "    print(\"Custom LR Train RMSE: %10.2f\"%custom_lrrmsetrain)\n",
    "    print(\" Custom LR Test RMSE: %10.2f\"%custom_lrrmsetest)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "basissets_touse = set(basis_sets + [selected_basisset])\n",
    "functional_to_use = set(functionals + [selected_functional])\n",
    "\n",
    "classes = []\n",
    "features = {}\n",
    "supersetnameslist = list(supersetnames.keys())\n",
    "for setname in featuresvalues_perset:\n",
    "    if setname in supersetnameslist:\n",
    "        print(\"Setname: \", setname)\n",
    "        for entry in featuresvalues_perset[setname]:\n",
    "            classes.append(supersetnameslist.index(setname))\n",
    "            #print(\"Entry: \", entry)\n",
    "            for featurename in entry:\n",
    "                for functional in functional_to_use:\n",
    "                    for basisset in basissets_touse:\n",
    "                        if featurename.find(basisset) != -1 and \\\n",
    "                            featurename.find(functional) != -1:\n",
    "                            if featurename not in features:\n",
    "                                features[featurename] = []\n",
    "                            features[featurename].append(entry[featurename])\n",
    "\n",
    "#print(\"Classes: \", len(classes))\n",
    "#for f in features:\n",
    "#    print(\"Feature: \", f, \" \", len(features[f]))\n",
    "X = pd.DataFrame(features)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.20, random_state=42)\n",
    "accuracys = []\n",
    "numoftrees = []\n",
    "for ntrees in range(10, 200, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=ntrees, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracys.append(accuracy)\n",
    "    numoftrees.append(ntrees)\n",
    "\n",
    "bestaccuracy = max(accuracys)   \n",
    "bestntrees = numoftrees[accuracys.index(bestaccuracy)]\n",
    "print(\"Best accuracy: \", max(accuracys), \" with \", bestntrees, \" trees\")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=bestntrees, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "testaccuracy = rf.score(X_test, y_test)\n",
    "trainaccuracy = rf.score(X_train, y_train)\n",
    "overallaccuracy = rf.score(X, classes)\n",
    "print(\"  Train accuracy: %5.2f\"%(trainaccuracy))\n",
    "print(\"   Test accuracy: %5.2f\"%(testaccuracy))\n",
    "print(\"Overall accuracy: %5.2f\"%(overallaccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = \"Full\"\n",
    "pls_model_full = models_results[setname].plsmodel\n",
    "lr_model_full = models_results[setname].lr_model\n",
    "lr_custom_model_full = models_results[setname].lr_custom_model\n",
    "\n",
    "ypredFull = []\n",
    "setnamesFull = []\n",
    "ypredFull_lr = []\n",
    "setnamesFull_lr = []\n",
    "ypredFull_lr_custom = []\n",
    "setnamesFull_lr_custom = []\n",
    "\n",
    "for ssetname in supersetnames:\n",
    "    print(\"Supersetnam \", ssetname)    \n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    lr_model_ssetname = models_results[ssetname].lr_model\n",
    "    lr_custom_model_ssetname = models_results[ssetname].lr_custom_model\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    setlist = models_results[setname].setnames\n",
    "    setnamesFull.extend(setlist)\n",
    "\n",
    "    # PLS \n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    ypredFull.extend(y_pred)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    wtmad2df = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "    wtamd2 = wtmad2df[ssetname]\n",
    "    ypredFull.extend(y_pred)\n",
    "    print(\" SS PLS WTMAD2\",\"%7.3f\"%(wtamd2))\n",
    "\n",
    "    print(\"%5s WTMAD2 %7.3f\"%(models_results[ssetname].bestourmethod_name_rmse, \\\n",
    "                            models_results[ssetname].bestinsidemethod_wtmad))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
