{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"./data/allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"./data/methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"./data/fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"./data/functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"./data/basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"./data/supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(commonutils)\n",
    "\n",
    "from commonutils import ModelResults\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "insidemethods = [\"W\",\"D3(0)\",\"D3(BJ)\"]\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        methodname = insidemethods[methodid]\n",
    "        models_results[setname].insidemethods_rmse[methodname] = float(\"inf\")\n",
    "        models_results[setname].insidemethods_mape[methodname] = float(\"inf\")\n",
    "        models_results[setname].insidemethods_wtamd[methodname] = float(\"inf\")\n",
    "        models_results[setname].insidemethods_ypred[methodname] = []\n",
    "\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        models_results[setname].insidemethods_ypred[methodname].extend(y_pred)\n",
    "\n",
    "        wtmad = None\n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "            models_results[setname].insidemethods_wtamd[methodname] = wtmad\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "        models_results[setname].insidemethods_rmse[methodname] = rmse\n",
    "        \n",
    "        mape = mean_absolute_percentage_error(models_results[setname].labels, y_pred)\n",
    "        models_results[setname].insidemethods_mape[methodname] = mape\n",
    "        \n",
    "    for j, method in enumerate(methods):\n",
    "        models_results[setname].funcional_basisset_rmse[method] = float(\"inf\")\n",
    "        models_results[setname].funcional_basisset_mape[method] = float\n",
    "        models_results[setname].funcional_basisset_wtamd[method] = float\n",
    "        models_results[setname].funcional_basisset_ypred[method] = []\n",
    "\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        models_results[setname].funcional_basisset_ypred[method].extend(y_pred)\n",
    "\n",
    "        wtmad = None            \n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "            models_results[setname].funcional_basisset_wtamd[method] = wtmad\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "        models_results[setname].funcional_basisset_rmse[method] = rmse\n",
    "\n",
    "        mape = mean_absolute_percentage_error(models_results[setname].labels, y_pred)\n",
    "        models_results[setname].funcional_basisset_mape[method] = mape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and generate equations\n",
    "basicfeattouse = [\"Potential_Energy\", \\\n",
    "                \"Kinetic_Energy\", \\\n",
    "                \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "                \"Dispersion_correction\", \\\n",
    "                \"E(C)\", \\\n",
    "                \"E(X)\", \\\n",
    "                \"Two_Electron_Energy\", \\\n",
    "                \"Nuclear_Repulsion\", \\\n",
    "                \"One_Electron_Energy\"]\n",
    "\n",
    "featuresvalues_perset = {}\n",
    "for setname in fullsetnames:\n",
    "    featuresvalues_perset [setname] = []\n",
    "    for val in allvalues_perset[setname]:\n",
    "        featuresvalues_perset[setname].append({})\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                torm = k.replace(\"energydiff\", \"\")\n",
    "                for f in val[k]:\n",
    "                    tocheck = f.replace(torm, \"\")\n",
    "                    if tocheck in basicfeattouse:\n",
    "                        keytouse = f.replace(\"-\", \"_\")\n",
    "                        keytouse = keytouse.replace(\"(\", \"\")\n",
    "                        keytouse = keytouse.replace(\")\", \"\")\n",
    "                        featuresvalues_perset[setname][-1][keytouse] = val[k][f]\n",
    "\n",
    "\n",
    "equations = {\"EC\" :\"EC\" , \\\n",
    "            \"EX\" : \"EX\", \\\n",
    "            \"FSPE\" : \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "            \"DC\" : \"Dispersion_correction\", \\\n",
    "            \"PE\" : \"Potential_Energy\", \\\n",
    "            \"KE\" : \"Kinetic_Energy\", \\\n",
    "            \"OEE\" : \"One_Electron_Energy\", \\\n",
    "            \"TEE\" : \"Two_Electron_Energy\", \\\n",
    "            \"NR\" : \"Nuclear_Repulsion\"}\n",
    "\n",
    "eq_featuresvalues_perset = \\\n",
    "    commonutils.equation_parser_compiler(equations, functionals, basis_sets, basicfeattouse, \\\n",
    "                              featuresvalues_perset)\n",
    "\n",
    "featuresvalues_perset = deepcopy(eq_featuresvalues_perset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_basisset = \"SVP\"\n",
    "selected_functional = \"PBE0\"\n",
    "functionals = []\n",
    "basis_sets = []\n",
    "\n",
    "sep = \"_\"\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    k = selected_functional + sep + \\\n",
    "            selected_basisset \n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            if val.find(k) != -1:\n",
    "                if val not in desciptors:\n",
    "                    desciptors[val] = [features[val]]\n",
    "                else:\n",
    "                    desciptors[val].append(features[val])\n",
    "\n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            for func in functionals:\n",
    "                for basis in basis_sets:\n",
    "                    if not(basis == selected_basisset and \\\n",
    "                           func == selected_functional):\n",
    "                        if val.find(func + sep + basis) != -1:\n",
    "                            actualk = val \n",
    "                            refk  = selected_functional + sep  + selected_basisset + \\\n",
    "                                val.replace(func + sep + basis, \"\")\n",
    "                            newk = actualk + \"_difftoref\"\n",
    "                            if newk not in desciptors:\n",
    "                                desciptors[newk] = [features[actualk]-features[refk]]\n",
    "                            else:\n",
    "                                desciptors[newk].append(features[actualk]-features[refk])\n",
    "    \n",
    "    models_results[setname].features = desciptors\n",
    "\n",
    "# feastures selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    #print(\"Removing constant features for \", setname)\n",
    "    for k in toremove:\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "print(\"Removing Nuclear Repulsion differences\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"NR_difftoref\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(commonutils)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "sys.path.append(\"./CLossLr\")\n",
    "import customlosslr as clr\n",
    "\n",
    "from commonutils import ModelsStore\n",
    "\n",
    "models_store = {}\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    models_store[setname] = ModelsStore()\n",
    "\n",
    "    print(\"Running PLS for dataset: \", setname)\n",
    " \n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                      test_size=0.20, random_state=42)\n",
    "    setlist = models_results[setname].setnames  \n",
    "    supersetlist = models_results[setname].supersetnames\n",
    "    maxcomp = X.shape[1]\n",
    "\n",
    "    # PLS\n",
    "    ncomps, rmses, r2s, wtmads, loormses, mapes = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp, split = False,\\\n",
    "          plot = False, loo=False)\n",
    "    r2max_comps = np.argmax(r2s)+1\n",
    "    rmsemin_comps = np.argmin(rmses)+1\n",
    "    mapemin_comps = np.argmin(mapes)+1\n",
    "    wtmadmin_comps = np.argmin(wtmads)+1\n",
    "    compstouse = mapemin_comps\n",
    "    print(\"  Using \", compstouse, \" components\")\n",
    "    models_store[setname].plsmodel = PLSRegression(n_components=compstouse)\n",
    "    y_pred = models_store[setname].plsmodel.fit(X, Y).predict(X)\n",
    "    plsrmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    plsr2 = r2_score(Y, y_pred)\n",
    "    plsmape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred[:,0]\n",
    "    wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "    plswtmad = wtmadf[setname]\n",
    "    cv = LeaveOneOut()\n",
    "    model = PLSRegression(n_components=compstouse)\n",
    "    scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "    plsloormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    #print(\"              PLS R2: %10.2f\"%plsr2)\n",
    "    #print(\"           PLS WTMAD: %10.2f\"%plswtmad)\n",
    "    print(\"            PLS RMSE: %10.2f\"%plsrmse)\n",
    "    print(\"        PLS LOO RMSE: %10.2f\"%plsloormse)\n",
    "    best_mape = 0.0\n",
    "    best_ncomp = 0\n",
    "    for ncomp in range(1, compstouse+1):\n",
    "        model = PLSRegression(n_components=ncomp)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        if ncomp == 1:\n",
    "            best_mape = mape\n",
    "            best_ncomp = ncomp\n",
    "        else:\n",
    "            if mape < best_mape:\n",
    "                best_mape = mape\n",
    "                best_ncomp = ncomp\n",
    "    model = PLSRegression(n_components=best_ncomp)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    plsrmsetest = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    plsmapetest = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    y_pred = model.predict(X_train)\n",
    "    plsrmsetrain = mean_squared_error(y_train, y_pred, squared=False)\n",
    "    plsmapetrain = mean_absolute_percentage_error(y_train, y_pred)\n",
    "    print(\"      PLS Train RMSE: %10.2f\"%plsrmsetrain)\n",
    "    print(\"      PLS  Test RMSE: %10.2f\"%plsrmsetest)\n",
    "    print(\"            PLS MAPE: %10.2f\"%plsmape)       \n",
    "    print(\"      PLS Train MAPE: %10.2f\"%plsmapetrain)\n",
    "    print(\"      PLS  Test MAPE: %10.2f\"%plsmapetest)\n",
    "    print()\n",
    "\n",
    "    # Linear Regression\n",
    "    #lm = LinearRegression()\n",
    "    lm = clr.custom_loss_lr (loss=clr.mean_average_error)\n",
    "    lm.fit(X, Y)\n",
    "    models_store[setname].lr_model = lm\n",
    "    y_pred_lr = lm.predict(X)\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_lr)\n",
    "    wtmad_lr = wtamd2[setname]\n",
    "    lrrmse = mean_squared_error(Y, y_pred_lr, squared=False)\n",
    "    lrrmape = mean_absolute_percentage_error(Y, y_pred_lr)\n",
    "    # use LOO to get the RMSE\n",
    "    #cv = LeaveOneOut()\n",
    "    #model = LinearRegression()\n",
    "    #scores = cross_val_score(model, X, Y, \\\n",
    "    #        scoring='neg_mean_squared_error', \\\n",
    "    #        cv=cv, n_jobs=-1)\n",
    "    #loolrrmse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    #lm = LinearRegression()\n",
    "    lm = clr.custom_loss_lr (loss=clr.mean_average_error)\n",
    "    lm.fit(X_train, y_train)\n",
    "    y_pred_lr = lm.predict(X_test)\n",
    "    lrrmsetest = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
    "    lrrmaoetest = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
    "    y_pred_lr = lm.predict(X_train)\n",
    "    lrrmsetrain = mean_squared_error(y_train, y_pred_lr, squared=False)\n",
    "    lrrmaopetrain = mean_absolute_percentage_error(y_train, y_pred_lr)\n",
    "    #print(\"            LR WTMAD: %10.2f\"%wtmad_lr)\n",
    "    print(\"             LR RMSE: %10.2f\"%lrrmse)\n",
    "    #print(\"         LR LOO RMSE: %10.2f\"%loolrrmse)\n",
    "    print(\"       LR Train RMSE: %10.2f\"%lrrmsetrain)\n",
    "    print(\"        LR Test RMSE: %10.2f\"%lrrmsetest)\n",
    "    print(\"             LR MAPE: %10.2f\"%lrrmape)\n",
    "    print(\"       LR Train MAPE: %10.2f\"%lrrmaopetrain)\n",
    "    print(\"        LR Test MAPE: %10.2f\"%lrrmaoetest)\n",
    "    print()\n",
    "\n",
    "    # Custom Loss Linear Regression\n",
    "    clm = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    clm.fit(X, Y)\n",
    "    models_store[setname].lr_custom_model = clm\n",
    "    y_pred_custom_lr = clm.predict(X)\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_custom_lr)\n",
    "    wtmad_custom_lr = wtamd2[setname]\n",
    "    custom_lrrmse = mean_squared_error(Y, y_pred_custom_lr, squared=False)\n",
    "    custom_lrrmape = mean_absolute_percentage_error(Y, y_pred_custom_lr)\n",
    "    # use LOO to get the RMSE canno use need to implemente full estimator API \n",
    "    # https://scikit-learn.org/1.5/developers/develop.html\n",
    "    #cv = LeaveOneOut()\n",
    "    #model = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    #scores = cross_val_score(model, X, Y, \\\n",
    "    #        scoring='neg_mean_squared_error', \\\n",
    "    #        cv=cv, n_jobs=-1)\n",
    "    #loocustom_lrrmse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    clm = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    clm.fit(X_train, y_train)\n",
    "    y_pred_custom_lr = clm.predict(X_test)\n",
    "    custom_lrrmsetest = mean_squared_error(y_test, y_pred_custom_lr, squared=False)\n",
    "    custom_lrrmapetest = mean_absolute_percentage_error(y_test, y_pred_custom_lr)\n",
    "    y_pred_custom_lr = clm.predict(X_train)\n",
    "    custom_lrrmsetrain = mean_squared_error(y_train, y_pred_custom_lr, squared=False)\n",
    "    custom_lrrmapetrain = mean_absolute_percentage_error(y_train, y_pred_custom_lr)\n",
    "    #print(\"     Custom LR WTMAD: %10.2f\"%wtmad_custom_lr)\n",
    "    print(\"      Custom LR RMSE: %10.2f\"%custom_lrrmse)\n",
    "    #print(\"  Custom LR LOO RMSE: %10.2f\"%loocustom_lrrmse)\n",
    "    print(\"Custom LR Train RMSE: %10.2f\"%custom_lrrmsetrain)\n",
    "    print(\" Custom LR Test RMSE: %10.2f\"%custom_lrrmsetest)\n",
    "    print(\"      Custom LR MAPE: %10.2f\"%custom_lrrmape)\n",
    "    print(\"Custom LR Train MAPE: %10.2f\"%custom_lrrmapetrain)\n",
    "    print(\" Custom LR Test MAPE: %10.2f\"%custom_lrrmapetest)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = None\n",
    "ssetname = \"Full\"\n",
    "pls_model_full = models_store[ssetname].plsmodel\n",
    "lr_model_full = models_store[ssetname].lr_model\n",
    "lr_custom_model_full = models_store[ssetname].lr_custom_model\n",
    "\n",
    "ypredFull = []\n",
    "ypredFull_lr = []\n",
    "ypredFull_lr_custom = []\n",
    "ypredFull_quadz = []\n",
    "ypredFull_allbasissets = {}\n",
    "ypredFull_d3bj = []\n",
    "\n",
    "for method in models_results[ssetname].funcional_basisset_ypred:\n",
    "    if method.find(selected_functional) != -1:\n",
    "        ypredFull_allbasissets[method] = []\n",
    "\n",
    "setnamesFull = []\n",
    "\n",
    "for ssetname in supersetnames:\n",
    "    pls_model_ssetname = models_store[ssetname].plsmodel\n",
    "    lr_model_ssetname = models_store[ssetname].lr_model\n",
    "    lr_custom_model_ssetname = models_store[ssetname].lr_custom_model\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[ssetname].features, \\\n",
    "                                    models_results[ssetname].labels)\n",
    "    setlist = models_results[ssetname].setnames\n",
    "    setnamesFull.extend(setlist)\n",
    "\n",
    "    # SuperSet PLS \n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS PLS\", mape))\n",
    "\n",
    "    # SuperSet LR\n",
    "    y_pred = lr_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_lr.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS LR\", mape))\n",
    "\n",
    "    # SuperSet Custom LR\n",
    "    y_pred = lr_custom_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_lr_custom.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS Custom LR\", mape))\n",
    "\n",
    "    # Full PLS\n",
    "    y_pred = pls_model_full.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full PLS\", mape))\n",
    "\n",
    "    # Full LR\n",
    "    y_pred = lr_model_full.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full LR\", mape))\n",
    "\n",
    "    # Full Custom LR\n",
    "    y_pred = lr_custom_model_full.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full Custom LR\", mape))\n",
    "\n",
    "\n",
    "    mape = models_results[ssetname].insidemethods_mape[\"D3(BJ)\"] \n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , D3(BJ)\", mape))\n",
    "    ypredFull_d3bj.extend(models_results[ssetname].insidemethods_ypred[\"D3(BJ)\"])\n",
    "\n",
    "    for method in models_results[ssetname].funcional_basisset_ypred:\n",
    "        if method.find(selected_functional) != -1:\n",
    "            y_pred = models_results[ssetname].funcional_basisset_ypred[method]\n",
    "            ypredFull_allbasissets[method].extend(y_pred)\n",
    "            print(\" %60s MAPE , %7.3f\"%(ssetname+' , '+method, mean_absolute_percentage_error(Y, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "basissets_touse = set(basis_sets + [selected_basisset])\n",
    "functional_to_use = set(functionals + [selected_functional])\n",
    "\n",
    "classes = []\n",
    "features = {}\n",
    "supersetnameslist = list(supersetnames.keys())\n",
    "for setname in featuresvalues_perset:\n",
    "    if setname in supersetnameslist:\n",
    "        print(\"Setname: \", setname)\n",
    "        for entry in featuresvalues_perset[setname]:\n",
    "            classes.append(supersetnameslist.index(setname))\n",
    "            #print(\"Entry: \", entry)\n",
    "            #for featurename in entry:\n",
    "            #    for functional in functional_to_use:\n",
    "            #        for basisset in basissets_touse:\n",
    "            #            if featurename.find(basisset) != -1 and \\\n",
    "            #                featurename.find(functional) != -1:\n",
    "            #                if featurename not in features:\n",
    "            #                    features[featurename] = []\n",
    "            #                features[featurename].append(entry[featurename])\n",
    "\n",
    "#print(\"Classes: \", len(classes))\n",
    "#for f in features:\n",
    "#    print(\"Feature: \", f, \" \", len(features[f]))\n",
    "#X = pd.DataFrame(features)\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results['Full'].features, \\\n",
    "                                    models_results['Full'].labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, classes, test_size=0.20, random_state=42)\n",
    "accuracys = []\n",
    "numoftrees = []\n",
    "for ntrees in range(10, 200, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=ntrees, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracys.append(accuracy)\n",
    "    numoftrees.append(ntrees)\n",
    "\n",
    "bestaccuracy = max(accuracys)   \n",
    "bestntrees = numoftrees[accuracys.index(bestaccuracy)]\n",
    "print(\"Best accuracy: \", max(accuracys), \" with \", bestntrees, \" trees\")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=bestntrees, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "testaccuracy = rf.score(X_test, y_test)\n",
    "trainaccuracy = rf.score(X_train, y_train)\n",
    "overallaccuracy = rf.score(X, classes)\n",
    "print(\"  Train accuracy: %5.2f\"%(trainaccuracy))\n",
    "print(\"   Test accuracy: %5.2f\"%(testaccuracy))\n",
    "print(\"Overall accuracy: %5.2f\"%(overallaccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert(len(ypredFull) == len(ypredFull_lr))\n",
    "assert(len(ypredFull) == len(ypredFull_lr_custom))\n",
    "assert(len(ypredFull) == len(models_results[\"Full\"].labels))\n",
    "assert(len(ypredFull) == len(setnamesFull))\n",
    "assert(len(ypredFull) == len(ypredFull_d3bj))\n",
    "for method in ypredFull_allbasissets:\n",
    "    assert(len(ypredFull) == len(ypredFull_allbasissets[method]))\n",
    "\n",
    "# using the classifier\n",
    "\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results['Full'].features, \\\n",
    "                                    models_results['Full'].labels)\n",
    "setlist = models_results['Full'].setnames\n",
    "\n",
    "y_pred_RF = []\n",
    "for i in range(len(X)):\n",
    "    c = rf.predict([X[i]])\n",
    "    #print(\"X: \", i, \" Y: \", Y[i], \" C: \", c, \" ==> \", supersetnameslist[c[0]])\n",
    "    plmodel = models_store[supersetnameslist[c[0]]].plsmodel\n",
    "    y = plmodel.predict([X[i]])\n",
    "    if len(y.shape) == 2:\n",
    "        y = y[:,0]\n",
    "    y_pred_RF.append(y[0])\n",
    "\n",
    "wtamd2_full_usingss = \\\n",
    "    commonutils.wtmad2(setnamesFull, \\\n",
    "                        ypredFull, \\\n",
    "                        models_results[\"Full\"].labels)\n",
    "wtamd2 = wtamd2_full_usingss[\"Full\"]\n",
    "print(\"%40s %7.3f\"%(\"Full using PLS SS WTMAD2, \", wtamd2))\n",
    "\n",
    "wtamd2_full_lr = \\\n",
    "    commonutils.wtmad2(setnamesFull, \\\n",
    "                        ypredFull_lr, \\\n",
    "                        models_results[\"Full\"].labels)\n",
    "wtamd2 = wtamd2_full_lr[\"Full\"]\n",
    "print(\"%40s %7.3f\"%(\"Full using LR SS WTMAD2, \", wtamd2))\n",
    "\n",
    "wtamd2_full_custom_lr = \\\n",
    "    commonutils.wtmad2(setnamesFull, \\\n",
    "                        ypredFull_lr_custom, \\\n",
    "                        models_results[\"Full\"].labels)\n",
    "wtamd2 = wtamd2_full_custom_lr[\"Full\"]\n",
    "print(\"%40s %7.3f\"%(\"Full using Custom LR SS WTMAD2, \", wtamd2))\n",
    "\n",
    "wtamd2 = commonutils.wtmad2(setnamesFull, y_pred_RF, models_results[\"Full\"].labels)\n",
    "wtamd2 = wtamd2[\"Full\"]\n",
    "print(\"%40s %7.3f\"%(\"Full using RF WTMAD2, \", wtamd2))\n",
    "\n",
    "for method in ypredFull_allbasissets:\n",
    "    wtamd2_full_allbasissets = \\\n",
    "        commonutils.wtmad2(setnamesFull, \\\n",
    "                            ypredFull_allbasissets[method], \\\n",
    "                            models_results[\"Full\"].labels)\n",
    "    wtamd2 = wtamd2_full_allbasissets[\"Full\"]\n",
    "    print(\"%40s %7.3f\"%(method + \" using SS WTMAD2, \", wtamd2))\n",
    "\n",
    "wtamd2_full_d3bj = \\\n",
    "    commonutils.wtmad2(setnamesFull, \\\n",
    "                        ypredFull_d3bj, \\\n",
    "                        models_results[\"Full\"].labels)\n",
    "wtamd2 = wtamd2_full_d3bj[\"Full\"]\n",
    "print(\"%40s %7.3f\"%(\"Full using D3(BJ) WTMAD2, \", wtamd2))\n",
    "\n",
    "maoe_full_usingss = mean_absolute_percentage_error(\\\n",
    "    models_results[\"Full\"].labels, ypredFull)\n",
    "print(\"%40s %7.3f\"%(\"Full using PLS SS MAPE, \", maoe_full_usingss))\n",
    "\n",
    "maoe_full_lr = mean_absolute_percentage_error(\\\n",
    "    models_results[\"Full\"].labels, ypredFull_lr)\n",
    "print(\"%40s %7.3f\"%(\"Full using LR SS MAPE, \", maoe_full_lr))\n",
    "\n",
    "mape_full_custom_lr = mean_absolute_percentage_error(\\\n",
    "    models_results[\"Full\"].labels, ypredFull_lr_custom)\n",
    "print(\"%40s %7.3f\"%(\"Full using Custom LR SS MAPE, \", mape_full_custom_lr))\n",
    "\n",
    "mape = mean_absolute_percentage_error(models_results[\"Full\"].labels, y_pred_RF)\n",
    "print(\"%40s %7.3f\"%(\"Full using RF MAPE, \", mape))\n",
    "\n",
    "for method in ypredFull_allbasissets:\n",
    "    mape_full_allbasissets = mean_absolute_percentage_error(\\\n",
    "        models_results[\"Full\"].labels, ypredFull_allbasissets[method])\n",
    "    print(\"%40s %7.3f\"%(method + \" using SS MAPE, \", mape_full_allbasissets))\n",
    "\n",
    "mape_full_d3bj = mean_absolute_percentage_error(\\\n",
    "    models_results[\"Full\"].labels, ypredFull_d3bj)\n",
    "print(\"%40s %7.3f\"%(\"Full using D3(BJ) MAPE, \", mape_full_d3bj))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract PLS and LR coefficients and equations\n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "    print(\"Equations for \", setname)\n",
    "    lr_model = models_store[setname].lr_model\n",
    "    lr_custom_model = models_store[setname].lr_custom_model\n",
    "    pls_model = models_store[setname].plsmodel\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    # LR model\n",
    "    y_pred = lr_model.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    #y_pred_eq = lr_model.intercept_ + np.dot(X, lr_model.coef_.T)\n",
    "    y_pred_eq = lr_model.get_intercept() + np.dot(X, lr_model.get_coefficients().T)\n",
    "    rmse_eq = mean_squared_error(Y, y_pred_eq, squared=False)\n",
    "    diffperc = np.abs(rmse - rmse_eq) / rmse * 100.0\n",
    "    print(\"  LR RMSE Diff %5.3f\"%(diffperc), \"%\")\n",
    "    #print(\"  %15s %12.8e\"%(\"Intercept\", lr_model.intercept_))\n",
    "    print(\"  %15s %12.4f\"%(\"Intercept\", lr_model.get_intercept()))\n",
    "    for i, f in enumerate(features_names):\n",
    "        #print(\"  %15s %12.8e\"%(f, lr_model.coef_.T[i]))\n",
    "        print(\"  %15s %12.4f\"%(f, lr_model.get_coefficients().T[i]))\n",
    "    print(\"\")\n",
    "\n",
    "    # Custom LR model\n",
    "    y_pred = lr_custom_model.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    y_pred_eq = lr_custom_model.get_intercept() + np.dot(X, \\\n",
    "                lr_custom_model.get_coefficients().T)\n",
    "    rmse_eq = mean_squared_error(Y, y_pred_eq, squared=False)\n",
    "    diffperc = np.abs(rmse - rmse_eq) / rmse * 100.0\n",
    "    print(\"  Custom LR RMSE Diff %5.3f \"%(diffperc), \"%\")\n",
    "    print(\"  %15s %12.4f\"%(\"Intercept\", lr_custom_model.get_intercept()) )\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\"  %15s %12.4f\"%(f, lr_custom_model.get_coefficients().T[i]))\n",
    "    print(\"\")\n",
    "\n",
    "    # PLS model\n",
    "    y_pred = pls_model.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    X_e = X.copy()\n",
    "    X_e -= pls_model._x_mean\n",
    "    X_e /= pls_model._x_std\n",
    "    y_pred_eq = np.dot(X_e, pls_model.coef_.T)\n",
    "    y_pred_eq += pls_model._y_mean\n",
    "    rmse_eq = mean_squared_error(Y, y_pred_eq, squared=False)\n",
    "    diffperc = np.abs(rmse - rmse_eq) / rmse * 100.0\n",
    "    print(\"  PLS RMSE Diff %5.3f \"%(diffperc), \"%\")\n",
    "    for i, f in enumerate(features_names):\n",
    "        print(\"  %15s %12.4f [%12.4f %12.4f]\"%(f, \\\n",
    "            pls_model.coef_.T[i],\n",
    "            pls_model._x_mean[i], \n",
    "            pls_model._x_std[i]))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
