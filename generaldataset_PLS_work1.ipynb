{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"./data/allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"./data/methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"./data/fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"./data/functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"./data/basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"./data/supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(commonutils)\n",
    "\n",
    "from commonutils import ModelResults\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "insidemethods = [\"W\",\"D3(0)\",\"D3(BJ)\"]\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        methodname = insidemethods[methodid]\n",
    "        models_results[setname].insidemethods_rmse[methodname] = float(\"inf\")\n",
    "        models_results[setname].insidemethods_mape[methodname] = float(\"inf\")\n",
    "        models_results[setname].insidemethods_wtamd[methodname] = float(\"inf\")\n",
    "        models_results[setname].insidemethods_ypred[methodname] = []\n",
    "\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        models_results[setname].insidemethods_ypred[methodname].extend(y_pred)\n",
    "\n",
    "        wtmad = None\n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "            models_results[setname].insidemethods_wtamd[methodname] = wtmad\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "        models_results[setname].insidemethods_rmse[methodname] = rmse\n",
    "        \n",
    "        mape = mean_absolute_percentage_error(models_results[setname].labels, y_pred)\n",
    "        models_results[setname].insidemethods_mape[methodname] = mape\n",
    "        \n",
    "    for j, method in enumerate(methods):\n",
    "        models_results[setname].funcional_basisset_rmse[method] = float(\"inf\")\n",
    "        models_results[setname].funcional_basisset_mape[method] = float\n",
    "        models_results[setname].funcional_basisset_wtamd[method] = float\n",
    "        models_results[setname].funcional_basisset_ypred[method] = []\n",
    "\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        models_results[setname].funcional_basisset_ypred[method].extend(y_pred)\n",
    "\n",
    "        wtmad = None            \n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "            models_results[setname].funcional_basisset_wtamd[method] = wtmad\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "        models_results[setname].funcional_basisset_rmse[method] = rmse\n",
    "\n",
    "        mape = mean_absolute_percentage_error(models_results[setname].labels, y_pred)\n",
    "        models_results[setname].funcional_basisset_mape[method] = mape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter and generate equations\n",
    "basicfeattouse = [\"Potential_Energy\", \\\n",
    "                \"Kinetic_Energy\", \\\n",
    "                \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "                \"Dispersion_correction\", \\\n",
    "                \"E(C)\", \\\n",
    "                \"E(X)\", \\\n",
    "                \"Two_Electron_Energy\", \\\n",
    "                \"Nuclear_Repulsion\", \\\n",
    "                \"One_Electron_Energy\"]\n",
    "\n",
    "featuresvalues_perset = {}\n",
    "for setname in fullsetnames:\n",
    "    featuresvalues_perset [setname] = []\n",
    "    for val in allvalues_perset[setname]:\n",
    "        featuresvalues_perset[setname].append({})\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                torm = k.replace(\"energydiff\", \"\")\n",
    "                for f in val[k]:\n",
    "                    tocheck = f.replace(torm, \"\")\n",
    "                    if tocheck in basicfeattouse:\n",
    "                        keytouse = f.replace(\"-\", \"_\")\n",
    "                        keytouse = keytouse.replace(\"(\", \"\")\n",
    "                        keytouse = keytouse.replace(\")\", \"\")\n",
    "                        featuresvalues_perset[setname][-1][keytouse] = val[k][f]\n",
    "\n",
    "\n",
    "equations = {\"EC\" :\"EC\" , \\\n",
    "            \"EX\" : \"EX\", \\\n",
    "            \"FSPE\" : \"FINAL_SINGLE_POINT_ENERGY\", \\\n",
    "            \"DC\" : \"Dispersion_correction\", \\\n",
    "            \"PE\" : \"Potential_Energy\", \\\n",
    "            \"KE\" : \"Kinetic_Energy\", \\\n",
    "            \"OEE\" : \"One_Electron_Energy\", \\\n",
    "            \"TEE\" : \"Two_Electron_Energy\", \\\n",
    "            \"NR\" : \"Nuclear_Repulsion\"}\n",
    "\n",
    "eq_featuresvalues_perset = \\\n",
    "    commonutils.equation_parser_compiler(equations, functionals, basis_sets, basicfeattouse, \\\n",
    "                              featuresvalues_perset)\n",
    "\n",
    "featuresvalues_perset = deepcopy(eq_featuresvalues_perset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[\"PBE\", \"PBE0\"]\n",
    "#[\"MINIX\", \"SVP\", \"TZVP\", \"QZVP\"]\n",
    "\n",
    "selected_basisset = \"SVP\"\n",
    "selected_functional = \"PBE\"\n",
    "functionals = [\"PBE\"]\n",
    "basis_sets = [\"MINIX\"]\n",
    "\n",
    "sep = \"_\"\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    k = selected_functional + sep + \\\n",
    "            selected_basisset \n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            if val.find(k) != -1:\n",
    "                if val not in desciptors:\n",
    "                    desciptors[val] = [features[val]]\n",
    "                else:\n",
    "                    desciptors[val].append(features[val])\n",
    "\n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            for func in functionals:\n",
    "                for basis in basis_sets:\n",
    "                    if not(basis == selected_basisset and \\\n",
    "                           func == selected_functional):\n",
    "                        if val.find(func + sep + basis) != -1:\n",
    "                            actualk = val \n",
    "                            refk  = selected_functional + sep  + selected_basisset + \\\n",
    "                                val.replace(func + sep + basis, \"\")\n",
    "                            newk = actualk + \"_difftoref\"\n",
    "                            if newk not in desciptors:\n",
    "                                desciptors[newk] = [features[actualk]-features[refk]]\n",
    "                            else:\n",
    "                                desciptors[newk].append(features[actualk]-features[refk])\n",
    "    \n",
    "    models_results[setname].features = desciptors\n",
    "\n",
    "# feastures selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    #print(\"Removing constant features for \", setname)\n",
    "    for k in toremove:\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "print(\"Removing Nuclear Repulsion differences\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"NR_difftoref\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "importlib.reload(commonutils)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "sys.path.append(\"./CLossLr\")\n",
    "import customlosslr as clr\n",
    "\n",
    "from commonutils import ModelsStore\n",
    "\n",
    "models_store = {}\n",
    "fp = open(\"modelsgeneral.csv\", \"w\")\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    models_store[setname] = ModelsStore()\n",
    "\n",
    "    #print(\"Running PLS for dataset: \", setname)\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, \n",
    "                      test_size=0.20, random_state=42)\n",
    "    setlist = models_results[setname].setnames  \n",
    "    supersetlist = models_results[setname].supersetnames\n",
    "    maxcomp = X.shape[1]\n",
    "\n",
    "    # PLS\n",
    "    ncomps, rmses, r2s, wtmads, loormses, mapes = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp, split = False,\\\n",
    "          plot = False, loo=False)\n",
    "    r2max_comps = np.argmax(r2s)+1\n",
    "    rmsemin_comps = np.argmin(rmses)+1\n",
    "    mapemin_comps = np.argmin(mapes)+1\n",
    "    wtmadmin_comps = np.argmin(wtmads)+1\n",
    "    compstouse = mapemin_comps\n",
    "    #print(\"  Using \", compstouse, \" components\")\n",
    "    models_store[setname].plsmodel = PLSRegression(n_components=compstouse)\n",
    "    y_pred = models_store[setname].plsmodel.fit(X, Y).predict(X)\n",
    "    plsrmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    plsr2 = r2_score(Y, y_pred)\n",
    "    plsmape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred[:,0]\n",
    "    wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "    plswtmad = wtmadf[setname]\n",
    "    cv = LeaveOneOut()\n",
    "    model = PLSRegression(n_components=compstouse)\n",
    "    scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "    plsloormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    #print(\"              PLS R2: %10.2f\"%plsr2)\n",
    "    #print(\"           PLS WTMAD: %10.2f\"%plswtmad)\n",
    "    print(\"%40s ,            PLS RMSE, %10.2f\"%(setname, plsrmse))\n",
    "    print(\"%40s ,            PLS RMSE, %10.2f\"%(setname, plsrmse), file=fp)\n",
    "    print(\"%40s ,        PLS LOO RMSE, %10.2f\"%(setname, plsloormse))\n",
    "    print(\"%40s ,        PLS LOO RMSE, %10.2f\"%(setname, plsloormse), file=fp)\n",
    "    best_mape = 0.0\n",
    "    best_ncomp = 0\n",
    "    for ncomp in range(1, compstouse+1):\n",
    "        model = PLSRegression(n_components=ncomp)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "        if ncomp == 1:\n",
    "            best_mape = mape\n",
    "            best_ncomp = ncomp\n",
    "        else:\n",
    "            if mape < best_mape:\n",
    "                best_mape = mape\n",
    "                best_ncomp = ncomp\n",
    "    models_store[setname].pls_model_splitted = PLSRegression(n_components=best_ncomp)\n",
    "    models_store[setname].pls_model_splitted.fit(X_train, y_train)\n",
    "    y_pred = models_store[setname].pls_model_splitted.predict(X_test)\n",
    "    plsrmsetest = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    plsmapetest = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    y_pred = models_store[setname].pls_model_splitted.predict(X_train)\n",
    "    plsrmsetrain = mean_squared_error(y_train, y_pred, squared=False)\n",
    "    plsmapetrain = mean_absolute_percentage_error(y_train, y_pred)\n",
    "    print(\"%40s ,      PLS Train RMSE, %10.2f\"%(setname,plsrmsetrain))\n",
    "    print(\"%40s ,      PLS Train RMSE, %10.2f\"%(setname,plsrmsetrain), file=fp)\n",
    "    print(\"%40s ,      PLS  Test RMSE, %10.2f\"%(setname,plsrmsetest))\n",
    "    print(\"%40s ,      PLS  Test RMSE, %10.2f\"%(setname,plsrmsetest), file=fp)\n",
    "    print(\"%40s ,            PLS MAPE, %10.2f\"%(setname,plsmape))    \n",
    "    print(\"%40s ,            PLS MAPE, %10.2f\"%(setname,plsmape), file=fp)  \n",
    "    print(\"%40s ,      PLS Train MAPE, %10.2f\"%(setname,plsmapetrain))\n",
    "    print(\"%40s ,      PLS Train MAPE, %10.2f\"%(setname,plsmapetrain), file=fp)\n",
    "    print(\"%40s ,      PLS  Test MAPE, %10.2f\"%(setname,plsmapetest))\n",
    "    print(\"%40s ,      PLS  Test MAPE, %10.2f\"%(setname,plsmapetest), file=fp)\n",
    "    #print()\n",
    "\n",
    "    # Linear Regression\n",
    "    #lm = LinearRegression()\n",
    "    models_store[setname].lr_model = clr.custom_loss_lr (loss=clr.mean_average_error)\n",
    "    models_store[setname].lr_model.fit(X, Y)\n",
    "    y_pred_lr = models_store[setname].lr_model.predict(X)\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_lr)\n",
    "    wtmad_lr = wtamd2[setname]\n",
    "    lrrmse = mean_squared_error(Y, y_pred_lr, squared=False)\n",
    "    lrrmape = mean_absolute_percentage_error(Y, y_pred_lr)\n",
    "    # use LOO to get the RMSE\n",
    "    #cv = LeaveOneOut()\n",
    "    #model = LinearRegression()\n",
    "    #scores = cross_val_score(model, X, Y, \\\n",
    "    #        scoring='neg_mean_squared_error', \\\n",
    "    #        cv=cv, n_jobs=-1)\n",
    "    #loolrrmse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    #lm = LinearRegression()\n",
    "    models_store[setname].lr_model_splitted  = clr.custom_loss_lr (loss=clr.mean_average_error)\n",
    "    models_store[setname].lr_model_splitted.fit(X_train, y_train)\n",
    "    y_pred_lr = models_store[setname].lr_model_splitted.predict(X_test)\n",
    "    lrrmsetest = mean_squared_error(y_test, y_pred_lr, squared=False)\n",
    "    lrrmaoetest = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
    "    y_pred_lr = models_store[setname].lr_model_splitted.predict(X_train)\n",
    "    lrrmsetrain = mean_squared_error(y_train, y_pred_lr, squared=False)\n",
    "    lrrmaopetrain = mean_absolute_percentage_error(y_train, y_pred_lr)\n",
    "    #print(\"            LR WTMAD: %10.2f\"%wtmad_lr)\n",
    "    print(\"%40s ,             LR RMSE, %10.2f\"%(setname,lrrmse))\n",
    "    print(\"%40s ,             LR RMSE, %10.2f\"%(setname,lrrmse), file=fp)\n",
    "    #print(\"         LR LOO RMSE: %10.2f\"%loolrrmse)\n",
    "    print(\"%40s ,       LR Train RMSE, %10.2f\"%(setname,lrrmsetrain))\n",
    "    print(\"%40s ,       LR Train RMSE, %10.2f\"%(setname,lrrmsetrain), file=fp)\n",
    "    print(\"%40s ,        LR Test RMSE, %10.2f\"%(setname,lrrmsetest))\n",
    "    print(\"%40s ,        LR Test RMSE, %10.2f\"%(setname,lrrmsetest), file=fp)\n",
    "    print(\"%40s ,             LR MAPE, %10.2f\"%(setname,lrrmape))\n",
    "    print(\"%40s ,             LR MAPE, %10.2f\"%(setname,lrrmape), file=fp)\n",
    "    print(\"%40s ,       LR Train MAPE, %10.2f\"%(setname,lrrmaopetrain))\n",
    "    print(\"%40s ,       LR Train MAPE, %10.2f\"%(setname,lrrmaopetrain), file=fp)\n",
    "    print(\"%40s ,        LR Test MAPE, %10.2f\"%(setname,lrrmaoetest))\n",
    "    print(\"%40s ,        LR Test MAPE, %10.2f\"%(setname,lrrmaoetest), file=fp)\n",
    "    #print()\n",
    "\n",
    "    # Custom Loss Linear Regression\n",
    "    models_store[setname].lr_custom_model = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    models_store[setname].lr_custom_model.fit(X, Y)\n",
    "    y_pred_custom_lr = models_store[setname].lr_custom_model.predict(X)\n",
    "    wtamd2 = commonutils.wtmad2(setlist, Y, y_pred_custom_lr)\n",
    "    wtmad_custom_lr = wtamd2[setname]\n",
    "    custom_lrrmse = mean_squared_error(Y, y_pred_custom_lr, squared=False)\n",
    "    custom_lrrmape = mean_absolute_percentage_error(Y, y_pred_custom_lr)\n",
    "    # use LOO to get the RMSE canno use need to implemente full estimator API \n",
    "    # https://scikit-learn.org/1.5/developers/develop.html\n",
    "    #cv = LeaveOneOut()\n",
    "    #model = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    #scores = cross_val_score(model, X, Y, \\\n",
    "    #        scoring='neg_mean_squared_error', \\\n",
    "    #        cv=cv, n_jobs=-1)\n",
    "    #loocustom_lrrmse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    models_store[setname].lr_custom_model_splitted  = clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    models_store[setname].lr_custom_model_splitted.fit(X_train, y_train)\n",
    "    y_pred_custom_lr = models_store[setname].lr_custom_model_splitted.predict(X_test)\n",
    "    custom_lrrmsetest = mean_squared_error(y_test, y_pred_custom_lr, squared=False)\n",
    "    custom_lrrmapetest = mean_absolute_percentage_error(y_test, y_pred_custom_lr)\n",
    "    y_pred_custom_lr = models_store[setname].lr_custom_model_splitted.predict(X_train)\n",
    "    custom_lrrmsetrain = mean_squared_error(y_train, y_pred_custom_lr, squared=False)\n",
    "    custom_lrrmapetrain = mean_absolute_percentage_error(y_train, y_pred_custom_lr)\n",
    "    #print(\"     Custom LR WTMAD: %10.2f\"%wtmad_custom_lr)\n",
    "    print(\"%40s ,      Custom LR RMSE, %10.2f\"%(setname,custom_lrrmse))\n",
    "    print(\"%40s ,      Custom LR RMSE, %10.2f\"%(setname,custom_lrrmse), file=fp)\n",
    "    #print(\"  Custom LR LOO RMSE: %10.2f\"%loocustom_lrrmse)\n",
    "    print(\"%40s ,Custom LR Train RMSE, %10.2f\"%(setname,custom_lrrmsetrain))\n",
    "    print(\"%40s ,Custom LR Train RMSE, %10.2f\"%(setname,custom_lrrmsetrain), file=fp)\n",
    "    print(\"%40s , Custom LR Test RMSE, %10.2f\"%(setname,custom_lrrmsetest))\n",
    "    print(\"%40s , Custom LR Test RMSE, %10.2f\"%(setname,custom_lrrmsetest), file=fp)\n",
    "    print(\"%40s ,      Custom LR MAPE, %10.2f\"%(setname,custom_lrrmape))\n",
    "    print(\"%40s ,      Custom LR MAPE, %10.2f\"%(setname,custom_lrrmape), file=fp)\n",
    "    print(\"%40s ,Custom LR Train MAPE, %10.2f\"%(setname,custom_lrrmapetrain))\n",
    "    print(\"%40s ,Custom LR Train MAPE, %10.2f\"%(setname,custom_lrrmapetrain), file=fp)\n",
    "    print(\"%40s , Custom LR Test MAPE: %10.2f\"%(setname,custom_lrrmapetest))\n",
    "    print(\"%40s , Custom LR Test MAPE: %10.2f\"%(setname,custom_lrrmapetest), file=fp)\n",
    "\n",
    "fp.close()\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = None\n",
    "ssetname = \"Full\"\n",
    "pls_model_full = models_store[ssetname].plsmodel\n",
    "pls_model_full_splitted = models_store[ssetname].pls_model_splitted\n",
    "lr_model_full = models_store[ssetname].lr_model\n",
    "lr_model_full_splitted = models_store[ssetname].lr_model_splitted\n",
    "lr_custom_model_full = models_store[ssetname].lr_custom_model\n",
    "lr_custom_model_full_splitted = models_store[ssetname].lr_custom_model_splitted\n",
    "\n",
    "ypredFull_pls = []\n",
    "ypredFull_pls_split = []\n",
    "ypredFull_lr = []\n",
    "ypredFull_lr_split = []\n",
    "ypredFull_lr_custom = []\n",
    "ypredFull_lr_custom_split = []\n",
    "ypredFull_allbasissets = {}\n",
    "ypredFull_d3bj = []\n",
    "\n",
    "for method in models_results[ssetname].funcional_basisset_ypred:\n",
    "    if method.find(selected_functional) != -1:\n",
    "        ypredFull_allbasissets[method] = []\n",
    "\n",
    "setnamesFull = []\n",
    "\n",
    "fp = open(\"modelsresults.csv\", \"w\")\n",
    "\n",
    "for ssetname in supersetnames:\n",
    "    pls_model_ssetname = models_store[ssetname].plsmodel\n",
    "    pls_model_ssetname_splitted = models_store[ssetname].pls_model_splitted\n",
    "    lr_model_ssetname = models_store[ssetname].lr_model\n",
    "    lr_model_ssetname_splitted = models_store[ssetname].lr_model_splitted\n",
    "    lr_custom_model_ssetname = models_store[ssetname].lr_custom_model\n",
    "    lr_custom_model_ssetname_splitted = models_store[ssetname].lr_custom_model\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[ssetname].features, \\\n",
    "                                    models_results[ssetname].labels)\n",
    "    setlist = models_results[ssetname].setnames\n",
    "    setnamesFull.extend(setlist)\n",
    "\n",
    "    # SuperSet PLS \n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_pls.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS PLS\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS PLS\", mape), file=fp)\n",
    "    y_pred = pls_model_ssetname_splitted.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_pls_split.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS PLS split\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS PLS split\", mape), file=fp)\n",
    "\n",
    "    # SuperSet LR\n",
    "    y_pred = lr_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_lr.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS LR\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS LR\", mape), file=fp)\n",
    "    y_pred = lr_model_ssetname_splitted.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_lr_split.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS LR split\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS LR split\", mape), file=fp)\n",
    "    \n",
    "    # SuperSet Custom LR\n",
    "    y_pred = lr_custom_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_lr_custom.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS Custom LR\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS Custom LR\", mape), file=fp)\n",
    "    y_pred = lr_custom_model_ssetname_splitted.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull_lr_custom_split.extend(y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS Custom LR split\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , SS Custom LR split\", mape), file=fp)\n",
    "\n",
    "    # Full PLS\n",
    "    y_pred = pls_model_full.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full PLS\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full PLS\", mape), file=fp)\n",
    "    y_pred = pls_model_full_splitted.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full PLS split\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full PLS split\", mape), file=fp)\n",
    "\n",
    "    # Full LR\n",
    "    y_pred = lr_model_full.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full LR\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full LR\", mape), file=fp)\n",
    "    ypred = lr_model_full_splitted.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full LR split\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full LR split\", mape), file=fp)\n",
    "\n",
    "    # Full Custom LR\n",
    "    y_pred = lr_custom_model_full.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full Custom LR\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full Custom LR\", mape), file=fp)\n",
    "    y_pred = lr_custom_model_full_splitted.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full Custom LR split\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , Full Custom LR split\", mape), file=fp)\n",
    "\n",
    "    mape = models_results[ssetname].insidemethods_mape[\"D3(BJ)\"] \n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , D3(BJ)\", mape))\n",
    "    print(\" %60s MAPE , %7.3f\"%(ssetname+\" , D3(BJ)\", mape), file=fp)\n",
    "    ypredFull_d3bj.extend(models_results[ssetname].insidemethods_ypred[\"D3(BJ)\"])\n",
    "\n",
    "    for method in models_results[ssetname].funcional_basisset_ypred:\n",
    "        if method.find(selected_functional) != -1:\n",
    "            y_pred = models_results[ssetname].funcional_basisset_ypred[method]\n",
    "            ypredFull_allbasissets[method].extend(y_pred)\n",
    "            print(\" %60s MAPE , %7.3f\"%(ssetname+' , '+method, \\\n",
    "                                        mean_absolute_percentage_error(Y, y_pred)))\n",
    "            print(\" %60s MAPE , %7.3f\"%(ssetname+' , '+method, \\\n",
    "                                        mean_absolute_percentage_error(Y, y_pred)), file=fp)\n",
    "fp.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "basissets_touse = set(basis_sets + [selected_basisset])\n",
    "functional_to_use = set(functionals + [selected_functional])\n",
    "\n",
    "classes = []\n",
    "features = {}\n",
    "supersetnameslist = list(supersetnames.keys())\n",
    "for setname in featuresvalues_perset:\n",
    "    if setname in supersetnameslist:\n",
    "        print(\"Setname: \", setname)\n",
    "        for entry in featuresvalues_perset[setname]:\n",
    "            classes.append(supersetnameslist.index(setname))\n",
    "            #print(\"Entry: \", entry)\n",
    "            #for featurename in entry:\n",
    "            #    for functional in functional_to_use:\n",
    "            #        for basisset in basissets_touse:\n",
    "            #            if featurename.find(basisset) != -1 and \\\n",
    "            #                featurename.find(functional) != -1:\n",
    "            #                if featurename not in features:\n",
    "            #                    features[featurename] = []\n",
    "            #                features[featurename].append(entry[featurename])\n",
    "\n",
    "#print(\"Classes: \", len(classes))\n",
    "#for f in features:\n",
    "#    print(\"Feature: \", f, \" \", len(features[f]))\n",
    "#X = pd.DataFrame(features)\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results['Full'].features, \\\n",
    "                                    models_results['Full'].labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "    X, classes, test_size=0.20, random_state=41)\n",
    "accuracys = []\n",
    "numoftrees = []\n",
    "for ntrees in range(10, 200, 10):\n",
    "    rf = RandomForestClassifier(n_estimators=ntrees, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracys.append(accuracy)\n",
    "    numoftrees.append(ntrees)\n",
    "\n",
    "bestaccuracy = max(accuracys)   \n",
    "bestntrees = numoftrees[accuracys.index(bestaccuracy)]\n",
    "print(\"Best accuracy: \", max(accuracys), \" with \", bestntrees, \" trees\")\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=bestntrees, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "testaccuracy = rf.score(X_test, y_test)\n",
    "trainaccuracy = rf.score(X_train, y_train)\n",
    "overallaccuracy = rf.score(X, classes)\n",
    "print(\"  Train accuracy: %5.2f\"%(trainaccuracy))\n",
    "print(\"   Test accuracy: %5.2f\"%(testaccuracy))\n",
    "print(\"Overall accuracy: %5.2f\"%(overallaccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert(len(ypredFull_pls) == len(ypredFull_pls_split))\n",
    "assert(len(ypredFull_pls) == len(ypredFull_lr))\n",
    "assert(len(ypredFull_pls) == len(ypredFull_lr_split)) \n",
    "assert(len(ypredFull_pls) == len(ypredFull_lr_custom))\n",
    "assert(len(ypredFull_pls) == len(ypredFull_lr_custom_split))\n",
    "assert(len(ypredFull_pls) == len(models_results[\"Full\"].labels))\n",
    "assert(len(ypredFull_pls) == len(setnamesFull))\n",
    "assert(len(ypredFull_pls) == len(ypredFull_d3bj))\n",
    "for method in ypredFull_allbasissets:\n",
    "    assert(len(ypredFull_pls) == len(ypredFull_allbasissets[method]))\n",
    "\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results['Full'].features, \\\n",
    "                                    models_results['Full'].labels)\n",
    "setlist = models_results['Full'].setnames\n",
    "\n",
    "y_pred_RF_PLS = []\n",
    "y_pred_RF_PLS_split = []\n",
    "y_pred_RF_LR = []\n",
    "y_pred_RF_LR_split = []\n",
    "y_pred_RF_LR_CUSTOM = []\n",
    "y_pred_RF_LR_CUSTOM_split = []\n",
    "for i in range(len(X)):\n",
    "    c = rf.predict([X[i]])\n",
    "    supersetrname= supersetnameslist[c[0]]\n",
    "    #print(\"X: \", i, \" Y: \", Y[i], \" C: \", c, \" ==> \", supersetnameslist[c[0]])\n",
    "    \n",
    "    y = models_store[supersetrname].plsmodel.predict([X[i]])\n",
    "    if len(y.shape) == 2:\n",
    "        y = y[:,0]\n",
    "    y_pred_RF_PLS.append(y[0])\n",
    "    y = models_store[supersetrname].pls_model_splitted.predict([X[i]])\n",
    "    if len(y.shape) == 2:\n",
    "        y = y[:,0]\n",
    "    y_pred_RF_PLS_split.append(y[0])\n",
    "\n",
    "    y = models_store[supersetrname].lr_model.predict([X[i]])\n",
    "    if len(y.shape) == 2:\n",
    "        y = y[:,0]\n",
    "    y_pred_RF_LR.append(y[0])\n",
    "    y = models_store[supersetrname].lr_model_splitted.predict([X[i]])\n",
    "    if len(y.shape) == 2:\n",
    "        y = y[:,0]\n",
    "    y_pred_RF_LR_split.append(y[0])\n",
    "\n",
    "    y = models_store[supersetrname].lr_custom_model.predict([X[i]])\n",
    "    if len(y.shape) == 2:\n",
    "        y = y[:,0]\n",
    "    y_pred_RF_LR_CUSTOM.append(y[0])\n",
    "    y = models_store[supersetrname].lr_custom_model_splitted.predict([X[i]])\n",
    "    if len(y.shape) == 2:\n",
    "        y = y[:,0]\n",
    "    y_pred_RF_LR_CUSTOM_split.append(y[0])\n",
    "\n",
    "fp = open(\"modelsresults.csv\", \"a\")\n",
    "\n",
    "predictred = {}\n",
    "\n",
    "predictred[\"Full , using PLS Full\"] = \\\n",
    "    models_store[\"Full\"].plsmodel.predict(X)\n",
    "predictred[\"Full , using PLS Full split\"] = \\\n",
    "    models_store[\"Full\"].pls_model_splitted.predict(X)\n",
    "predictred[\"Full , using PLS SS\"] = ypredFull_pls\n",
    "predictred[\"Full , using PLS SS split\"] = ypredFull_pls_split\n",
    "\n",
    "predictred[\"Full , using LR Full\"] = \\\n",
    "    models_store[\"Full\"].lr_model.predict(X)\n",
    "predictred[\"Full , using LR Full split\"] = \\\n",
    "    models_store[\"Full\"].lr_model_splitted.predict(X)\n",
    "predictred[\"Full , using LR SS\"] = ypredFull_lr\n",
    "predictred[\"Full , using LR SS split\"] = ypredFull_lr_split\n",
    "\n",
    "predictred[\"Full , using Custom LR Full\"] = \\\n",
    "    models_store[\"Full\"].lr_custom_model.predict(X)\n",
    "predictred[\"Full , using Custom LR Full split\"] = \\\n",
    "    models_store[\"Full\"].lr_custom_model_splitted.predict(X)\n",
    "predictred[\"Full , using Custom LR SS\"] = ypredFull_lr_custom\n",
    "predictred[\"Full , using Custom LR SS split\"] = ypredFull_lr_custom_split\n",
    "\n",
    "predictred[\"Full , using PLSRF\"] = y_pred_RF_PLS\n",
    "predictred[\"Full , using PLSRF split\"] = y_pred_RF_PLS_split\n",
    "predictred[\"Full , using LRRF\"] = y_pred_RF_LR\n",
    "predictred[\"Full , using LRRF split\"] = y_pred_RF_LR_split\n",
    "predictred[\"Full , using Custom LRRF\"] = y_pred_RF_LR_CUSTOM\n",
    "predictred[\"Full , using Custom LRRF split\"] = y_pred_RF_LR_CUSTOM_split\n",
    "\n",
    "for m in predictred:\n",
    "    ypred = predictred[m]\n",
    "    wtamd2_full_usingss = \\\n",
    "        commonutils.wtmad2(setnamesFull, \\\n",
    "                        ypred, \\\n",
    "                        models_results[\"Full\"].labels)\n",
    "    wtamd2 = wtamd2_full_usingss[\"Full\"]\n",
    "    print(\"%44s %7.3f\"%(m + \" WTMAD2, \", wtamd2))\n",
    "    print(\"%44s %7.3f\"%(m + \" WTMAD2, \", wtamd2), file=fp)\n",
    "\n",
    "for method in ypredFull_allbasissets:\n",
    "    wtamd2_full_allbasissets = \\\n",
    "        commonutils.wtmad2(setnamesFull, \\\n",
    "                            ypredFull_allbasissets[method], \\\n",
    "                            models_results[\"Full\"].labels)\n",
    "    wtamd2 = wtamd2_full_allbasissets[\"Full\"]\n",
    "    print(\"%44s %7.3f\"%(\"Full , \"+ method + \" WTMAD2, \", wtamd2))\n",
    "    print(\"%44s %7.3f\"%(\"Full , \"+ method + \" WTMAD2, \", wtamd2), file=fp)\n",
    "\n",
    "wtamd2_full_d3bj = \\\n",
    "    commonutils.wtmad2(setnamesFull, \\\n",
    "                        ypredFull_d3bj, \\\n",
    "                        models_results[\"Full\"].labels)\n",
    "wtamd2 = wtamd2_full_d3bj[\"Full\"]\n",
    "print(\"%44s %7.3f\"%(\"Full , D3(BJ) WTMAD2, \", wtamd2))\n",
    "print(\"%44s %7.3f\"%(\"Full , D3(BJ) WTMAD2, \", wtamd2), file=fp)\n",
    "\n",
    "for m in predictred:\n",
    "    ypred = predictred[m]\n",
    "    mape_full_usingss = mean_absolute_percentage_error(\\\n",
    "        models_results[\"Full\"].labels, ypred)\n",
    "    print(\"%44s %7.3f\"%(m + \" MAPE, \", mape_full_usingss))\n",
    "    print(\"%44s %7.3f\"%(m + \" MAPE, \", mape_full_usingss), file=fp)\n",
    "\n",
    "for method in ypredFull_allbasissets:\n",
    "    mape_full_allbasissets = mean_absolute_percentage_error(\\\n",
    "        models_results[\"Full\"].labels, ypredFull_allbasissets[method])\n",
    "    print(\"%44s %7.3f\"%(\"Full , \" + method + \" MAPE, \", mape_full_allbasissets))\n",
    "    print(\"%44s %7.3f\"%(\"Full , \" + method + \" MAPE, \", mape_full_allbasissets), file=fp)\n",
    "\n",
    "mape_full_d3bj = mean_absolute_percentage_error(\\\n",
    "    models_results[\"Full\"].labels, ypredFull_d3bj)\n",
    "print(\"%44s %7.3f\"%(\"Full , D3(BJ) MAPE, \", mape_full_d3bj))\n",
    "print(\"%44s %7.3f\"%(\"Full , D3(BJ) MAPE, \", mape_full_d3bj), file=fp)\n",
    "\n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract PLS and LR coefficients and equations\n",
    "\n",
    "def lr_test_and_rpint (lr_model, X, Y, name, fp):\n",
    "\n",
    "    y_pred = lr_model.predict(X)\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    #y_pred_eq = lr_model.intercept_ + np.dot(X, lr_model.coef_.T)\n",
    "    y_pred_eq = lr_model.get_intercept() + np.dot(X, lr_model.get_coefficients().T)\n",
    "    rmse_eq = mean_squared_error(Y, y_pred_eq, squared=False)\n",
    "    diffperc = np.abs(rmse - rmse_eq) / rmse * 100.0\n",
    "    if diffperc > 0.0001:\n",
    "        print(\"%40s RMSE Diff %5.3f \"%(name, diffperc), \"%\")\n",
    "        print(\"%40s RMSE Diff %5.3f \"%(name, diffperc), \"%\", file=fp)\n",
    "        exit(1)\n",
    "\n",
    "    print(\"%40s , %30s , %12.4f\"%(name, \"Intercept\", lr_model.get_intercept()))\n",
    "    print(\"%40s , %30s , %12.4f\"%(name, \"Intercept\", lr_model.get_intercept()), file=fp)\n",
    "    for i, f in enumerate(features_names):\n",
    "        #print(\"  %15s %12.8e\"%(f, lr_model.coef_.T[i]))\n",
    "        print(\"%40s , %30s , %12.4f\"%(name, f, lr_model.get_coefficients().T[i]))\n",
    "        print(\"%40s , %30s , %12.4f\"%(name, f, lr_model.get_coefficients().T[i]), file=fp)\n",
    "    #print(\"\")\n",
    "    #print(\"\", file=fp)\n",
    "\n",
    "def pls_test_and_rpint (pls_model, X, Y, name, fp):\n",
    "    \n",
    "        y_pred = pls_model.predict(X)\n",
    "        rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "        X_e = X.copy()\n",
    "        X_e -= pls_model._x_mean\n",
    "        X_e /= pls_model._x_std\n",
    "        y_pred_eq = np.dot(X_e, pls_model.coef_.T)\n",
    "        y_pred_eq += pls_model._y_mean\n",
    "        rmse_eq = mean_squared_error(Y, y_pred_eq, squared=False)\n",
    "        diffperc = np.abs(rmse - rmse_eq) / rmse * 100.0\n",
    "        if diffperc > 0.0001:\n",
    "            print(\"%40s RMSE Diff %5.3f \"%(name, diffperc), \"%\")\n",
    "            print(\"%40s RMSE Diff %5.3f \"%(name, diffperc), \"%\", file=fp)\n",
    "            exit(1)\n",
    "            \n",
    "        for i, f in enumerate(features_names):\n",
    "            print(\"%40s , %30s , %12.4f , %16.4f , %16.4f \"%(\\\n",
    "                name, f, \\\n",
    "                pls_model.coef_.T[i], \\\n",
    "                pls_model._x_mean[i], \\\n",
    "                pls_model._x_std[i]))\n",
    "            print(\"%40s , %30s , %12.4f , %16.4f , %16.4f \"%(\\\n",
    "                name, f, \\\n",
    "                pls_model.coef_.T[i], \\\n",
    "                pls_model._x_mean[i], \\\n",
    "                pls_model._x_std[i]), file=fp)\n",
    "        #print(\"\")\n",
    "        #print(\"\", file=fp)\n",
    "\n",
    "fp = open(\"modelscoefficients.txt\", \"w\")    \n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "    lr_model = models_store[setname].lr_model\n",
    "    lr_model_splitted = models_store[setname].lr_model_splitted\n",
    "    lr_custom_model = models_store[setname].lr_custom_model\n",
    "    lr_custom_model_splitted = models_store[setname].lr_custom_model_splitted\n",
    "    pls_model = models_store[setname].plsmodel\n",
    "    pls_model_splitted = models_store[setname].pls_model_splitted\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    # LR model\n",
    "    lr_test_and_rpint (lr_model, X, Y, setname + \" LR \", fp)\n",
    "    lr_test_and_rpint (lr_model_splitted, X, Y, setname + \" LR split \", fp)\n",
    "\n",
    "    # Custom LR model\n",
    "    lr_test_and_rpint (lr_custom_model, X, Y, setname + \" Custom LR \", fp)\n",
    "    lr_test_and_rpint (lr_custom_model_splitted, X, Y, setname + \" Custom LR split \", fp)\n",
    "\n",
    "    # PLS model\n",
    "    pls_test_and_rpint (pls_model, X, Y, setname + \" PLS \", fp)\n",
    "    pls_test_and_rpint (pls_model_splitted, X, Y, setname + \" PLS split \", fp)\n",
    "\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
