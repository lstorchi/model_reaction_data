{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commonutils\n",
    "\n",
    "rootdir = \"../datasets/ML_data/W4-11\"\n",
    "labelsfilename = \"../datasets/ML_data/W4-11/labels.txt\"\n",
    "howmanydifs = 3\n",
    "\n",
    "allvalues1, basic_pbedescriptors1, basic_hfdescriptors1 =\\\n",
    "      commonutils.read_dataset(rootdir, labelsfilename, howmanydifs)\n",
    "\n",
    "print(\"Number of samples: \", len(allvalues1))\n",
    "print(\"Number of basic PBE descriptors: \", len(basic_pbedescriptors1))\n",
    "print(\"Number of basic  HF descriptors: \", len(basic_hfdescriptors1))\n",
    "\n",
    "rootdir = \"../datasets/ML_data/MB16-43\"\n",
    "labelsfilename = \"../datasets/ML_data/MB16-43/labels.txt\"\n",
    "howmanydifs = 3\n",
    "\n",
    "allvalues2, basic_pbedescriptors2, basic_hfdescriptors2 =\\\n",
    "      commonutils.read_dataset(rootdir, labelsfilename, howmanydifs)\n",
    "\n",
    "print(\"Number of samples: \", len(allvalues2))\n",
    "print(\"Number of basic PBE descriptors: \", len(basic_pbedescriptors2))\n",
    "print(\"Number of basic  HF descriptors: \", len(basic_hfdescriptors2))\n",
    "\n",
    "allvalues = allvalues1 + allvalues2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "for methodid in range(howmanydifs):\n",
    "    y_pred = []\n",
    "    labels = []\n",
    "    for val in allvalues:\n",
    "        y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "        labels.append(val[\"label\"])\n",
    "    \n",
    "    print(\"Method\", methodid+1, \\\n",
    "          \"R2 score  : %9.3f\"%(r2_score(labels, y_pred)))\n",
    "    print(\"Method\", methodid+1, \\\n",
    "          \"RMSE score: %9.3f\"%(mean_squared_error(labels, y_pred, squared=False)))\n",
    "\n",
    "print(\"Our data\")\n",
    "y_pred = []\n",
    "labels = []\n",
    "for val in allvalues:\n",
    "    labels.append(val[\"label\"])\n",
    "    y_pred.append(val[\"pbeenergydiff\"][\"PBE_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "print(\"PBE R2 score  : %9.3f\"%(r2_score(labels, y_pred)))\n",
    "print(\"PBE RMSE score: %9.3f\"%(mean_squared_error(labels, y_pred, squared=False)))\n",
    "\n",
    "y_pred = []\n",
    "labels = []\n",
    "for val in allvalues:\n",
    "    labels.append(val[\"label\"])\n",
    "    y_pred.append(val[\"hfenergydiff\"][\"HF_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "print(\" HF R2 score  : %9.3f\"%(r2_score(labels, y_pred)))\n",
    "print(\" HF RMSE score: %9.3f\"%(mean_squared_error(labels, y_pred, squared=False)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build correclation and print\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fulldescriptors =[]\n",
    "labels = []\n",
    "\n",
    "for idx, val in enumerate(allvalues):\n",
    "    fulldescriptors.append({})\n",
    "    fulldescriptors[idx].update(val[\"pbeenergydiff\"])\n",
    "    fulldescriptors[idx].update(val[\"hfenergydiff\"])\n",
    "\n",
    "    labels.append(val[\"label\"])\n",
    "\n",
    "moldescriptors_featues, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (fulldescriptors, labels)\n",
    "\n",
    "df = pd.DataFrame(moldescriptors_featues, columns=features_names)\n",
    "\n",
    "top_corr = commonutils.get_top_correlations_blog(df, 0.85)\n",
    "for tc in top_corr:\n",
    "    print(\"%35s %35s %9.3f\"%(tc[0], tc[1], tc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA quick to see the data\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "fulldescriptors =[]\n",
    "labels = []\n",
    "\n",
    "for idx, val in enumerate(allvalues):\n",
    "    fulldescriptors.append({})\n",
    "    fulldescriptors[idx].update(val[\"pbeenergydiff\"])\n",
    "    fulldescriptors[idx].update(val[\"hfenergydiff\"])\n",
    "\n",
    "    labels.append(val[\"label\"])\n",
    "\n",
    "moldescriptors_featues, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (fulldescriptors, labels)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "fit = pca.fit(moldescriptors_featues)\n",
    "# summarize components\n",
    "print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "\n",
    "print(\"Loadings\")\n",
    "loadings = pd.DataFrame(pca.components_.T, columns=['PC1', 'PC2', 'PC3'], index=features_names)\n",
    "print(loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test using PLS \n",
    "import models\n",
    "\n",
    "fulldescriptors =[]\n",
    "labels = []\n",
    "\n",
    "for idx, val in enumerate(allvalues):\n",
    "    fulldescriptors.append({})\n",
    "    fulldescriptors[idx].update(val[\"pbeenergydiff\"])\n",
    "    fulldescriptors[idx].update(val[\"hfenergydiff\"])\n",
    "\n",
    "    labels.append(val[\"label\"])\n",
    "\n",
    "moldescriptors_featues, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (fulldescriptors, labels)\n",
    "\n",
    "maxcomp = moldescriptors_featues.shape[1]\n",
    "# search fo the best number od components and build final model\n",
    "perc_split = 0.2\n",
    "ncomps, rmses_test, rmses_train, r2s_test, r2s_train = \\\n",
    "    models.pls_model (0.2, moldescriptors_featues, Y, \\\n",
    "                      ncomp_start = 1, ncomp_max = maxcomp)\n",
    "r2max_comps = np.argmax(r2s_test)+1\n",
    "rmsemin_comps = np.argmin(rmses_test)+1\n",
    "compstouse = min(rmsemin_comps, r2max_comps)\n",
    "\n",
    "perc_split = 0.2\n",
    "rmse_train, rmse_test, r2_train, r2_test, rmse_full, r2_full , \\\n",
    "        plsmodel, X_train, X_test, y_train, y_test  = \\\n",
    "        models.pls_model (0.2, moldescriptors_featues, Y, False, compstouse)\n",
    "perc_split = 0.0\n",
    "rmse, r2 = models.pls_model (perc_split, moldescriptors_featues, Y, False, \\\n",
    "                  compstouse, leaveoneout=True)\n",
    "\n",
    "print(\"PLS model with %d components\"%(compstouse))\n",
    "print(\"Train RMSE: %9.3f\"%(rmse_train))\n",
    "print(\"Test  RMSE: %9.3f\"%(rmse_test))\n",
    "print(\"Full  RMSE: %9.3f\"%(rmse_full))\n",
    "print(\"Train R2  : %9.3f\"%(r2_train))\n",
    "print(\"Test  R2  : %9.3f\"%(r2_test))\n",
    "print(\"Full  R2  : %9.3f\"%(r2_full))\n",
    "print(\"LOO   RMSE: %9.3f\"%(rmse))\n",
    "print(\"LOO   R2  : %9.3f\"%(r2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test using permutation features importance\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "scoring = ['r2', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error']\n",
    "    \n",
    "r_multi = permutation_importance(plsmodel, X_test, y_test, n_repeats=30, \\\n",
    "                                random_state=0, scoring=scoring)\n",
    "\n",
    "for metric in r_multi:\n",
    "    print(f\"{metric}\"+ \" Used\")\n",
    "    r = r_multi[metric]\n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "            print(f\"{features_names[i]:<30}\"\n",
    "              f\"{r.importances_mean[i]:.3e}\"\n",
    "              f\" +/- {r.importances_std[i]:.3e}\")\n",
    "    print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
