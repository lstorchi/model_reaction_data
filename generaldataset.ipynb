{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import commonutils\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "setnames = [\"W4-11\", \"MB16-43\"]\n",
    "howmanydifs = 3\n",
    "methods = {\"PBE\" : [\"Nuclear Repulsion  :\", \\\n",
    "                    \"One Electron Energy:\", \\\n",
    "                    \"Two Electron Energy:\", \\\n",
    "                    \"Potential Energy   :\", \\\n",
    "                    \"Kinetic Energy     :\", \\\n",
    "                    \"E(X)               :\"  , \\\n",
    "                    \"E(C)               :\"  , \\\n",
    "                    \"Dispersion correction\", \\\n",
    "                    \"FINAL SINGLE POINT ENERGY\"], \n",
    "            \"HF\" : [\"Nuclear Repulsion  :\", \\\n",
    "                    \"One Electron Energy:\", \\\n",
    "                    \"Two Electron Energy:\", \\\n",
    "                    \"Potential Energy   :\", \\\n",
    "                    \"Kinetic Energy     :\", \\\n",
    "                    \"Dispersion correction\", \\\n",
    "                    \"FINAL SINGLE POINT ENERGY\"]\n",
    "            }\n",
    "\n",
    "allvalues_perset = {}\n",
    "\n",
    "allvalues = []\n",
    "for i, setname in enumerate(setnames):\n",
    "      print(\"Reading dataset: \", setname)\n",
    "      rootdir = \"../datasets/ML_data/\" + setname\n",
    "      labelsfilename = \"../datasets/ML_data/\"+setname+\"/labels.txt\"\n",
    "      allvalues_perset[setname] = None\n",
    "\n",
    "      allvalues_perset[setname] =\\\n",
    "            commonutils.read_dataset(rootdir, labelsfilename, howmanydifs, methods)\n",
    "      \n",
    "      print(\"Number of samples: \", len(allvalues_perset[setname]))\n",
    "      print(\"Number of basic PBE descriptors: \", len(allvalues_perset[setname]))\n",
    "      print(\"Number of basic  HF descriptors: \", len(allvalues_perset[setname]))\n",
    "      \n",
    "      allvalues += allvalues_perset[setname]\n",
    "      print(\"\")\n",
    "\n",
    "allvalues_perset[\"Full\"] = allvalues      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "print(\"\")\n",
    "for methodid in range(howmanydifs):\n",
    "    for setname in setnames + [\"Full\"]:\n",
    "        print(\"%10s, %10s , \"%(str(methodid), setname), end=\"\")\n",
    "        y_pred = []\n",
    "        labels = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "            labels.append(val[\"label\"])\n",
    "        print(\"%9.3f , \"%(r2_score(labels, y_pred)), end=\"\")\n",
    "        print(\"%9.3f \"%(mean_squared_error(labels, y_pred, squared=False)), end=\"\")    \n",
    "        print(\"\")\n",
    "for method in methods:\n",
    "    for setname in setnames + [\"Full\"]:\n",
    "        print(\"%10s, %10s , \"%(\"Our_\"+str(method), setname), end=\"\")\n",
    "        y_pred = []\n",
    "        labels = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "            labels.append(val[\"label\"])\n",
    "        print(\"%9.3f , \"%(r2_score(labels, y_pred)), end=\"\")\n",
    "        print(\"%9.3f \"%(mean_squared_error(labels, y_pred, squared=False)), end=\"\")    \n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build correclation and print\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "fulldescriptors = {}\n",
    "labels = {}\n",
    "top_correlation_perset = {}\n",
    "\n",
    "for setname in setnames + [\"Full\"]:\n",
    "    fulldescriptors[setname] = []\n",
    "    labels[setname] = []\n",
    "    for idx, val in enumerate(allvalues_perset[setname]):\n",
    "        fulldescriptors[setname].append({})\n",
    "        for method in methods:\n",
    "            fulldescriptors[setname][idx].update(val[method+\"_energydiff\"])\n",
    "\n",
    "        labels[setname].append(val[\"label\"])\n",
    "\n",
    "    moldescriptors_featues, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (fulldescriptors[setname], labels[setname])\n",
    "\n",
    "    df = pd.DataFrame(moldescriptors_featues, columns=features_names)\n",
    "\n",
    "    top_corr = commonutils.get_top_correlations_blog(df, 0.95)\n",
    "\n",
    "    top_correlation_perset[setname] = top_corr\n",
    "    if DEBUG:\n",
    "        print(\"Top correlations for set: \", setname)\n",
    "        for tc in top_corr:\n",
    "            print(\"%35s %35s %9.3f\"%(tc[0], tc[1], tc[2]))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA quick to see the data\n",
    "\n",
    "if DEBUG:\n",
    "    from sklearn.decomposition import PCA\n",
    "    import numpy as np\n",
    "\n",
    "    for setname in setnames + [\"Full\"]:\n",
    "        moldescriptors_featues, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (fulldescriptors[setname], \\\n",
    "                                         labels[setname])\n",
    "\n",
    "        pca = PCA(n_components=3)\n",
    "        fit = pca.fit(moldescriptors_featues)\n",
    "        # summarize components\n",
    "        print(\"PCA for set: \", setname)\n",
    "        print(\"Explained Variance: %s\" % fit.explained_variance_ratio_)\n",
    "        loadings = pd.DataFrame(pca.components_.T, \\\n",
    "                                columns=['PC1', 'PC2', 'PC3'], \\\n",
    "                                    index=features_names)\n",
    "        print(loadings)\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test using PLS \n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "import models\n",
    "\n",
    "mostimportantefeatures_persetname = {}\n",
    "\n",
    "print(\"SetName , Comp. , RMSE Train, RMSE Test, RMSE Full, R2 Train, \" + \\\n",
    "      \"R2 Test, R2 Full, RMSE LOO, R2 LOO\")\n",
    "for setname in setnames + [\"Full\"]:\n",
    "    mostimportantefeatures_persetname[setname] = []\n",
    "    moldescriptors_featues, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (fulldescriptors[setname], \\\n",
    "                                 labels[setname])\n",
    "\n",
    "    maxcomp = moldescriptors_featues.shape[1]\n",
    "    # search fo the best number od components and build final model\n",
    "    perc_split = 0.2\n",
    "    ncomps, rmses_test, rmses_train, r2s_test, r2s_train = \\\n",
    "        models.pls_model (0.2, moldescriptors_featues, Y, \\\n",
    "                      ncomp_start = 1, ncomp_max = maxcomp)\n",
    "    r2max_comps = np.argmax(r2s_test)+1\n",
    "    rmsemin_comps = np.argmin(rmses_test)+1\n",
    "    compstouse = min(rmsemin_comps, r2max_comps)\n",
    "\n",
    "    perc_split = 0.2\n",
    "    rmse_train, rmse_test, r2_train, r2_test, rmse_full, r2_full , \\\n",
    "        plsmodel, X_train, X_test, y_train, y_test  = \\\n",
    "            models.pls_model (0.2, moldescriptors_featues, Y, False, compstouse)\n",
    "    perc_split = 0.0\n",
    "    rmse, r2 = models.pls_model (perc_split, moldescriptors_featues, Y, False, \\\n",
    "                  compstouse, leaveoneout=True)\n",
    "    \n",
    "    print(\"%10s, %4d , %9.3f , %9.3f , %9.3f , %9.3f , %9.3f , %9.3f , %9.3f , %9.3f\"%(\\\n",
    "        setname, compstouse, \\\n",
    "        rmse_train, rmse_test, rmse_full, \\\n",
    "        r2_train, r2_test, r2_full, \\\n",
    "        rmse, r2))\n",
    "\n",
    "    scoring = 'neg_mean_squared_error'\n",
    "\n",
    "    r = permutation_importance(plsmodel, X_test, y_test, n_repeats=30, \\\n",
    "                            random_state=0, scoring=scoring)\n",
    "    \n",
    "    for i in r.importances_mean.argsort()[::-1]:\n",
    "        mostimportantefeatures_persetname[setname].append(features_names[i])\n",
    "\n",
    "    if DEBUG:\n",
    "        scoring = ['r2', 'neg_mean_squared_error', 'neg_mean_absolute_error']\n",
    "    \n",
    "        r_multi = permutation_importance(plsmodel, X_test, y_test, n_repeats=30, \\\n",
    "                                random_state=0, scoring=scoring)\n",
    "\n",
    "        for metric in r_multi:\n",
    "            print(f\"{metric}\"+ \" Used\")\n",
    "            r = r_multi[metric]\n",
    "            for i in r.importances_mean.argsort()[::-1]:\n",
    "                if r.importances_mean[i] - 2 * r.importances_std[i] > 0:\n",
    "                    print(f\"{features_names[i]:<30}\"\n",
    "                        f\"{r.importances_mean[i]:.3e}\"\n",
    "                        f\" +/- {r.importances_std[i]:.3e}\")\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for setname in setnames + [\"Full\"]:\n",
    "    print(\"Most important features for set: \", setname)\n",
    "    for tc in mostimportantefeatures_persetname[setname]:\n",
    "        print(\"%35s\"%(tc))\n",
    "    print(\"\")\n",
    "    for tc in top_correlation_perset[setname]:\n",
    "        print(\"%35s %35s %9.3f\"%(tc[0], tc[1], tc[2]))\n",
    "#remove some features based on importance and correlation\n",
    "\"\"\"\n",
    "features_to_remove = [\"HF_Nuclear_Repulsion\", \\\n",
    "                      \"HF_Two_Electron_Energy\", \\\n",
    "                      \"HF_One_Electron_Energy\"]\n",
    "featureset = [\"hfenergydiff\"]\n",
    "\n",
    "commonutils.remove_features(allvalues, features_to_remove, featureset)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test using PLS \n",
    "import models\n",
    "\n",
    "fulldescriptors =[]\n",
    "labels = []\n",
    "\n",
    "for idx, val in enumerate(allvalues):\n",
    "    fulldescriptors.append({})\n",
    "    fulldescriptors[idx].update(val[\"pbeenergydiff\"])\n",
    "    fulldescriptors[idx].update(val[\"hfenergydiff\"])\n",
    "\n",
    "    labels.append(val[\"label\"])\n",
    "\n",
    "moldescriptors_featues, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (fulldescriptors, labels)\n",
    "\n",
    "maxcomp = moldescriptors_featues.shape[1]\n",
    "# search fo the best number od components and build final model\n",
    "perc_split = 0.2\n",
    "ncomps, rmses_test, rmses_train, r2s_test, r2s_train = \\\n",
    "    models.pls_model (0.2, moldescriptors_featues, Y, \\\n",
    "                      ncomp_start = 1, ncomp_max = maxcomp)\n",
    "r2max_comps = np.argmax(r2s_test)+1\n",
    "rmsemin_comps = np.argmin(rmses_test)+1\n",
    "compstouse = min(rmsemin_comps, r2max_comps)\n",
    "\n",
    "perc_split = 0.2\n",
    "rmse_train, rmse_test, r2_train, r2_test, rmse_full, r2_full , \\\n",
    "        plsmodel, X_train, X_test, y_train, y_test  = \\\n",
    "        models.pls_model (0.2, moldescriptors_featues, Y, False, compstouse)\n",
    "perc_split = 0.0\n",
    "rmse, r2 = models.pls_model (perc_split, moldescriptors_featues, Y, False, \\\n",
    "                  compstouse, leaveoneout=True)\n",
    "\n",
    "print(\"PLS model with %d components\"%(compstouse))\n",
    "print(\"Train RMSE: %9.3f\"%(rmse_train))\n",
    "print(\"Test  RMSE: %9.3f\"%(rmse_test))\n",
    "print(\"Full  RMSE: %9.3f\"%(rmse_full))\n",
    "print(\"Train R2  : %9.3f\"%(r2_train))\n",
    "print(\"Test  R2  : %9.3f\"%(r2_test))\n",
    "print(\"Full  R2  : %9.3f\"%(r2_full))\n",
    "print(\"LOO   RMSE: %9.3f\"%(rmse))\n",
    "print(\"LOO   R2  : %9.3f\"%(r2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-rdkit-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
