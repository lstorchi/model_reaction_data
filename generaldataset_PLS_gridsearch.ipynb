{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from importlib import reload\n",
    "from commonutils import ModelResults\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"./data/allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"./data/methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"./data/fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"./data/functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"./data/basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"./data/supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(commonutils)\n",
    "\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        wtmad = None\n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestinsidemethod_wtmad:\n",
    "                models_results[setname].bestinsidemethod_wtmad = wtmad\n",
    "                models_results[setname].bestinsidemethod_name_wtmad = str(methodid)\n",
    "                models_results[setname].y_pred_bestinsidemethod_wtmad = y_pred\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestinsidemethod_rmse:\n",
    "            models_results[setname].bestinsidemethod_rmse = rmse\n",
    "            models_results[setname].bestinsidemethod_name_rmse = str(methodid)\n",
    "            models_results[setname].y_pred_bestinsidemethod_rmse = y_pred\n",
    "\n",
    "    for j, method in enumerate(methods):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        wtmad = None            \n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestourmethod_wtmad:\n",
    "                models_results[setname].bestourmethod_wtmad = wtmad\n",
    "                models_results[setname].bestourmethod_name_wtmad = method\n",
    "                models_results[setname].y_pred_bestourmethod_wtmad = y_pred\n",
    "        \n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestourmethod_rmse:\n",
    "            models_results[setname].bestourmethod_rmse = rmse\n",
    "            models_results[setname].bestourmethod_name_rmse = method\n",
    "            models_results[setname].y_pred_bestourmethod_rmse = y_pred\n",
    "\n",
    "bestmnethodscount = {}\n",
    "setofbestourmethodswtamd = {}\n",
    "for setname in fullsetnames:\n",
    "    if models_results[setname].bestourmethod_name_rmse in bestmnethodscount:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] += 1\n",
    "    else:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] = 1\n",
    "\n",
    "    if models_results[setname].bestourmethod_name_wtmad != \"\":\n",
    "        if models_results[setname].bestourmethod_name_wtmad in setofbestourmethodswtamd:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] += 1\n",
    "        else:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mainfunc (mainmodelsID, allfeatures, CORRCUT, \\\n",
    "            selected_functional, selected_basisset, \\\n",
    "            functionals, basis_sets, fullsetnames, \\\n",
    "            allvalues_perset, models_results, supersetnames):\n",
    "\n",
    "    for setname in fullsetnames:\n",
    "        desciptors = {}\n",
    "        for val in allvalues_perset[setname]:\n",
    "            k = selected_functional + \"-\" + \\\n",
    "                selected_basisset + \"_energydiff\"\n",
    "            for k2 in val[k]:\n",
    "                if k2 not in desciptors:\n",
    "                    desciptors[k2] = [val[k][k2]]\n",
    "                else:\n",
    "                    desciptors[k2].append(val[k][k2])\n",
    "    \n",
    "        for val in allvalues_perset[setname]:\n",
    "            for func in functionals:\n",
    "                for basis in basis_sets:\n",
    "                    if not(basis == selected_basisset and \\\n",
    "                           func == selected_functional):\n",
    "                        refk  = selected_functional + \"-\" + selected_basisset + \"_energydiff\"\n",
    "                        k = func + \"-\" + basis + \"_energydiff\"\n",
    "                        for k2 in val[k]:\n",
    "                            refk2 = k2.replace(basis, selected_basisset)\n",
    "                            refk2 = refk2.replace(func, selected_functional)\n",
    "                            newk2 = k2 + \"_difftoref\"\n",
    "                            if newk2 not in desciptors:\n",
    "                                desciptors[newk2] = [val[refk][refk2] - val[k][k2]]\n",
    "                            else:\n",
    "                                desciptors[newk2].append(val[refk][refk2] - val[k][k2])\n",
    "        \n",
    "        models_results[setname].features = desciptors\n",
    "    \n",
    "    # feastures selection\n",
    "    setname = \"Full\"\n",
    "    numoffeat = len(models_results[setname].features)\n",
    "    #print(\"Number of features for \", numoffeat)\n",
    "    for setname in fullsetnames:\n",
    "        if len(models_results[setname].features) != numoffeat:\n",
    "            print(\"Number of features for \", setname, \" is different\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "    toremove = []\n",
    "    setname = \"Full\"\n",
    "    for k in models_results[setname].features:\n",
    "        if len(set(models_results[setname].features[k])) == 1:\n",
    "            toremove.append(k)\n",
    "            #print(\"Constant fatures to remove: \", k)\n",
    "    \n",
    "    # remove constant values\n",
    "    for setname in fullsetnames:\n",
    "        #print(\"Removing constant features for \", setname)\n",
    "        for k in toremove:\n",
    "            #print(\"Constant fatures to remove: \", k)\n",
    "            del models_results[setname].features[k]\n",
    "    \n",
    "    \n",
    "    # force removing features Nuclear Repulsion difference\n",
    "    #print(\"Removing Nuclear Repulsion difference\")\n",
    "    for setname in fullsetnames: \n",
    "        toremove = []\n",
    "        for k in models_results[setname].features:\n",
    "            if k.find(\"Nuclear_Repulsion_difftoref\") != -1:\n",
    "                toremove.append(k)\n",
    "        for k in toremove:\n",
    "            #print(\"Removing feature \", k)\n",
    "            del models_results[setname].features[k]\n",
    "    \n",
    "    setname = \"Full\"\n",
    "    numoffeat = len(models_results[setname].features)\n",
    "    #print(\"Number of features for \", numoffeat)\n",
    "    for setname in fullsetnames:\n",
    "        if len(models_results[setname].features) != numoffeat:\n",
    "            print(\"Number of features for \", setname, \" is different\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "    setname = \"Full\"\n",
    "    #print(\"Running PLS for dataset: \", setname)\n",
    "    \n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "                  models_results[setname].labels)\n",
    "    setlist = models_results[setname].setnames  \n",
    "    supersetlist = models_results[setname].supersetnames\n",
    "    maxcomp = X.shape[1]\n",
    "    ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "              models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "              ncomp_start = 1, ncomp_max = maxcomp-8, split = False,\\\n",
    "              plot = False, loo=False)\n",
    "    r2max_comps = np.argmax(r2s)+1\n",
    "    rmsemin_comps = np.argmin(rmses)+1\n",
    "    wtmadmin_comps = np.argmin(wtmads)+1\n",
    "    compstouse = min(r2max_comps, rmsemin_comps, wtmadmin_comps)\n",
    "    #print(\"   Selected \", compstouse, \" components\")\n",
    "    \n",
    "    # perform features importance analysis\n",
    "    setname = \"Full\"   \n",
    "    #print(\"Running PLS for dataset: \", setname)\n",
    "    #print(\"  Using \", compstouse, \" components\")\n",
    "    X, Y, features_names = \\\n",
    "          commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "                  models_results[setname].labels)\n",
    "    setlist = []\n",
    "    for i, s in enumerate(models_results[setname].setnames):\n",
    "        ss = models_results[setname].supersetnames[i]\n",
    "        setlist.append(ss + \"_\" + s)\n",
    "    \n",
    "    plsmodel = PLSRegression(n_components=compstouse)\n",
    "    plsmodel.fit(X, Y)\n",
    "    y_pred = plsmodel.predict(X) \n",
    "       \n",
    "    cv = LeaveOneOut()\n",
    "    model = PLSRegression(n_components=compstouse)\n",
    "    scores = cross_val_score(model, X, Y, \\\n",
    "                scoring='neg_mean_squared_error', \\\n",
    "                cv=cv, n_jobs=-1)\n",
    "    loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    r2 = r2_score(Y, y_pred)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "    wtmad = wtmadf[\"Full\"]\n",
    "    \n",
    "    most_importante_features = []\n",
    "    result = permutation_importance(plsmodel, X, Y, n_repeats=10, \\\n",
    "                                    random_state=42, n_jobs=2)\n",
    "    pfi_sorted_idx = result.importances_mean.argsort()\n",
    "    #compute absolute values of the PLS coefficients\n",
    "    coef = np.abs(plsmodel.coef_).flatten()\n",
    "    #sort the coefficients\n",
    "    sorted_idx = np.argsort(coef)\n",
    "    \n",
    "    # print the most important features\n",
    "    for i in reversed(pfi_sorted_idx):\n",
    "        most_importante_features.append(features_names[i])\n",
    "    \n",
    "    setname = \"Full\"\n",
    "    touse = set()\n",
    "    # add by default the selected FINAL_SINGLE_POINT_ENERGY\n",
    "    touse.add(selected_functional + \"-\" + \\\n",
    "                selected_basisset + \"_\" + \\\n",
    "                \"FINAL_SINGLE_POINT_ENERGY\")\n",
    "    toremove = set()\n",
    "    df = pd.DataFrame(models_results[setname].features)\n",
    "    corr = df.corr().abs()\n",
    "    for feat1 in most_importante_features:\n",
    "        if feat1 not in toremove:\n",
    "            touse.add(feat1)\n",
    "            for idx, v in enumerate(corr[feat1]):\n",
    "                if v > CORRCUT:\n",
    "                    feat2 = corr.columns[idx]\n",
    "                    if feat2 != feat1:\n",
    "                        toremove.add(feat2)\n",
    "    \n",
    "    z = touse.intersection(toremove) \n",
    "    if len(z) != 0:\n",
    "        print(\"Error in removing correlated features\")\n",
    "        print(z)\n",
    "        sys.exit(1) \n",
    "    \n",
    "    for setname in fullsetnames:\n",
    "        for k in touse:\n",
    "            models_results[setname].uncorrelated_features[k] = \\\n",
    "                deepcopy(models_results[setname].features[k])\n",
    "            \n",
    "    #compute VIF\n",
    "    df = pd.DataFrame(models_results[\"Full\"].uncorrelated_features)\n",
    "    vif = pd.DataFrame()\n",
    "    #scale data before computing VIF\n",
    "    df = df.apply(lambda x: (x - np.mean(x)) / np.std(x))\n",
    "    vif[\"features\"] = df.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "    # histogram of VIF\n",
    "    for v in vif.values:\n",
    "        if v[1] > 160:\n",
    "            #print(v[0], v[1])\n",
    "            for setname in fullsetnames:\n",
    "                if v[0] in models_results[setname].uncorrelated_features:\n",
    "                    del models_results[setname].uncorrelated_features[v[0]]\n",
    "    \n",
    "    comptuseperset = {}\n",
    "    for setname in list(supersetnames)+[\"Full\"]:\n",
    "        comptuseperset[setname] = 0\n",
    "    \n",
    "    perc_split = 0.2\n",
    "    for setname in list(supersetnames)+[\"Full\"]:\n",
    "       #print(\"Running PLS search for dataset: \", setname)\n",
    "    \n",
    "       X, Y, features_names = \\\n",
    "          commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                  models_results[setname].labels)\n",
    "       setlist = models_results[setname].setnames\n",
    "       supersetlist = models_results[setname].supersetnames\n",
    "       maxcomp = X.shape[1]\n",
    "       ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "              models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "              ncomp_start = 1, ncomp_max = maxcomp, split = False,\\\n",
    "              plot = False)\n",
    "       r2max_comps = np.argmax(r2s)+1\n",
    "       rmsemin_comps = np.argmin(rmses)+1\n",
    "       wtmadmin_comps = np.argmin(wtmads)+1\n",
    "       loormsemin_comps = np.argmin(loormses)+1\n",
    "    \n",
    "       compstouse = wtmadmin_comps\n",
    "       comptuseperset[setname] = compstouse \n",
    "    \n",
    "    for setname in list(supersetnames)+[\"Full\"]:   \n",
    "       #print(\"Running PLS for dataset: \", setname)\n",
    "       #print(\"  Using \", comptuseperset[setname], \" components\")\n",
    "       compstouse = comptuseperset[setname]\n",
    "       X, Y, features_names = \\\n",
    "          commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                  models_results[setname].labels)\n",
    "       setlist = models_results[setname].setnames\n",
    "       models_results[setname].plsmodel = PLSRegression(n_components=compstouse)\n",
    "       models_results[setname].plsmodel.fit(X, Y)\n",
    "       models_results[setname].y_pred = \\\n",
    "          models_results[setname].plsmodel.predict(X) \n",
    "       \n",
    "       cv = LeaveOneOut()\n",
    "       model = PLSRegression(n_components=compstouse)\n",
    "       scores = cross_val_score(model, X, Y, \\\n",
    "                scoring='neg_mean_squared_error', \\\n",
    "                cv=cv, n_jobs=-1)\n",
    "       loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "       rmse = mean_squared_error(Y, models_results[setname].y_pred, squared=False)\n",
    "       r2 = r2_score(Y, models_results[setname].y_pred)\n",
    "       y_pred = models_results[setname].y_pred\n",
    "       if len(y_pred.shape) == 2:\n",
    "                y_pred = y_pred[:,0]\n",
    "       wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "       wtmad = wtmadf[setname]\n",
    "    \n",
    "    pls_model_full = models_results[\"Full\"].plsmodel\n",
    "    ypredFull = []\n",
    "    YFull = []\n",
    "    setnamesFull = []\n",
    "    \n",
    "    setoffeatures = set()\n",
    "\n",
    "    for ssetname in supersetnames:\n",
    "        sublistset = set()\n",
    "        for f in models_results[ssetname].uncorrelated_features:\n",
    "            setoffeatures.add(f)\n",
    "            sublistset.add(f)\n",
    "        if sublistset != setoffeatures:\n",
    "            print(\"Error in set of features\")\n",
    "            sys.exit(1)\n",
    "    \n",
    "        pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "        X, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (models_results[ssetname].uncorrelated_features, \\\n",
    "                                        models_results[ssetname].labels)\n",
    "        setlist = models_results[ssetname].setnames\n",
    "        setnamesFull.extend(setlist)\n",
    "        YFull.extend(list(Y))\n",
    "    \n",
    "        y_pred = pls_model_ssetname.predict(X)\n",
    "        if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred[:,0]\n",
    "        ypredFull.extend(list(y_pred))\n",
    "        rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "        wtmad2df = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "        wtmad2 = wtmad2df[ssetname]\n",
    "    \n",
    "        y_pred_full = pls_model_full.predict(X)\n",
    "        if len(y_pred_full.shape) == 2:\n",
    "            y_pred_full = y_pred_full[:,0]\n",
    "        rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "        wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "        wtmad2_full = wtmad2_fulldf[ssetname]\n",
    "    \n",
    "        print(\"%4d , %30s , %5d , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f\"%\\\n",
    "              (mainmodelsID, ssetname, len(Y), \\\n",
    "               wtmad2, wtmad2_full, \\\n",
    "               models_results[ssetname].bestinsidemethod_wtmad, \\\n",
    "               models_results[ssetname].bestourmethod_wtmad, \\\n",
    "               rmse, rmse_full, \\\n",
    "               models_results[ssetname].bestinsidemethod_rmse,\n",
    "               models_results[ssetname].bestourmethod_rmse))\n",
    "        \n",
    "    ssetname = \"Full\"\n",
    "    X, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (models_results[\"Full\"].uncorrelated_features, \\\n",
    "                                        models_results[\"Full\"].labels)\n",
    "    setlist = models_results[\"Full\"].setnames\n",
    "    y_pred_full = pls_model_full.predict(X)\n",
    "    \n",
    "    wtmad2df_full = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "    wtmad2_full = wtmad2df_full[\"Full\"]\n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "    \n",
    "    rmse = mean_squared_error(YFull, ypredFull, squared=False)\n",
    "    wtmad2df = commonutils.wtmad2(setnamesFull, YFull, ypredFull)\n",
    "    wtmad2 = wtmad2df[\"Full\"]\n",
    "    rmse = mean_squared_error(YFull, ypredFull, squared=False)\n",
    "    print(\"%4d , %30s , %5d , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f\"%\\\n",
    "              (mainmodelsID, ssetname, len(Y), \\\n",
    "               wtmad2, wtmad2_full, \\\n",
    "               models_results[ssetname].bestinsidemethod_wtmad, \\\n",
    "               models_results[ssetname].bestourmethod_wtmad, \\\n",
    "               rmse, rmse_full, \\\n",
    "               models_results[ssetname].bestinsidemethod_rmse,\n",
    "               models_results[ssetname].bestourmethod_rmse))\n",
    "    \n",
    "    return str(setoffeatures)[1:-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#functionals = [\"PBE\", \"PBE0\", \"TPSS\", \"TPSSh\"]\n",
    "#basis_sets = ['MINIX', 'SVP', 'TZVP']\n",
    "CORRCUT = 0.95\n",
    "\n",
    "modelsdata = []\n",
    "\n",
    "basis_sets_l = [['MINIX'], \n",
    "                ['SVP'], \n",
    "                ['TZVP'],\n",
    "                ['MINIX', 'SVP'],\n",
    "                ['MINIX', 'TZVP'],\n",
    "                ['SVP', 'TZVP'],\n",
    "                ['MINIX', 'SVP', 'TZVP']]\n",
    "functionals_l = [[\"PBE0\"], \n",
    "                 [\"PBE\"], \n",
    "                 [\"TPSS\"], \n",
    "                 [\"TPSSh\"], \n",
    "                 [\"PBE\", \"TPSS\", \"TPSSh\"], \n",
    "                 [\"PBE0\", \"TPSS\", \"TPSSh\"]]\n",
    "selected_basisset_l = [\"TZVP\", 'SVP', 'MINIX']\n",
    "selected_functional_l = [\"PBE0\", \"PBE\", \"TPSS\", \"TPSSh\"]\n",
    "\n",
    "mainmodelsID = 1\n",
    "print(\"ModelID, Setname , Dim , wtmad2 , wtmad2_full , \"+ \\\n",
    "          \"bestinsidemethod_wtmad2 , bestourmethod_wtmad2 ,\"+ \\\n",
    "            \"rmse , rmse_full , bestinsidemethod_rmse , bestourmethod_rmse\")\n",
    "for selected_functional in selected_functional_l:\n",
    "  for selected_basisset in selected_basisset_l:\n",
    "    for  basis_sets in basis_sets_l:\n",
    "      for functionals in functionals_l:\n",
    "       \n",
    "        usedfeats = mainfunc(mainmodelsID, allfeatures, CORRCUT, \\\n",
    "          selected_functional, selected_basisset, \\\n",
    "          functionals, basis_sets, fullsetnames, \\\n",
    "          allvalues_perset, models_results, supersetnames)\n",
    "\n",
    "        modelsdata.append([mainmodelsID, \\\n",
    "                        selected_functional, \\\n",
    "                        selected_basisset, \\\n",
    "                        functionals, \\\n",
    "                        basis_sets, \\\n",
    "                        usedfeats])\n",
    "\n",
    "        mainmodelsID += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in modelsdata:\n",
    "    print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
