{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"./data/allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"./data/methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"./data/fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"./data/functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"./data/basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"./data/supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(commonutils)\n",
    "\n",
    "from commonutils import ModelResults\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        wtmad = None\n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestinsidemethod_wtmad:\n",
    "                models_results[setname].bestinsidemethod_wtmad = wtmad\n",
    "                models_results[setname].bestinsidemethod_name_wtmad = str(methodid)\n",
    "                models_results[setname].y_pred_bestinsidemethod_wtmad = y_pred\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestinsidemethod_rmse:\n",
    "            models_results[setname].bestinsidemethod_rmse = rmse\n",
    "            models_results[setname].bestinsidemethod_name_rmse = str(methodid)\n",
    "            models_results[setname].y_pred_bestinsidemethod_rmse = y_pred\n",
    "\n",
    "    for j, method in enumerate(methods):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        wtmad = None            \n",
    "        fulllist = list(supersetnames.keys()) + [\"Full\"]\n",
    "        if setname in fulllist:\n",
    "            wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "            wtmad = wtmadf[setname]\n",
    "\n",
    "            if wtmad < models_results[setname].bestourmethod_wtmad:\n",
    "                models_results[setname].bestourmethod_wtmad = wtmad\n",
    "                models_results[setname].bestourmethod_name_wtmad = method\n",
    "                models_results[setname].y_pred_bestourmethod_wtmad = y_pred\n",
    "        \n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestourmethod_rmse:\n",
    "            models_results[setname].bestourmethod_rmse = rmse\n",
    "            models_results[setname].bestourmethod_name_rmse = method\n",
    "            models_results[setname].y_pred_bestourmethod_rmse = y_pred\n",
    "\n",
    "bestmnethodscount = {}\n",
    "setofbestourmethodswtamd = {}\n",
    "for setname in fullsetnames:\n",
    "    if models_results[setname].bestourmethod_name_rmse in bestmnethodscount:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] += 1\n",
    "    else:\n",
    "        bestmnethodscount[models_results[setname].bestourmethod_name_rmse] = 1\n",
    "\n",
    "    if models_results[setname].bestourmethod_name_wtmad != \"\":\n",
    "        if models_results[setname].bestourmethod_name_wtmad in setofbestourmethodswtamd:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] += 1\n",
    "        else:\n",
    "            setofbestourmethodswtamd[models_results[setname].bestourmethod_name_wtmad] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running PLS for dataset:  Full\n",
      "   Selected  15  components\n",
      "Running PLS for dataset:  Full\n",
      "  Using  15  components\n",
      "Running PLS search for dataset:  BARRIER_HEIGHTS\n",
      "Running PLS search for dataset:  INTRAMOLECULAR_INTERACTIONS\n",
      "Running PLS search for dataset:  SMALL_MOLECULES\n",
      "Running PLS search for dataset:  INTERMOLECULAR_INTERACTIONS\n",
      "Running PLS search for dataset:  LARGE_SYSTEMS\n",
      "Running PLS search for dataset:  Full\n",
      "Running PLS for dataset:  BARRIER_HEIGHTS\n",
      "  Using  13  components\n",
      "Running PLS for dataset:  INTRAMOLECULAR_INTERACTIONS\n",
      "  Using  13  components\n",
      "Running PLS for dataset:  SMALL_MOLECULES\n",
      "  Using  14  components\n",
      "Running PLS for dataset:  INTERMOLECULAR_INTERACTIONS\n",
      "  Using  11  components\n",
      "Running PLS for dataset:  LARGE_SYSTEMS\n",
      "  Using  13  components\n",
      "Running PLS for dataset:  Full\n",
      "  Using  12  components\n"
     ]
    }
   ],
   "source": [
    "#build descriptors \n",
    "selected_functional = \"PBE0\"\n",
    "selected_basisset = \"TZVP\"\n",
    "functionals = [\"PBE\", \"PBE0\", \"TPSS\", \"TPSSh\"]\n",
    "#basis_sets = ['MINIX', 'SVP', 'TZVP']\n",
    "basis_sets = ['MINIX']\n",
    "# remove corralted features \n",
    "CORRCUT = 0.95\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    for val in allvalues_perset[setname]:\n",
    "        k = selected_functional + \"-\" + \\\n",
    "            selected_basisset + \"_energydiff\"\n",
    "        for k2 in val[k]:\n",
    "            if k2 not in desciptors:\n",
    "                desciptors[k2] = [val[k][k2]]\n",
    "            else:\n",
    "                desciptors[k2].append(val[k][k2])\n",
    "\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for func in functionals:\n",
    "            for basis in basis_sets:\n",
    "                if not(basis == selected_basisset and \\\n",
    "                       func == selected_functional):\n",
    "                    refk  = selected_functional + \"-\" + selected_basisset + \"_energydiff\"\n",
    "                    k = func + \"-\" + basis + \"_energydiff\"\n",
    "                    for k2 in val[k]:\n",
    "                        refk2 = k2.replace(basis, selected_basisset)\n",
    "                        refk2 = refk2.replace(func, selected_functional)\n",
    "                        newk2 = k2 + \"_difftoref\"\n",
    "                        if newk2 not in desciptors:\n",
    "                            desciptors[newk2] = [val[refk][refk2] - val[k][k2]]\n",
    "                        else:\n",
    "                            desciptors[newk2].append(val[refk][refk2] - val[k][k2])\n",
    "    \n",
    "    models_results[setname].features = desciptors\n",
    "\n",
    "# feastures selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "#print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    #print(\"Removing constant features for \", setname)\n",
    "    for k in toremove:\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "#print(\"Removing Nuclear Repulsion difference\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"Nuclear_Repulsion_difftoref\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "#print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "setname = \"Full\"\n",
    "print(\"Running PLS for dataset: \", setname)\n",
    "\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "setlist = models_results[setname].setnames  \n",
    "supersetlist = models_results[setname].supersetnames\n",
    "maxcomp = X.shape[1]\n",
    "ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp-8, split = False,\\\n",
    "          plot = False, loo=False)\n",
    "r2max_comps = np.argmax(r2s)+1\n",
    "rmsemin_comps = np.argmin(rmses)+1\n",
    "wtmadmin_comps = np.argmin(wtmads)+1\n",
    "compstouse = min(r2max_comps, rmsemin_comps, wtmadmin_comps)\n",
    "print(\"   Selected \", compstouse, \" components\")\n",
    "\n",
    "# perform features importance analysis\n",
    "setname = \"Full\"   \n",
    "print(\"Running PLS for dataset: \", setname)\n",
    "print(\"  Using \", compstouse, \" components\")\n",
    "X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].features, \\\n",
    "              models_results[setname].labels)\n",
    "setlist = []\n",
    "for i, s in enumerate(models_results[setname].setnames):\n",
    "    ss = models_results[setname].supersetnames[i]\n",
    "    setlist.append(ss + \"_\" + s)\n",
    "\n",
    "plsmodel = PLSRegression(n_components=compstouse)\n",
    "plsmodel.fit(X, Y)\n",
    "y_pred = plsmodel.predict(X) \n",
    "   \n",
    "cv = LeaveOneOut()\n",
    "model = PLSRegression(n_components=compstouse)\n",
    "scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "r2 = r2_score(Y, y_pred)\n",
    "if len(y_pred.shape) == 2:\n",
    "    y_pred = y_pred[:,0]\n",
    "wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "wtmad = wtmadf[\"Full\"]\n",
    "\n",
    "most_importante_features = []\n",
    "result = permutation_importance(plsmodel, X, Y, n_repeats=10, \\\n",
    "                                random_state=42, n_jobs=2)\n",
    "pfi_sorted_idx = result.importances_mean.argsort()\n",
    "#compute absolute values of the PLS coefficients\n",
    "coef = np.abs(plsmodel.coef_).flatten()\n",
    "#sort the coefficients\n",
    "sorted_idx = np.argsort(coef)\n",
    "\n",
    "# print the most important features\n",
    "for i in reversed(pfi_sorted_idx):\n",
    "    most_importante_features.append(features_names[i])\n",
    "\n",
    "setname = \"Full\"\n",
    "touse = set()\n",
    "# add by default the selected FINAL_SINGLE_POINT_ENERGY\n",
    "touse.add(selected_functional + \"-\" + \\\n",
    "            selected_basisset + \"_\" + \\\n",
    "            \"FINAL_SINGLE_POINT_ENERGY\")\n",
    "toremove = set()\n",
    "df = pd.DataFrame(models_results[setname].features)\n",
    "corr = df.corr().abs()\n",
    "for feat1 in most_importante_features:\n",
    "    if feat1 not in toremove:\n",
    "        touse.add(feat1)\n",
    "        for idx, v in enumerate(corr[feat1]):\n",
    "            if v > CORRCUT:\n",
    "                feat2 = corr.columns[idx]\n",
    "                if feat2 != feat1:\n",
    "                    toremove.add(feat2)\n",
    "\n",
    "z = touse.intersection(toremove) \n",
    "if len(z) != 0:\n",
    "    print(\"Error in removing correlated features\")\n",
    "    sys.exit(1) \n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for k in touse:\n",
    "        models_results[setname].uncorrelated_features[k] = \\\n",
    "            deepcopy(models_results[setname].features[k])\n",
    "        \n",
    "#compute VIF\n",
    "df = pd.DataFrame(models_results[\"Full\"].uncorrelated_features)\n",
    "vif = pd.DataFrame()\n",
    "#scale data before computing VIF\n",
    "df = df.apply(lambda x: (x - np.mean(x)) / np.std(x))\n",
    "vif[\"features\"] = df.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(df.values, i) for i in range(df.shape[1])]\n",
    "# histogram of VIF\n",
    "for v in vif.values:\n",
    "    if v[1] > 160:\n",
    "        #print(v[0], v[1])\n",
    "        for setname in fullsetnames:\n",
    "            if v[0] in models_results[setname].uncorrelated_features:\n",
    "                del models_results[setname].uncorrelated_features[v[0]]\n",
    "\n",
    "comptuseperset = {}\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    comptuseperset[setname] = 0\n",
    "\n",
    "perc_split = 0.2\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "   print(\"Running PLS search for dataset: \", setname)\n",
    "\n",
    "   X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "              models_results[setname].labels)\n",
    "   setlist = models_results[setname].setnames\n",
    "   supersetlist = models_results[setname].supersetnames\n",
    "   maxcomp = X.shape[1]\n",
    "   ncomps, rmses, r2s, wtmads, loormses = \\\n",
    "          models.pls_model (X, Y, supersetlist, setlist, \\\n",
    "          ncomp_start = 1, ncomp_max = maxcomp, split = False,\\\n",
    "          plot = False)\n",
    "   r2max_comps = np.argmax(r2s)+1\n",
    "   rmsemin_comps = np.argmin(rmses)+1\n",
    "   wtmadmin_comps = np.argmin(wtmads)+1\n",
    "   loormsemin_comps = np.argmin(loormses)+1\n",
    "\n",
    "   compstouse = wtmadmin_comps\n",
    "   comptuseperset[setname] = compstouse \n",
    "\n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "   print(\"Running PLS for dataset: \", setname)\n",
    "   print(\"  Using \", comptuseperset[setname], \" components\")\n",
    "   compstouse = comptuseperset[setname]\n",
    "   X, Y, features_names = \\\n",
    "      commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "              models_results[setname].labels)\n",
    "   setlist = models_results[setname].setnames\n",
    "   models_results[setname].plsmodel = PLSRegression(n_components=compstouse)\n",
    "   models_results[setname].plsmodel.fit(X, Y)\n",
    "   models_results[setname].y_pred = \\\n",
    "      models_results[setname].plsmodel.predict(X) \n",
    "   \n",
    "   cv = LeaveOneOut()\n",
    "   model = PLSRegression(n_components=compstouse)\n",
    "   scores = cross_val_score(model, X, Y, \\\n",
    "            scoring='neg_mean_squared_error', \\\n",
    "            cv=cv, n_jobs=-1)\n",
    "   loormse = np.sqrt(np.mean(np.absolute(scores)))\n",
    "   rmse = mean_squared_error(Y, models_results[setname].y_pred, squared=False)\n",
    "   r2 = r2_score(Y, models_results[setname].y_pred)\n",
    "   y_pred = models_results[setname].y_pred\n",
    "   if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred[:,0]\n",
    "   wtmadf = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "   wtmad = wtmadf[setname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setname , Dim , wtmad2 , wtmad2_full , bestinsidemethod_wtmad2 , bestourmethod_wtmad2 ,rmse , rmse_full , bestinsidemethod_rmse , bestourmethod_rmse\n",
      "               BARRIER_HEIGHTS ,   194 ,   2.980 ,   6.330 ,  17.010 ,  10.520 ,   1.378 ,   2.830 ,   8.201 ,   4.856\n",
      "   INTRAMOLECULAR_INTERACTIONS ,   291 ,   3.920 ,  10.520 ,   8.630 ,   8.020 ,   0.270 ,   1.149 ,   0.873 ,   0.589\n",
      "               SMALL_MOLECULES ,   473 ,   4.030 ,   4.000 ,   6.750 ,   5.260 ,   5.373 ,   5.683 ,  12.191 ,   6.291\n",
      "   INTERMOLECULAR_INTERACTIONS ,   304 ,   6.040 ,  29.660 ,   9.470 ,  10.240 ,   0.879 ,   2.669 ,   2.286 ,   5.970\n",
      "                 LARGE_SYSTEMS ,   243 ,   7.370 ,  10.000 ,  12.500 ,   8.820 ,   3.937 ,   7.346 ,  12.567 ,   9.042\n",
      "                          Full ,  1505 ,   4.820 ,  11.720 ,  10.160 ,   8.160 ,   3.462 ,   4.647 ,   9.227 ,   6.219\n",
      "{'PBE0-TZVP_E(C)', 'TPSSh-MINIX_E(C)_difftoref', 'PBE-MINIX_FINAL_SINGLE_POINT_ENERGY_difftoref', 'PBE0-TZVP_Nuclear_Repulsion', 'PBE-MINIX_Dispersion_correction_difftoref', 'PBE-MINIX_E(C)_difftoref', 'TPSSh-MINIX_FINAL_SINGLE_POINT_ENERGY_difftoref', 'PBE0-TZVP_Kinetic_Energy', 'PBE0-TZVP_Dispersion_correction', 'PBE-MINIX_Potential_Energy_difftoref', 'PBE-MINIX_E(X)_difftoref', 'PBE-MINIX_Two_Electron_Energy_difftoref', 'PBE0-TZVP_FINAL_SINGLE_POINT_ENERGY', 'PBE0-TZVP_E(X)'}\n"
     ]
    }
   ],
   "source": [
    "pls_model_full = models_results[\"Full\"].plsmodel\n",
    "ypredFull = []\n",
    "YFull = []\n",
    "setnamesFull = []\n",
    "\n",
    "setoffeatures = set()\n",
    "print(\"Setname , Dim , wtmad2 , wtmad2_full , \"+ \\\n",
    "      \"bestinsidemethod_wtmad2 , bestourmethod_wtmad2 ,\"+ \\\n",
    "        \"rmse , rmse_full , bestinsidemethod_rmse , bestourmethod_rmse\")\n",
    "for ssetname in supersetnames:\n",
    "    sublistset = set()\n",
    "    for f in models_results[ssetname].uncorrelated_features:\n",
    "        setoffeatures.add(f)\n",
    "        sublistset.add(f)\n",
    "    if sublistset != setoffeatures:\n",
    "        print(\"Error in set of features\")\n",
    "        sys.exit(1)\n",
    "        \n",
    "    pls_model_ssetname = models_results[ssetname].plsmodel\n",
    "    X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[ssetname].uncorrelated_features, \\\n",
    "                                    models_results[ssetname].labels)\n",
    "    setlist = models_results[ssetname].setnames\n",
    "    setnamesFull.extend(setlist)\n",
    "    YFull.extend(list(Y))\n",
    "\n",
    "    y_pred = pls_model_ssetname.predict(X)\n",
    "    if len(y_pred.shape) == 2:\n",
    "        y_pred = y_pred[:,0]\n",
    "    ypredFull.extend(list(y_pred))\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    wtmad2df = commonutils.wtmad2(setlist, Y, y_pred)\n",
    "    wtmad2 = wtmad2df[ssetname]\n",
    "\n",
    "    y_pred_full = pls_model_full.predict(X)\n",
    "    if len(y_pred_full.shape) == 2:\n",
    "        y_pred_full = y_pred_full[:,0]\n",
    "    rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "    wtmad2_fulldf = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "    wtmad2_full = wtmad2_fulldf[ssetname]\n",
    "\n",
    "    print(\"%30s , %5d , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f\"%\\\n",
    "          (ssetname, len(Y), \\\n",
    "           wtmad2, wtmad2_full, \\\n",
    "           models_results[ssetname].bestinsidemethod_wtmad, \\\n",
    "           models_results[ssetname].bestourmethod_wtmad, \\\n",
    "           rmse, rmse_full, \\\n",
    "           models_results[ssetname].bestinsidemethod_rmse,\n",
    "           models_results[ssetname].bestourmethod_rmse))\n",
    "    \n",
    "ssetname = \"Full\"\n",
    "X, Y, features_names = \\\n",
    "        commonutils.build_XY_matrix (models_results[\"Full\"].uncorrelated_features, \\\n",
    "                                    models_results[\"Full\"].labels)\n",
    "setlist = models_results[\"Full\"].setnames\n",
    "y_pred_full = pls_model_full.predict(X)\n",
    "\n",
    "wtmad2df_full = commonutils.wtmad2(setlist, Y, y_pred_full)\n",
    "wtmad2_full = wtmad2df_full[\"Full\"]\n",
    "rmse_full = mean_squared_error(Y, y_pred_full, squared=False)\n",
    "\n",
    "rmse = mean_squared_error(YFull, ypredFull, squared=False)\n",
    "wtmad2df = commonutils.wtmad2(setnamesFull, YFull, ypredFull)\n",
    "wtmad2 = wtmad2df[\"Full\"]\n",
    "rmse = mean_squared_error(YFull, ypredFull, squared=False)\n",
    "print(\"%30s , %5d , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f , %7.3f\"%\\\n",
    "          (ssetname, len(Y), \\\n",
    "           wtmad2, wtmad2_full, \\\n",
    "           models_results[ssetname].bestinsidemethod_wtmad, \\\n",
    "           models_results[ssetname].bestourmethod_wtmad, \\\n",
    "           rmse, rmse_full, \\\n",
    "           models_results[ssetname].bestinsidemethod_rmse,\n",
    "           models_results[ssetname].bestourmethod_rmse))\n",
    "print(setoffeatures)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
