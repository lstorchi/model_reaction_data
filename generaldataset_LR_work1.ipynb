{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import commonutils\n",
    "from commonutils import ModelResults\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "#from sklearn.metrics import root_mean_squared_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "sys.path.append(\"./CLossLr\")\n",
    "import customlosslr as clr\n",
    "\n",
    "from commonutils import ModelsStore\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from commonfuncsforcli import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equations = {\"Te\": \"Kinetic_Energy\", \\\n",
    "         \"V_NN\": \"Nuclear_Repulsion\",\\\n",
    "         \"V_eN\": \"One_Electron_Energy - Kinetic_Energy\",\\\n",
    "         \"EX\": \"EX\",\\\n",
    "         \"E_J\": \"Two_Electron_Energy - EX - EC\",\\\n",
    "         \"DC\": \"Dispersion_correction\",\\\n",
    "         \"EC\": \"EC\"}\n",
    "SHIFTFT = \"DC\"\n",
    "\n",
    "selected_basisset = \"MINIX\"\n",
    "selected_functional = \"PBE\"\n",
    "functionals = []\n",
    "basis_sets = []\n",
    "\n",
    "print(\"Selected functional: \", selected_functional)\n",
    "print(\" Selected basis set: \", selected_basisset)\n",
    "print(\"        Functionals: \", functionals)\n",
    "print(\"         Basis sets: \", basis_sets)\n",
    "\n",
    "featuresvalues_perset,\\\n",
    "fullsetnames, \\\n",
    "models_results, \\\n",
    "supersetnames = readdata(shiftusingFT=SHIFTFT, \\\n",
    "                selected_functionalin=selected_functional, \\\n",
    "                selected_basisin=selected_basisset, \\\n",
    "                equations=equations)\n",
    "\n",
    "sep = \"_\"\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    k = selected_functional + sep +\\\n",
    "                selected_basisset \n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            if val.find(k) != -1:\n",
    "                if val not in desciptors:\n",
    "                    desciptors[val] = [features[val]]\n",
    "                else:\n",
    "                    desciptors[val].append(features[val])\n",
    "\n",
    "    for features in featuresvalues_perset[setname]:\n",
    "        for val in features:\n",
    "            for func in functionals:\n",
    "                for basis in basis_sets:\n",
    "                    if not(basis == selected_basisset and \\\n",
    "                            func == selected_functional):\n",
    "                        if val.find(func + sep + basis) != -1:\n",
    "                            actualk = val \n",
    "                            refk  = selected_functional + sep  + \\\n",
    "                                    selected_basisset + \\\n",
    "                                    val.replace(func + sep + basis, \"\")\n",
    "                            newk = actualk + \"_difftoref\"\n",
    "                            if newk not in desciptors:\n",
    "                                desciptors[newk] = [features[actualk]-features[refk]]\n",
    "                            else:\n",
    "                                desciptors[newk].append(features[actualk]-features[refk])\n",
    "    \n",
    "    models_results[setname].features = desciptors\n",
    "\n",
    "# features selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    for k in toremove:\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "tormfeatname = set()\n",
    "print(\"Removing Nuclear Repulsion differences\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"NR_difftoref\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        tormfeatname.add(k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "print(\"Removed features: \", tormfeatname)\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_store = {}\n",
    "for setname in list(supersetnames)+[\"Full\"]:\n",
    "    models_store[setname] = ModelsStore()\n",
    "\n",
    "    print(\"Running models for dataset: \", setname)\n",
    "    X, y, features_names = \\\n",
    "            commonutils.build_XY_matrix \\\n",
    "            (models_results[setname].features, \\\n",
    "            models_results[setname].labels)\n",
    "    X_test = None\n",
    "    X_train = None\n",
    "    y_test = None\n",
    "    y_train = None\n",
    "    fts_test = None\n",
    "    fts_train = None\n",
    "    if len(models_results[setname].fts) > 0:\n",
    "        X_train, X_test, y_train, y_test, fts_train, fts_test \\\n",
    "          = train_test_split(X, y, models_results[setname].fts,\n",
    "                      test_size=0.20, random_state=42)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test \\\n",
    "          = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "    setlist = models_results[setname].setnames  \n",
    "    supersetlist = models_results[setname].supersetnames\n",
    "    y_true = y  \n",
    "    y_test_true = y_test\n",
    "    y_train_true = y_train\n",
    "    fts = models_results[setname].fts\n",
    "\n",
    "    # Linear regression model to get starting beta values\n",
    "    lr_start_model = clr.custom_loss_lr (loss=clr.mean_average_error)\n",
    "    lr_start_split_model = clr.custom_loss_lr (loss=clr.mean_average_error)\n",
    "    try:\n",
    "        lr_start_model.fit(X, y)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        lr_start_model.set_solver(\"Nelder-Mead\")\n",
    "        lr_start_model.fit(X, y)\n",
    "    try:\n",
    "        lr_start_split_model.fit(X_train, y_train)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        lr_start_split_model.set_solver(\"Nelder-Mead\")\n",
    "        lr_start_split_model.fit(X_train, y_train)\n",
    "\n",
    "    # Custom Loss Linear Regression\n",
    "    models_store[setname].lr_custom_model =\\\n",
    "            clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    bestastart = lr_start_model.get_beta()   \n",
    "    if setname == \"Full\":\n",
    "        bestastart = np.ones(len(bestastart))\n",
    "    try:\n",
    "        models_store[setname].lr_custom_model.fit(X, y, \\\n",
    "                beta_init_values = bestastart)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        models_store[setname].lr_custom_model.set_solver(\"Nelder-Mead\")\n",
    "        models_store[setname].lr_custom_model.fit(X, y, \\\n",
    "                beta_init_values = bestastart)\n",
    "    y_pred_custom_lr = models_store[setname].lr_custom_model.predict(X)\n",
    "    if SHIFTFT != \"\":\n",
    "        y_true, y_pred_custom_lr = shiftbackdata (y, y_pred_custom_lr, fts)\n",
    "    custom_lrrmse = 0.0\n",
    "    try:\n",
    "        custom_lrrmse = root_mean_squared_error(y_true, y_pred_custom_lr)\n",
    "    except:\n",
    "        custom_lrrmse = np.sqrt(mean_squared_error(y_true, y_pred_custom_lr))    \n",
    "    custom_lrrmape = mean_absolute_percentage_error(y_true, y_pred_custom_lr)\n",
    "    models_store[setname].lr_custom_model_splitted  = \\\n",
    "            clr.custom_loss_lr (loss=clr.mean_absolute_percentage_error)\n",
    "    bestastart = lr_start_split_model.get_beta()\n",
    "    try:\n",
    "        models_store[setname].lr_custom_model_splitted.fit(X_train, y_train, \\\n",
    "                beta_init_values = bestastart)\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        models_store[setname].lr_custom_model_splitted.set_solver(\"Nelder-Mead\")\n",
    "        models_store[setname].lr_custom_model_splitted.fit(X_train, y_train, \\\n",
    "                beta_init_values = bestastart)\n",
    "    y_pred_custom_lr = models_store[setname].lr_custom_model_splitted.predict(X_test)\n",
    "    if SHIFTFT != \"\":\n",
    "        y_test_true, y_pred_custom_lr = shiftbackdata (y_test, y_pred_custom_lr, fts_test)\n",
    "    custom_lrrmsetest = 0.0\n",
    "    try:\n",
    "        custom_lrrmsetest = root_mean_squared_error(y_test_true, y_pred_custom_lr)\n",
    "    except:\n",
    "        custom_lrrmsetest = np.sqrt(mean_squared_error(y_test_true, y_pred_custom_lr))\n",
    "    custom_lrrmapetest = mean_absolute_percentage_error(y_test_true, y_pred_custom_lr)\n",
    "    y_pred_custom_lr = models_store[setname].lr_custom_model_splitted.predict(X_train)\n",
    "    if SHIFTFT != \"\":\n",
    "        y_train_true, y_pred_custom_lr = shiftbackdata (y_train, y_pred_custom_lr, fts_train)\n",
    "    custom_lrrmsetrain = 0.0\n",
    "    try:\n",
    "        custom_lrrmsetrain = root_mean_squared_error(y_train_true, y_pred_custom_lr)\n",
    "    except:\n",
    "        custom_lrrmsetrain = np.sqrt(mean_squared_error(y_train_true, y_pred_custom_lr))\n",
    "    custom_lrrmapetrain = mean_absolute_percentage_error(y_train_true, y_pred_custom_lr)\n",
    "    print(\"%40s ,      Custom LR RMSE, %12.6f\"%(setname,custom_lrrmse))\n",
    "    print(\"%40s ,Custom LR Train RMSE, %12.6f\"%(setname,custom_lrrmsetrain))\n",
    "    print(\"%40s , Custom LR Test RMSE, %12.6f\"%(setname,custom_lrrmsetest))\n",
    "    print(\"%40s ,      Custom LR MAPE, %12.6f\"%(setname,custom_lrrmape))\n",
    "    print(\"%40s ,Custom LR Train MAPE, %12.6f\"%(setname,custom_lrrmapetrain))\n",
    "    print(\"%40s , Custom LR Test MAPE: %12.6f\"%(setname,custom_lrrmapetest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build RF model\n",
    "classes = []\n",
    "features = {}\n",
    "supersetnameslist = list(supersetnames.keys())\n",
    "for setname in featuresvalues_perset:\n",
    "    if setname in supersetnameslist:\n",
    "        print(\"Setname: \", setname)\n",
    "        for entry in featuresvalues_perset[setname]:\n",
    "            classes.append(supersetnameslist.index(setname))\n",
    "\n",
    "X, _, features_names =\\\n",
    "        commonutils.build_XY_matrix (\\\n",
    "        models_results['Full'].features,\\\n",
    "        models_results['Full'].labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\\\n",
    "        X, classes, test_size=0.20, random_state=41)\n",
    "accuracys = []\n",
    "numoftrees = []\n",
    "depths = []\n",
    "for ntrees in range(10, 200, 10):\n",
    "    for depth in [5, 10, 15, None]:\n",
    "        rf = RandomForestClassifier(n_estimators=ntrees, \\\n",
    "                                    max_depth=depth, \\\n",
    "                                    random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "        y_pred = rf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracys.append(accuracy)\n",
    "        numoftrees.append(ntrees)\n",
    "        depths.append(depth)\n",
    "bestaccuracy = max(accuracys)   \n",
    "bestntrees = numoftrees[accuracys.index(bestaccuracy)]\n",
    "bestdepth = depths[accuracys.index(bestaccuracy)]\n",
    "print(\"Best accuracy: \", max(accuracys), \" with \", \\\n",
    "      bestntrees, \" trees \", \\\n",
    "      \" and depth \", bestdepth)\n",
    "rf = RandomForestClassifier(n_estimators=bestntrees, \\\n",
    "                            max_depth=bestdepth, \\\n",
    "                            random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "testaccuracy = rf.score(X_test, y_test)\n",
    "trainaccuracy = rf.score(X_train, y_train)\n",
    "overallaccuracy = rf.score(X, classes)\n",
    "print(\"  Train accuracy: %5.2f\"%(trainaccuracy))\n",
    "print(\"   Test accuracy: %5.2f\"%(testaccuracy))\n",
    "print(\"Overall accuracy: %5.2f\"%(overallaccuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLPs \n",
    "lrfullmodel = models_store[\"Full\"].lr_custom_model\n",
    "setname  = \"LARGE_SYSTEMS_FLPs\"\n",
    "X, y, features_names =\\\n",
    "            commonutils.build_XY_matrix (\\\n",
    "            models_results[setname].features,\\\n",
    "            models_results[setname].labels) \n",
    "\n",
    "func_basis_ref  = selected_functional + \"-\" + selected_basisset\n",
    "y_ref_func_basisset = models_results[setname].funcional_basisset_ypred[func_basis_ref]\n",
    "\n",
    "y_true = y\n",
    "fts = models_results[setname].fts\n",
    "if len(fts) == 0:\n",
    "    fts = [0.0]*len(y)\n",
    "\n",
    "y_pred_rf = []\n",
    "for i in range(len(y)):\n",
    "    x = X[i]\n",
    "    c = rf.predict([x])\n",
    "    setname = supersetnameslist[c[0]]\n",
    "    #print(\"Setname: \", setname)\n",
    "    y_pred = models_store[setname].lr_custom_model.predict([x])\n",
    "    y_pred_rf.append(y_pred[0])    \n",
    "\n",
    "y_pred_full_model = lrfullmodel.predict(X)\n",
    "if SHIFTFT != \"\":\n",
    "    y_true, y_pred_full_model = shiftbackdata (y, y_pred_full_model, fts)\n",
    "    _, y_pred_rf = shiftbackdata (y, y_pred_rf, fts)\n",
    "fp = open(\"flps.csv\", \"w\")\n",
    "print(\" %12s , %12s , %12s , %12s \"%(\\\n",
    "    \"True\", \"Full model\", \"RF model\", func_basis_ref), \\\n",
    "        file=fp)\n",
    "for yt, ypf, ypr, yref in zip(\\\n",
    "    y_true, y_pred_full_model, y_pred_rf, y_ref_func_basisset): \n",
    "    print(\" %12.6f , %12.6f , %12.6f , %12.5f \"%(\\\n",
    "        yt, ypf, ypr, yref), file=fp)\n",
    "fp.close()     \n",
    "mape  = mean_absolute_percentage_error(y_true, y_pred_full_model)\n",
    "r2 = r2_score(y_true, y_pred_full_model)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_full_model))\n",
    "print(\"Full model MAPE: \", mape)\n",
    "print(\"  Full model R2: \", r2)\n",
    "print(\"Full model RMSE: \", rmse)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred_rf)\n",
    "r2 = r2_score(y_true, y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_rf))\n",
    "print(\"  RF model MAPE: \", mape)\n",
    "print(\"    RF model R2: \", r2)\n",
    "print(\"  RF model RMSE: \", rmse)\n",
    "mape = mean_absolute_percentage_error(y_true, y_ref_func_basisset)\n",
    "r2 = r2_score(y_true, y_ref_func_basisset)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_ref_func_basisset))\n",
    "print(func_basis_ref, \" MAPE: \", mape)\n",
    "print(func_basis_ref, \"   R2: \", r2)\n",
    "print(func_basis_ref, \" RMSE: \", rmse)\n",
    "# scatter plot of the results\n",
    "plt.figure()\n",
    "plt.scatter(y_true, y_pred_full_model, color='blue')\n",
    "plt.scatter(y_true, y_pred_rf, color='red')\n",
    "plt.scatter(y_true, y_ref_func_basisset, color='green')\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Full model vs RF model')\n",
    "plt.legend([\"Full model\", \"RF model\", func_basis_ref])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMTKN55\n",
    "modeltorm = \"FLPs\"\n",
    "idexestorm = []\n",
    "for i, name in enumerate(models_results[\"Full\"].setnames):\n",
    "    setname  = name.split(\"_\")[-1]\n",
    "    if setname == modeltorm:\n",
    "        idexestorm.append(i)\n",
    "\n",
    "lrfullmodel = models_store[\"Full\"].lr_custom_model\n",
    "setname  = \"Full\"\n",
    "X, y, features_names =\\\n",
    "            commonutils.build_XY_matrix (\\\n",
    "            models_results[setname].\\\n",
    "            features,\\\n",
    "            models_results[setname].labels) \n",
    "# remove FLPs so indextorm\n",
    "fts = models_results[setname].fts\n",
    "if len(fts) == 0:\n",
    "    fts = [0.0]*len(y)\n",
    "X = np.delete(X, idexestorm, axis=0)\n",
    "y = np.delete(y, idexestorm)\n",
    "fts = np.delete(fts, idexestorm)\n",
    "\n",
    "func_basis_ref  = selected_functional + \"-\" + selected_basisset\n",
    "y_ref_func_basisset = models_results[setname].funcional_basisset_ypred[func_basis_ref]\n",
    "y_ref_func_basisset = np.delete(y_ref_func_basisset, idexestorm)\n",
    "y_true = y\n",
    "\n",
    "y_pred_rf = []\n",
    "for i in range(len(y)):\n",
    "    x = X[i]\n",
    "    c = rf.predict([x])\n",
    "    setname = supersetnameslist[c[0]]\n",
    "    #print(\"Setname: \", setname)\n",
    "    y_pred = models_store[setname].lr_custom_model.predict([x])\n",
    "    y_pred_rf.append(y_pred[0])    \n",
    "\n",
    "y_pred_full_model = lrfullmodel.predict(X)\n",
    "if SHIFTFT != \"\":\n",
    "    y_true, y_pred_full_model = shiftbackdata (y, y_pred_full_model, fts)\n",
    "    _, y_pred_rf = shiftbackdata (y, y_pred_rf, fts)\n",
    "fp = open(\"predictionsgmtkn55.csv\", \"w\")\n",
    "print(\" %12s , %12s , %12s , %12s \"%(\\\n",
    "    \"True\", \"Full model\", \"RF model\", func_basis_ref),\\\n",
    "        file=fp)\n",
    "for yt, ypf, ypr, yref in zip(\\\n",
    "    y_true, y_pred_full_model, y_pred_rf, y_ref_func_basisset): \n",
    "    print(\" %12.6f , %12.6f , %12.6f , %12.5f \"%(\\\n",
    "        yt, ypf, ypr, yref), file=fp)\n",
    "fp.close()\n",
    "mape  = mean_absolute_percentage_error(y_true, y_pred_full_model)\n",
    "r2 = r2_score(y_true, y_pred_full_model)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_full_model))\n",
    "print(\"Full model MAPE: \", mape)\n",
    "print(\"  Full model R2: \", r2)\n",
    "print(\"Full model RMSE: \", rmse)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred_rf)\n",
    "r2 = r2_score(y_true, y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_rf))\n",
    "print(\"  RF model MAPE: \", mape)\n",
    "print(\"    RF model R2: \", r2)\n",
    "print(\"  RF model RMSE: \", rmse)\n",
    "mape = mean_absolute_percentage_error(y_true, y_ref_func_basisset)\n",
    "r2 = r2_score(y_true, y_ref_func_basisset)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_ref_func_basisset))\n",
    "print(func_basis_ref, \" MAPE: \", mape)\n",
    "print(func_basis_ref, \"   R2: \", r2)\n",
    "print(func_basis_ref, \" RMSE: \", rmse)\n",
    "# scatter plot of the results\n",
    "plt.figure()\n",
    "plt.scatter(y_true, y_pred_full_model, color='blue')\n",
    "plt.scatter(y_true, y_pred_rf, color='red')\n",
    "plt.scatter(y_true, y_ref_func_basisset, color='green')\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Full model vs RF model')\n",
    "plt.legend([\"Full model\", \"RF model\", func_basis_ref])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Full\n",
    "lrfullmodel = models_store[\"Full\"].lr_custom_model\n",
    "setname  = \"Full\"\n",
    "X, y, features_names =\\\n",
    "            commonutils.build_XY_matrix (\\\n",
    "            models_results[setname].features,\\\n",
    "            models_results[setname].labels) \n",
    "fts = models_results[setname].fts\n",
    "if len(fts) == 0:\n",
    "    fts = [0.0]*len(y)\n",
    "func_basis_ref  = selected_functional + \"-\" + selected_basisset\n",
    "y_ref_func_basisset = models_results[setname].funcional_basisset_ypred[func_basis_ref]\n",
    "y_true = y\n",
    "\n",
    "y_pred_rf = []\n",
    "for i in range(len(y)):\n",
    "    x = X[i]\n",
    "    c = rf.predict([x])\n",
    "    setname = supersetnameslist[c[0]]\n",
    "    #print(\"Setname: \", setname)\n",
    "    y_pred = models_store[setname].lr_custom_model.predict([x])\n",
    "    y_pred_rf.append(y_pred[0])    \n",
    "\n",
    "y_pred_full_model = lrfullmodel.predict(X)\n",
    "if SHIFTFT != \"\":\n",
    "    y_true, y_pred_full_model = shiftbackdata (y, y_pred_full_model, fts)\n",
    "    _, y_pred_rf = shiftbackdata (y, y_pred_rf, fts)\n",
    "mape  = mean_absolute_percentage_error(y_true, y_pred_full_model)\n",
    "r2 = r2_score(y_true, y_pred_full_model)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_full_model))\n",
    "print(\"Full model MAPE: \", mape)\n",
    "print(\"  Full model R2: \", r2)\n",
    "print(\"Full model RMSE: \", rmse)\n",
    "mape = mean_absolute_percentage_error(y_true, y_pred_rf)\n",
    "r2 = r2_score(y_true, y_pred_rf)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred_rf))\n",
    "print(\"  RF model MAPE: \", mape)\n",
    "print(\"    RF model R2: \", r2)\n",
    "print(\"  RF model RMSE: \", rmse)\n",
    "mape = mean_absolute_percentage_error(y_true, y_ref_func_basisset)\n",
    "r2 = r2_score(y_true, y_ref_func_basisset)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_ref_func_basisset))\n",
    "print(func_basis_ref, \" MAPE: \", mape)\n",
    "print(func_basis_ref, \"   R2: \", r2)\n",
    "print(func_basis_ref, \" RMSE: \", rmse)\n",
    "# scatter plot of the results\n",
    "plt.figure()\n",
    "plt.scatter(y_true, y_pred_full_model, color='blue')\n",
    "plt.scatter(y_true, y_pred_rf, color='red')\n",
    "plt.scatter(y_true, y_ref_func_basisset, color='green')\n",
    "plt.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Full model vs RF model')\n",
    "plt.legend([\"Full model\", \"RF model\", func_basis_ref])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = open(\"modelscoefficients.csv\", \"w\")    \n",
    "for setname in list(supersetnames)+[\"Full\"]:   \n",
    "    lr_model = models_store[setname].lr_model\n",
    "    lr_model_splitted = models_store[setname].lr_model_splitted\n",
    "    lr_custom_model = models_store[setname].lr_custom_model\n",
    "    lr_custom_model_splitted = models_store[setname].lr_custom_model_splitted\n",
    "\n",
    "    X, y, features_names = \\\n",
    "            commonutils.build_XY_matrix (\\\n",
    "                models_results[setname].features, \\\n",
    "                models_results[setname].labels)\n",
    "\n",
    "    # Custom LR model\n",
    "    lr_test_and_rpint (lr_custom_model, X, y, setname + \" Custom LR \", \\\n",
    "                    features_names, fp, \\\n",
    "                    shiftft=SHIFTFT, \\\n",
    "                    fts=models_results[setname].fts)\n",
    "    lr_test_and_rpint (lr_custom_model_splitted, X, y, \\\n",
    "                    setname + \" Custom LR split \", \\\n",
    "                    features_names, fp, \\\n",
    "                    shiftft=SHIFTFT, \\\n",
    "                    fts=models_results[setname].fts)\n",
    "\n",
    "fp.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
