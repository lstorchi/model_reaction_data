{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import commonutils\n",
    "import models\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from dataclasses import dataclass\n",
    "import prettyprinter as pp\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "howmanydifs = 3\n",
    "allvalues_perset = pickle.load(open(\"allvalues_perset.p\", \"rb\"))\n",
    "methods = pickle.load(open(\"methods.p\", \"rb\"))\n",
    "fullsetnames = pickle.load(open(\"fullsetnames.p\", \"rb\"))\n",
    "functionals = pickle.load(open(\"functionals.p\", \"rb\"))\n",
    "basis_sets = pickle.load(open(\"basis_sets.p\", \"rb\"))\n",
    "supersetnames = pickle.load(open(\"supersetnames.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debug purposes\n",
    "#for val in allvalues_perset:\n",
    "#    print(\"======= START =======\")\n",
    "#    print(val, len(allvalues_perset[val]))\n",
    "#    pp.pprint(allvalues_perset[val])\n",
    "#    print(\"=======  END  =======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "reload(commonutils)\n",
    "\n",
    "from commonutils import ModelResults\n",
    "\n",
    "allfeatures = set()\n",
    "for setname in fullsetnames:\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for k in val:\n",
    "            if k.find(\"energydiff\") != -1:\n",
    "                for f in val[k]:\n",
    "                    allfeatures.add(f)\n",
    "\n",
    "# set labels and sets iists\n",
    "models_results = {}\n",
    "for setname in fullsetnames:\n",
    "    models_results[setname] = ModelResults()\n",
    "    for val in allvalues_perset[setname]:\n",
    "        models_results[setname].labels.append(val[\"label\"]) \n",
    "        models_results[setname].supersetnames.append(val[\"super_setname\"])\n",
    "        models_results[setname].setnames.append(val[\"super_setname\"]+\"_\"+val[\"setname\"])\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for methodid in range(howmanydifs):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[\"label\"] + val[\"difs\"][methodid])\n",
    "\n",
    "        wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                    models_results[setname].labels, y_pred)\n",
    "        wtmad = wtmadf[\"Full\"]\n",
    "\n",
    "        if wtmad < models_results[setname].bestinsidemethod_wtmad:\n",
    "            models_results[setname].bestinsidemethod_wtmad = wtmad\n",
    "            models_results[setname].bestinsidemethod_name_wtmad = str(methodid)\n",
    "            models_results[setname].y_pred_bestinsidemethod_wtmad = y_pred\n",
    "\n",
    "        rmse = mean_squared_error(models_results[setname].labels, \\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestinsidemethod_rmse:\n",
    "            models_results[setname].bestinsidemethod_rmse = rmse\n",
    "            models_results[setname].bestinsidemethod_name_rmse = str(methodid)\n",
    "            models_results[setname].y_pred_bestinsidemethod_rmse = y_pred\n",
    "\n",
    "    for j, method in enumerate(methods):\n",
    "        y_pred = []\n",
    "        for val in allvalues_perset[setname]:\n",
    "            y_pred.append(val[method + \"_energydiff\"][method+\"_FINAL_SINGLE_POINT_ENERGY\"])\n",
    "\n",
    "        wtmadf = commonutils.wtmad2(models_results[setname].setnames, \\\n",
    "                                models_results[setname].labels, y_pred)\n",
    "        wtmad = wtmadf[\"Full\"]\n",
    "\n",
    "        if wtmad < models_results[setname].bestourmethod_wtmad:\n",
    "            models_results[setname].bestourmethod_wtmad = wtmad\n",
    "            models_results[setname].bestourmethod_name_wtmad = method\n",
    "            models_results[setname].y_pred_bestourmethod_wtmad = y_pred\n",
    "        \n",
    "        rmse = mean_squared_error(models_results[setname].labels,\\\n",
    "                                y_pred, squared=False)\n",
    "\n",
    "        if rmse < models_results[setname].bestourmethod_rmse:\n",
    "            models_results[setname].bestourmethod_rmse = rmse\n",
    "            models_results[setname].bestourmethod_name_rmse = method\n",
    "            models_results[setname].y_pred_bestourmethod_rmse = y_pred\n",
    "\n",
    "print(\"Results for inside and our methods\")\n",
    "print(\"%40s\"% \"Dataset\", \" , \", \\\n",
    "    \"Best inside method RMSE\", \" , \", \\\n",
    "    \"RMSE\", \" , \", \\\n",
    "    \"Best inside method WTMAD2\", \" , \", \\\n",
    "    \"WTMAD2\", \" , \", \\\n",
    "    \"Best our method RMSE\", \" , \", \\\n",
    "    \"RMSE\", \" , \", \\\n",
    "    \"Best our method WTMAD2\", \" , \", \\\n",
    "    \"WTMAD2\")\n",
    "for setname in fullsetnames:\n",
    "    print(\"%40s\"%setname, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestinsidemethod_name_rmse , \" , \",\\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_rmse, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestinsidemethod_name_wtmad , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_wtmad, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestourmethod_name_rmse , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_rmse, \" , \", \\\n",
    "        \"%10s\"%models_results[setname].bestourmethod_name_wtmad , \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_wtmad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build descriptors \n",
    "selected_basisset = \"TZVP\"\n",
    "selected_functional = \"PBE\"\n",
    "functionals = [\"PBE\", \"PBE0\", \"TPSS\", \"TPSSh\"]\n",
    "for setname in fullsetnames:\n",
    "    desciptors = {}\n",
    "    for val in allvalues_perset[setname]:\n",
    "        for func in functionals:\n",
    "            for basis in basis_sets:\n",
    "                if basis == selected_basisset and func == selected_functional:\n",
    "                    k = func + \"-\" + basis + \"_energydiff\"\n",
    "                    for k2 in val[k]:\n",
    "                        if k2 not in desciptors:\n",
    "                            desciptors[k2] = [val[k][k2]]\n",
    "                        else:\n",
    "                            desciptors[k2].append(val[k][k2])\n",
    "                else:\n",
    "                    refk  = selected_functional + \"-\" + selected_basisset + \"_energydiff\"\n",
    "                    k = func + \"-\" + basis + \"_energydiff\"\n",
    "                    for k2 in val[k]:\n",
    "                        refk2 = k2.replace(basis, selected_basisset)\n",
    "                        refk2 = refk2.replace(func, selected_functional)\n",
    "                        newk2 = k2 + \"_difftoref\"\n",
    "                        if newk2 not in desciptors:\n",
    "                            desciptors[newk2] = [val[refk][refk2] - val[k][k2]]\n",
    "                        else:\n",
    "                            desciptors[newk2].append(val[refk][refk2] - val[k][k2])\n",
    "    models_results[setname].features = desciptors\n",
    "    #print(\"Descriptors for \", setname)\n",
    "    #for k in desciptors:\n",
    "    #    print(k, len(desciptors[k]), desciptors[k])\n",
    "\n",
    "# feastures selection\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)\n",
    "\n",
    "toremove = []\n",
    "setname = \"Full\"\n",
    "for k in models_results[setname].features:\n",
    "    if len(set(models_results[setname].features[k])) == 1:\n",
    "        toremove.append(k)\n",
    "        print(\"Constant fatures to remove: \", k)\n",
    "\n",
    "# remove constant values\n",
    "for setname in fullsetnames:\n",
    "    #print(\"Removing constant features for \", setname)\n",
    "    for k in toremove:\n",
    "        #print(\"Constant fatures to remove: \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "# test print for debug\n",
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])\n",
    "\n",
    "# force removing features Nuclear Repulsion difference\n",
    "print(\"Removing Nuclear Repulsion difference\")\n",
    "for setname in fullsetnames: \n",
    "    toremove = []\n",
    "    for k in models_results[setname].features:\n",
    "        if k.find(\"Nuclear_Repulsion_difftoref\") != -1:\n",
    "            toremove.append(k)\n",
    "    for k in toremove:\n",
    "        #print(\"Removing feature \", k)\n",
    "        del models_results[setname].features[k]\n",
    "\n",
    "setname = \"Full\"\n",
    "numoffeat = len(models_results[setname].features)\n",
    "print(\"Number of features for \", numoffeat)\n",
    "for setname in fullsetnames:\n",
    "    if len(models_results[setname].features) != numoffeat:\n",
    "        print(\"Number of features for \", setname, \" is different\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove corralted features \n",
    "CORRCUT = 0.95\n",
    "\n",
    "setname = \"Full\"\n",
    "touse = set()\n",
    "# add by default the selected FINAL_SINGLE_POINT_ENERGY\n",
    "touse.add(selected_functional + \"-\" + \\\n",
    "            selected_basisset + \"_\" + \\\n",
    "            \"FINAL_SINGLE_POINT_ENERGY\")\n",
    "toremove = set()\n",
    "df = pd.DataFrame(models_results[setname].features)\n",
    "corr = df.corr().abs()\n",
    "for i, k in enumerate(corr.columns):\n",
    "    print(i+1, \" - \", k, \" \", i)\n",
    "    if k not in toremove:\n",
    "        touse.add(k)\n",
    "    for idx, v in enumerate(corr[k]):\n",
    "        if v > CORRCUT and idx > i:\n",
    "            print(\" %60s %4.2f\"%(corr.index[idx], v))\n",
    "            if corr.index[idx] not in touse:\n",
    "                toremove.add(corr.index[idx])\n",
    "\n",
    "print(\"Features to use\")\n",
    "for i, feat in enumerate(touse):\n",
    "    print(i+1 ,  \" - \" , feat)\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    for k in touse:\n",
    "        models_results[setname].uncorrelated_features[k] = \\\n",
    "            deepcopy(models_results[setname].features[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for setname in fullsetnames:\n",
    "#    print(\"Descriptors for \", setname)\n",
    "#    i = 1\n",
    "#    for k in models_results[setname].features:\n",
    "#        print(i, \" - \", k, len(models_results[setname].features[k]), \\\n",
    "#           models_results[setname].features[k])\n",
    "#        i += 1\n",
    "\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "setname = \"Full\"\n",
    "df = pd.DataFrame(models_results[setname].uncorrelated_features)\n",
    "print(\"Correlation matrix\")\n",
    "plt.rcParams['figure.figsize'] = 60,60\n",
    "sns.set(font_scale=2)\n",
    "sns.heatmap(df.corr().abs(), annot=True)\n",
    "#print(df.corr().abs())\n",
    "#sns.heatmap(df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test two linear models to predict energudiff\n",
    "# LinearRegression\n",
    "\"\"\"\n",
    "import sklearn.linear_model as lm\n",
    "linearNR_Two = lm.LinearRegression()\n",
    "linearNR_Two.fit(df[\"PBE_Nuclear_Repulsion\"].values.reshape(-1,1), \\\n",
    "                  df[\"PBE_Two_Electron_Energy\"])\n",
    "print(linearNR_Two.coef_, linearNR_Two.intercept_)\n",
    "linearNR_One = lm.LinearRegression()\n",
    "linearNR_One.fit(df[\"PBE_Nuclear_Repulsion\"].values.reshape(-1,1), \\\n",
    "                 df[\"PBE_One_Electron_Energy\"])\n",
    "print(linearNR_One.coef_, linearNR_One.intercept_)\n",
    "\n",
    "Onepred = linearNR_One.predict(df[\"PBE_Nuclear_Repulsion\"].values.reshape(-1,1))\n",
    "Twopred = linearNR_Two.predict(df[\"PBE_Nuclear_Repulsion\"].values.reshape(-1,1))\n",
    "\n",
    "# scatter plot\n",
    "plt.clf()\n",
    "plt.scatter(df[\"PBE_One_Electron_Energy\"], Onepred)\n",
    "plt.xlabel('Calculated Energy')\n",
    "plt.ylabel('Predicted Energy')\n",
    "plt.title('One Electron Energy')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(df[\"PBE_Two_Electron_Energy\"], Twopred)\n",
    "plt.xlabel('Calculated Energy')\n",
    "plt.ylabel('Predicted Energy')\n",
    "plt.title('Two Electron Energy')\n",
    "plt.show()\n",
    "\n",
    "predEnergy = Onepred + Twopred + \\\n",
    "    df[\"PBE_Nuclear_Repulsion\"].values\n",
    "calculatedEnergy = df[\"PBE_Nuclear_Repulsion\"].values + \\\n",
    "    df[\"PBE_One_Electron_Energy\"].values + \\\n",
    "    df[\"PBE_Two_Electron_Energy\"].values\n",
    "\n",
    "# scatter plot\n",
    "plt.clf()\n",
    "plt.scatter(calculatedEnergy, predEnergy)    \n",
    "plt.xlabel('Calculated Energy')\n",
    "plt.ylabel('Predicted Energy')\n",
    "plt.title('Linear Regression')\n",
    "plt.show()\n",
    "\n",
    "for i, ce in enumerate(calculatedEnergy):\n",
    "    diff = abs(ce - predEnergy[i])/((ce+predEnergy[i])/2.0)\n",
    "    print(\"%10.4f %10.4f %6.2f\"%(ce, predEnergy[i], diff*100))\n",
    "\n",
    "# PLSRegression using both one and two electron ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reload of models\n",
    "import importlib\n",
    "importlib.reload(models)\n",
    "# search for the best model a simple grid search\n",
    "nepochs = [50, 100]\n",
    "#nepochs = [100]\n",
    "#batch_sizes = [4, 8, 16, 32]\n",
    "batch_sizes = [16, 32]\n",
    "\"\"\"\n",
    "modelshapes = [[4, 4, 4], [8, 8, 8], [16, 16, 16], \\\n",
    "                [32, 32, 32], [64, 64, 64], \\\n",
    "                [128, 128, 128], [4, 4, 4, 4], \\\n",
    "                [8, 8, 8, 8], [16, 16, 16, 16], \\\n",
    "                [32, 32, 32, 32], [64, 64, 64, 64], \\\n",
    "                [128, 128, 128, 128], [4, 4, 4, 4, 4], \\\n",
    "                [8, 8, 8, 8, 8], [16, 16, 16, 16, 16], \n",
    "                [32, 32, 32, 32, 32], [64, 64, 64, 64, 64],\n",
    "                [128, 128, 128, 128, 128], [4, 4, 4, 4, 4, 4], \\\n",
    "                [8, 8, 8, 8, 8, 8], [16, 16, 16, 16, 16, 16], \n",
    "                [32, 32, 32, 32, 32, 32], [64, 64, 64, 64, 64, 64],\n",
    "                [128, 128, 128, 128, 128, 128]]\n",
    "\"\"\"\n",
    "modelshapes = [\\\n",
    "    [32, 32, 32, 32],\\\n",
    "    [64, 64, 64, 64],\\\n",
    "    [128, 128, 128, 128],\\\n",
    "    [32, 32, 32, 32, 32, 32],\\\n",
    "    [64, 64, 64, 64, 64, 64],\\\n",
    "    [128, 128, 128, 128, 128, 128], \\\n",
    "    [32, 32, 64, 128, 64, 32, 32, 24],\\\n",
    "    [64, 128, 256, 128, 64, 32],\\\n",
    "    [32, 64, 128, 128, 128, 64, 32, 24]]\n",
    "setname = \"Full\"\n",
    "print(\"Searching for best NN model for set: \", setname)\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                            models_results[setname].labels)\n",
    "\n",
    "setlist = []\n",
    "for i, s in enumerate(models_results[setname].setnames):\n",
    "    ss = models_results[setname].supersetnames[i]\n",
    "    setlist.append(ss + \"_\" + s)   \n",
    "supersetlist = models_results[setname].supersetnames\n",
    "\n",
    "scalerx = preprocessing.StandardScaler().fit(X)\n",
    "X_s = scalerx.transform(X) \n",
    "scalery = preprocessing.StandardScaler().fit(Y.reshape(-1, 1))\n",
    "Y_s = scalery.transform(Y.reshape(-1, 1))\n",
    "modelminmape, modelminwtmad, modelminrmse  = \\\n",
    "        models.nn_model(0.2, X_s, scalerx, Y_s, scalery, \\\n",
    "            supersetlist, setlist, \\\n",
    "            nepochs, modelshapes, batch_sizes, inputshape=-1,\\\n",
    "            search=True, split=False)\n",
    "\n",
    "print(\"Best NN model for set: \", setname, file=sys.stderr)\n",
    "print(\"  WTAMD: \", modelminwtmad, file=sys.stderr)\n",
    "print(\"   MAPE: \", modelminmape, file=sys.stderr)\n",
    "print(\"   RMSE: \", modelminrmse, file=sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(models)\n",
    "\n",
    "setname = \"Full\"\n",
    "X, Y, features_names = \\\n",
    "    commonutils.build_XY_matrix (models_results[setname].uncorrelated_features , \\\n",
    "                                models_results[setname].labels)\n",
    "\n",
    "setlist = []\n",
    "for i, s in enumerate(models_results[setname].setnames):\n",
    "    ss = models_results[setname].supersetnames[i]\n",
    "    setlist.append(ss + \"_\" + s)   \n",
    "supersetlist = models_results[setname].supersetnames\n",
    "\n",
    "scalerx = preprocessing.StandardScaler().fit(X)\n",
    "X_s = scalerx.transform(X) \n",
    "scalery = preprocessing.StandardScaler().fit(Y.reshape(-1, 1))\n",
    "Y_s = scalery.transform(Y.reshape(-1, 1))\n",
    "#build the final model and print the results\n",
    "results_mape = models.nn_model(0.2, X_s, scalerx, Y_s, scalery, \\\n",
    "                    supersetlist, setlist, \\\n",
    "                    [modelminmape[1]], \\\n",
    "                    [modelminmape[0]], \\\n",
    "                    [modelminmape[2]], \\\n",
    "                    inputshape=-1,\\\n",
    "                    search=False, split=False)\n",
    "        \n",
    "models_results[setname].nn_model_mape = results_mape\n",
    "\n",
    "results_wtmad = models.nn_model(0.2, X_s, scalerx, Y_s, scalery, \\\n",
    "                    supersetlist, setlist, \\\n",
    "                    [modelminwtmad[1]], \\\n",
    "                    [modelminwtmad[0]], \\\n",
    "                    [modelminwtmad[2]], \\\n",
    "                    inputshape=-1,\\\n",
    "                    search=False, split=False)\n",
    "        \n",
    "models_results[setname].nn_model_wtmad = results_wtmad\n",
    "\n",
    "results_rmse = models.nn_model(0.2, X_s, scalerx, Y_s, scalery, \\\n",
    "                    supersetlist, setlist, \\\n",
    "                    [modelminrmse[1]], \\\n",
    "                    [modelminrmse[0]], \\\n",
    "                    [modelminrmse[2]], \\\n",
    "                    inputshape=-1,\\\n",
    "                    search=False, split=False)\n",
    "\n",
    "models_results[setname].nn_model_rmse = results_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setname = \"Full\"\n",
    "results_mape = models_results[setname].nn_model_mape\n",
    "results_wtmad = models_results[setname].nn_model_wtmad\n",
    "results_rmse = models_results[setname].nn_model_rmse\n",
    "\n",
    "for history in [results_mape['history'], results_wtmad['history'], results_rmse['history']]:\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 10,10\n",
    "    plt.plot(history.history['mse'])\n",
    "    plt.plot(history.history['val_mse'])\n",
    "    plt.title('model')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.clf()\n",
    "    plt.rcParams['figure.figsize'] = 10,10\n",
    "    plt.plot(history.history['mape'])\n",
    "    plt.plot(history.history['val_mape'])\n",
    "    plt.title('model MAPE')\n",
    "    plt.ylabel('MAPE')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "setname = \"Full\"\n",
    "results_mape = models_results[setname].nn_model_mape\n",
    "results_wtmad = models_results[setname].nn_model_wtmad\n",
    "results_rmse = models_results[setname].nn_model_rmse\n",
    "print(\" Dim , %40s\"% \"Dataset\", \" , \", \\\n",
    "    \"Best inside method RMSE\", \" , \", \\\n",
    "    \"Best our method RMSE\", \" , \", \\\n",
    "    \"RMSE mape, \", \\\n",
    "    \"RMSE wtmad, \", \\\n",
    "    \"RMSE rmse\")\n",
    "for setname in fullsetnames:\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    \n",
    "    X_s = scalerx.transform(X)\n",
    "    Y_s = scalery.transform(Y.reshape(-1, 1))\n",
    "\n",
    "    y_pred_mape = scalery.inverse_transform(results_mape['model'].predict(X_s, verbose=0))\n",
    "    models_results[setname].y_pred_mape = y_pred_mape\n",
    "    rmse_mape = mean_squared_error(Y, y_pred_mape, squared=False)\n",
    "    \n",
    "    y_pred_wtmad = scalery.inverse_transform(results_wtmad['model'].predict(X_s, verbose=0))\n",
    "    models_results[setname].y_pred_wtmad = y_pred_wtmad\n",
    "    rmse_wtmad = mean_squared_error(Y, y_pred_wtmad, squared=False)\n",
    "\n",
    "    y_pred_rmse = scalery.inverse_transform(results_rmse['model'].predict(X_s, verbose=0))\n",
    "    models_results[setname].y_pred_rmse = y_pred_rmse\n",
    "    rmse_rmse = mean_squared_error(Y, y_pred_rmse, squared=False)\n",
    "    \n",
    "    print(\"%4d , %40s\"%(len(models_results[setname].labels), setname), \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%rmse_mape, \" , \", \\\n",
    "        \"%7.3f\"%rmse_wtmad, \" , \", \\\n",
    "        \"%7.3f\"%rmse_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print(\" Dim , %40s\"% \"Dataset\", \" , \", \\\n",
    "      \"Best inside method RMSE\", \" , \", \\\n",
    "      \"Best our method RMSE\", \" , \", \\\n",
    "      \"RMSE , MAPE, R2\")\n",
    "for setname in fullsetnames:\n",
    "    X, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (models_results[setname].fulldescriptors, \\\n",
    "                                    models_results[setname].labels)\n",
    "    \n",
    "    X_s = scalerx.transform(X)\n",
    "    Y_s = scalery.transform(Y.reshape(-1, 1))\n",
    "    y_pred = scalery.inverse_transform(results_rmse['model'].predict(X_s, verbose=0))\n",
    "    models_results[setname].y_pred = y_pred\n",
    "    rmse = mean_squared_error(Y, y_pred, squared=False)\n",
    "    r2 = r2_score(Y, y_pred)\n",
    "    mape = mean_absolute_percentage_error(Y, y_pred)\n",
    "\n",
    "    print(\"%4d , %40s\"%(len(models_results[setname].labels), setname), \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestinsidemethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%models_results[setname].bestourmethod_rmse, \" , \", \\\n",
    "        \"%7.3f\"%rmse, \" , \", \\\n",
    "        \"%7.3f\"%mape, \" , \", \\\n",
    "        \"%7.3f\"%r2)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printonlysuperset = True\n",
    "\n",
    "for setname in fullsetnames:\n",
    "    ssetname = \"Full\"\n",
    "    if setname in supersetnames or setname == \"Full\":\n",
    "        ssetname = setname  \n",
    "    else:    \n",
    "        lastunder = setname.rfind(\"_\")\n",
    "        ssetname = setname[:lastunder]\n",
    "\n",
    "    X, Y, features_names = \\\n",
    "            commonutils.build_XY_matrix (models_results[setname].uncorrelated_features, \\\n",
    "                                    models_results[setname].labels)\n",
    "    \n",
    "    setlist = []\n",
    "    for i, s in enumerate(models_results[setname].setnames):\n",
    "        ss = models_results[setname].supersetnames[i]\n",
    "        setlist.append(ss + \"_\" + s)   \n",
    "    \n",
    "    y_pred_wtmad = models_results[setname].y_pred_wtmad \n",
    "    rmse_wtmad = mean_squared_error(Y, y_pred_wtmad, squared=False)\n",
    "    y_pred_mape = models_results[setname].y_pred_mape\n",
    "    rmse_mape = mean_squared_error(Y, y_pred_mape, squared=False)\n",
    "    y_pred_rmse = models_results[setname].y_pred_rmse\n",
    "    rmse_rmse = mean_squared_error(Y, y_pred_rmse, squared=False)\n",
    "    \n",
    "    if setname in supersetnames or setname == \"Full\":\n",
    "        if len(y_pred_mape.shape) == 2:\n",
    "            y_pred_mape = y_pred_mape[:,0]\n",
    "        if len(Y.shape) == 2:\n",
    "            Y = Y[:,0]\n",
    "        wtmad2 = commonutils.wtmad2(setlist, Y, y_pred_mape)\n",
    "        print(\"WTAMD2             (MAPE) %7.3f\"%wtmad2[\"Full\"])\n",
    "        if len(y_pred_wtmad.shape) == 2:\n",
    "            y_pred_wtmad = y_pred_wtmad[:,0]\n",
    "        wtmad2 = commonutils.wtmad2(setlist, Y, y_pred_wtmad)\n",
    "        print(\"WTMAD2            (WTMAD) %7.3f\"%wtmad2[\"Full\"])\n",
    "        if len(y_pred_rmse.shape) == 2:\n",
    "            y_pred_rmse = y_pred_rmse[:,0]\n",
    "        wtmad2 = commonutils.wtmad2(setlist, Y, y_pred_rmse)\n",
    "        print(\"WTAMD2             (RMSE) %7.3f\"%wtmad2[\"Full\"])\n",
    "        print(\"WTAMD2 (bestinsidemethod) %7.3f\"%models_results[setname].bestinsidemethod_wtmad) \n",
    "        print(\"WTAMD2    (bestourmethod) %7.3f\"%models_results[setname].bestourmethod_wtmad)\n",
    "\n",
    "    if printonlysuperset and setname not in list(supersetnames.keys()) + [\"Full\"]:\n",
    "        continue\n",
    "\n",
    "    print(\"RMSE              (WTAMD) %7.3f\"%rmse_wtmad)\n",
    "    print(\"RMSE               (MAPE) %7.3f\"%rmse_mape)\n",
    "    print(\"RMSE               (RMSE) %7.3f\"%rmse_rmse)\n",
    "    print(\"RMSE   (bestinsidemethod) %7.3f\"%models_results[setname].bestinsidemethod_rmse)\n",
    "    print(\"RMSE      (bestourmethod) %7.3f\"%models_results[setname].bestourmethod_rmse)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(Y, y_pred_wtmad, \\\n",
    "               c='b', s=50, label='NN Full model WTAMD')\n",
    "    ax.scatter(Y, y_pred_mape, \\\n",
    "                c='r', s=50, label='NN Full model MAPE')\n",
    "    #ax.scatter(Y, models_results[setname].y_pred_bestinsidemethod, \\\n",
    "    #            c='r', s=50, label='Best inside method')\n",
    "    ax.scatter(Y, y_pred_rmse, \\\n",
    "                c='black', s=50, label='NN Full model RMSE')\n",
    "    ax.scatter(Y, models_results[setname].y_pred_bestourmethod_rmse, \\\n",
    "               c='g', s=50, label='Best our method')\n",
    "    lims = [\n",
    "        np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "        np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "    ]\n",
    "    ax.plot(lims, lims, 'k-', alpha=0.75, zorder=0)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlim(lims)\n",
    "    ax.set_ylim(lims)\n",
    "    plt.xlabel('True Values')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.title(setname)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
